{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ-GHPTGx0x-",
        "outputId": "1cd34692-f5c9-443e-deef-261b909d36ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CH20JfjZx0lk",
        "outputId": "5d1f9eae-c7bf-422f-a20a-20afeb4dddb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Dec 10 14:30:56 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3OOBQYWFckK"
      },
      "outputs": [],
      "source": [
        "# !pip install REMI-z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HR2uv0Inh2Hc"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# # Check if REMI-z directory exists before cloning\n",
        "# if os.path.exists('REMI-z'):\n",
        "#     print(\"REMI-z directory already exists. Skipping git clone.\")\n",
        "# else:\n",
        "#     !git clone https://github.com/Sonata165/REMI-z.git\n",
        "\n",
        "# # Change directory using %cd for persistent changes in Colab\n",
        "# %cd REMI-z\n",
        "# !pip install -r Requirements.txt\n",
        "# !pip install -e .\n",
        "# %cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmS1DNYPFT6F"
      },
      "outputs": [],
      "source": [
        "from remi_z import MultiTrack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmoZeJX8J6nd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsnGhInXuOoN"
      },
      "source": [
        "## Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdE3vFor-J9z",
        "outputId": "aa001db6-cc04-4431-d24f-590a156ef912"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-12-10 14:31:13--  http://hog.ee.columbia.edu/craffel/lmd/lmd_full.tar.gz\n",
            "Resolving hog.ee.columbia.edu (hog.ee.columbia.edu)... 128.59.66.5\n",
            "Connecting to hog.ee.columbia.edu (hog.ee.columbia.edu)|128.59.66.5|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1768163879 (1.6G) [application/x-gzip]\n",
            "Saving to: ‘lmd_full.tar.gz.1’\n",
            "\n",
            "lmd_full.tar.gz.1   100%[===================>]   1.65G  7.61MB/s    in 3m 11s  \n",
            "\n",
            "2025-12-10 14:34:25 (8.81 MB/s) - ‘lmd_full.tar.gz.1’ saved [1768163879/1768163879]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://hog.ee.columbia.edu/craffel/lmd/lmd_full.tar.gz\n",
        "!tar -xzf lmd_full.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOog0P-7uHJD",
        "outputId": "5a087e30-e97f-4555-bbd9-7fae79132351"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lmd_full  lmd_full.tar.gz  lmd_full.tar.gz.1  REMI-z  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2luOa7muHGv",
        "outputId": "a8540f1d-1e3d-4571-cd4a-40d8ccbea437"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['location', 'caption', 'genre', 'genre_prob', 'mood', 'mood_prob', 'key', 'time_signature', 'tempo', 'tempo_word', 'duration', 'duration_word', 'chord_summary', 'chord_summary_occurence', 'instrument_summary', 'instrument_numbers_sorted', 'all_chords', 'all_chords_timestamps', 'test_set'],\n",
              "        num_rows: 168385\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Login using e.g. `huggingface-cli login` to access this dataset\n",
        "ds = load_dataset(\"amaai-lab/MidiCaps\")\n",
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "C3hs1dMduHBY",
        "outputId": "9ff2d67e-f9ec-44a3-ca79-440f32882f2d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a8cbf8b7-d6f3-4c98-894b-c83f4ce1f575\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>location</th>\n",
              "      <th>caption</th>\n",
              "      <th>genre</th>\n",
              "      <th>genre_prob</th>\n",
              "      <th>mood</th>\n",
              "      <th>mood_prob</th>\n",
              "      <th>key</th>\n",
              "      <th>time_signature</th>\n",
              "      <th>tempo</th>\n",
              "      <th>tempo_word</th>\n",
              "      <th>duration</th>\n",
              "      <th>duration_word</th>\n",
              "      <th>chord_summary</th>\n",
              "      <th>chord_summary_occurence</th>\n",
              "      <th>instrument_summary</th>\n",
              "      <th>instrument_numbers_sorted</th>\n",
              "      <th>all_chords</th>\n",
              "      <th>all_chords_timestamps</th>\n",
              "      <th>test_set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lmd_full/1/1a0751ad20e2f82957410a7510a1b13e.mid</td>\n",
              "      <td>A melodic electronic composition with classica...</td>\n",
              "      <td>[electronic, classical]</td>\n",
              "      <td>[0.3596, 0.2367]</td>\n",
              "      <td>[melodic, film, space, epic, relaxing]</td>\n",
              "      <td>[0.1228, 0.1114, 0.0917, 0.0828, 0.079]</td>\n",
              "      <td>F# minor</td>\n",
              "      <td>4/4</td>\n",
              "      <td>135.0</td>\n",
              "      <td>Allegro</td>\n",
              "      <td>59</td>\n",
              "      <td>Short song</td>\n",
              "      <td>[F#m, A/E, C#]</td>\n",
              "      <td>2</td>\n",
              "      <td>[String Ensemble, Trumpet, Brass Section, Synt...</td>\n",
              "      <td>[48, 56, 61, 50, 128, 35]</td>\n",
              "      <td>[F#m, A/E, C#, F#m, C#, F#m, C#, D, C#, Bm, F#...</td>\n",
              "      <td>[0.464399092, 5.015510204, 5.758548752, 8.8235...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lmd_full/1/164fcc530a285bdb8066c6aa8616c95b.mid</td>\n",
              "      <td>A cheerful and melodic Christmas song that ble...</td>\n",
              "      <td>[classical, pop]</td>\n",
              "      <td>[0.1914, 0.1836]</td>\n",
              "      <td>[christmas, happy, melodic, corporate, adventure]</td>\n",
              "      <td>[0.1763, 0.1688, 0.1643, 0.1282, 0.072]</td>\n",
              "      <td>Eb major</td>\n",
              "      <td>2/4</td>\n",
              "      <td>124.0</td>\n",
              "      <td>Allegro</td>\n",
              "      <td>169</td>\n",
              "      <td>Song</td>\n",
              "      <td>[Eb, Bb7, Eb, Fm]</td>\n",
              "      <td>5</td>\n",
              "      <td>[Tango Accordion, Clarinet, Acoustic Guitar, D...</td>\n",
              "      <td>[23, 71, 25, 128, 32]</td>\n",
              "      <td>[Bb7, Eb, Bb7, Eb, Fm, Eb, Bb7, Eb, Bb7, Eb, F...</td>\n",
              "      <td>[0.464399092, 6.780226757, 9.84526077, 13.7462...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lmd_full/1/16b9a230fb007c0009feee532c3c4686.mid</td>\n",
              "      <td>This energetic electronic and classical compos...</td>\n",
              "      <td>[electronic, classical]</td>\n",
              "      <td>[0.2148, 0.1806]</td>\n",
              "      <td>[energetic, film, melodic, happy, dark]</td>\n",
              "      <td>[0.1079, 0.1062, 0.0958, 0.0927, 0.0635]</td>\n",
              "      <td>C major</td>\n",
              "      <td>4/4</td>\n",
              "      <td>120.0</td>\n",
              "      <td>Moderate tempo</td>\n",
              "      <td>158</td>\n",
              "      <td>Song</td>\n",
              "      <td>[C, G, C, C7]</td>\n",
              "      <td>2</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[C, G, C, C7, Dm, C, G, C, C7, Bbmaj7, C, G7, ...</td>\n",
              "      <td>[0.464399092, 4.086712018, 7.430385487, 8.9164...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lmd_full/1/17655598958db48a34cd882f81402568.mid</td>\n",
              "      <td>A short electronic ambient song featuring a pi...</td>\n",
              "      <td>[electronic, ambient]</td>\n",
              "      <td>[0.3031, 0.2369]</td>\n",
              "      <td>[film, energetic, melodic, epic, dark]</td>\n",
              "      <td>[0.1162, 0.1108, 0.105, 0.0863, 0.0824]</td>\n",
              "      <td>E major</td>\n",
              "      <td>4/4</td>\n",
              "      <td>170.0</td>\n",
              "      <td>Presto</td>\n",
              "      <td>99</td>\n",
              "      <td>Short song</td>\n",
              "      <td>[B, Emaj7, C#m7, B7, A]</td>\n",
              "      <td>5</td>\n",
              "      <td>[Piano]</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[B, Emaj7, C#m7, B7, A, B, Emaj7, C#m7, B7, A,...</td>\n",
              "      <td>[0.464399092, 1.30031746, 2.972154195, 3.71519...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lmd_full/1/13ad61f0cef919bc069175d0b0ce2437.mid</td>\n",
              "      <td>In this short electronic song, synth strings l...</td>\n",
              "      <td>[electronic, ambient]</td>\n",
              "      <td>[0.4655, 0.2017]</td>\n",
              "      <td>[film, space, relaxing, melodic, dark]</td>\n",
              "      <td>[0.0944, 0.0943, 0.0885, 0.0856, 0.0816]</td>\n",
              "      <td>C minor</td>\n",
              "      <td>4/4</td>\n",
              "      <td>124.0</td>\n",
              "      <td>Fast</td>\n",
              "      <td>103</td>\n",
              "      <td>Short song</td>\n",
              "      <td>[Gm, Dm, F, C, Bb6]</td>\n",
              "      <td>1</td>\n",
              "      <td>[Synth Strings, Drums, Electric Bass, Trumpet,...</td>\n",
              "      <td>[51, 128, 34, 56, 52, 115, 61, 25, 55, 16]</td>\n",
              "      <td>[Gm, Dm, F, C, Bb6, C7, Bb, Cm, Bb, Cm7, Bb, G...</td>\n",
              "      <td>[0.464399092, 4.272471655, 5.665668934, 8.2663...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8cbf8b7-d6f3-4c98-894b-c83f4ce1f575')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a8cbf8b7-d6f3-4c98-894b-c83f4ce1f575 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a8cbf8b7-d6f3-4c98-894b-c83f4ce1f575');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e593b2be-62f2-4984-8775-824d1574e437\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e593b2be-62f2-4984-8775-824d1574e437')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e593b2be-62f2-4984-8775-824d1574e437 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                          location  \\\n",
              "0  lmd_full/1/1a0751ad20e2f82957410a7510a1b13e.mid   \n",
              "1  lmd_full/1/164fcc530a285bdb8066c6aa8616c95b.mid   \n",
              "2  lmd_full/1/16b9a230fb007c0009feee532c3c4686.mid   \n",
              "3  lmd_full/1/17655598958db48a34cd882f81402568.mid   \n",
              "4  lmd_full/1/13ad61f0cef919bc069175d0b0ce2437.mid   \n",
              "\n",
              "                                             caption                    genre  \\\n",
              "0  A melodic electronic composition with classica...  [electronic, classical]   \n",
              "1  A cheerful and melodic Christmas song that ble...         [classical, pop]   \n",
              "2  This energetic electronic and classical compos...  [electronic, classical]   \n",
              "3  A short electronic ambient song featuring a pi...    [electronic, ambient]   \n",
              "4  In this short electronic song, synth strings l...    [electronic, ambient]   \n",
              "\n",
              "         genre_prob                                               mood  \\\n",
              "0  [0.3596, 0.2367]             [melodic, film, space, epic, relaxing]   \n",
              "1  [0.1914, 0.1836]  [christmas, happy, melodic, corporate, adventure]   \n",
              "2  [0.2148, 0.1806]            [energetic, film, melodic, happy, dark]   \n",
              "3  [0.3031, 0.2369]             [film, energetic, melodic, epic, dark]   \n",
              "4  [0.4655, 0.2017]             [film, space, relaxing, melodic, dark]   \n",
              "\n",
              "                                  mood_prob       key time_signature  tempo  \\\n",
              "0   [0.1228, 0.1114, 0.0917, 0.0828, 0.079]  F# minor            4/4  135.0   \n",
              "1   [0.1763, 0.1688, 0.1643, 0.1282, 0.072]  Eb major            2/4  124.0   \n",
              "2  [0.1079, 0.1062, 0.0958, 0.0927, 0.0635]   C major            4/4  120.0   \n",
              "3   [0.1162, 0.1108, 0.105, 0.0863, 0.0824]   E major            4/4  170.0   \n",
              "4  [0.0944, 0.0943, 0.0885, 0.0856, 0.0816]   C minor            4/4  124.0   \n",
              "\n",
              "       tempo_word  duration duration_word            chord_summary  \\\n",
              "0         Allegro        59    Short song           [F#m, A/E, C#]   \n",
              "1         Allegro       169          Song        [Eb, Bb7, Eb, Fm]   \n",
              "2  Moderate tempo       158          Song            [C, G, C, C7]   \n",
              "3          Presto        99    Short song  [B, Emaj7, C#m7, B7, A]   \n",
              "4            Fast       103    Short song      [Gm, Dm, F, C, Bb6]   \n",
              "\n",
              "   chord_summary_occurence                                 instrument_summary  \\\n",
              "0                        2  [String Ensemble, Trumpet, Brass Section, Synt...   \n",
              "1                        5  [Tango Accordion, Clarinet, Acoustic Guitar, D...   \n",
              "2                        2                                                 []   \n",
              "3                        5                                            [Piano]   \n",
              "4                        1  [Synth Strings, Drums, Electric Bass, Trumpet,...   \n",
              "\n",
              "                    instrument_numbers_sorted  \\\n",
              "0                   [48, 56, 61, 50, 128, 35]   \n",
              "1                       [23, 71, 25, 128, 32]   \n",
              "2                                          []   \n",
              "3                                         [0]   \n",
              "4  [51, 128, 34, 56, 52, 115, 61, 25, 55, 16]   \n",
              "\n",
              "                                          all_chords  \\\n",
              "0  [F#m, A/E, C#, F#m, C#, F#m, C#, D, C#, Bm, F#...   \n",
              "1  [Bb7, Eb, Bb7, Eb, Fm, Eb, Bb7, Eb, Bb7, Eb, F...   \n",
              "2  [C, G, C, C7, Dm, C, G, C, C7, Bbmaj7, C, G7, ...   \n",
              "3  [B, Emaj7, C#m7, B7, A, B, Emaj7, C#m7, B7, A,...   \n",
              "4  [Gm, Dm, F, C, Bb6, C7, Bb, Cm, Bb, Cm7, Bb, G...   \n",
              "\n",
              "                               all_chords_timestamps  test_set  \n",
              "0  [0.464399092, 5.015510204, 5.758548752, 8.8235...     False  \n",
              "1  [0.464399092, 6.780226757, 9.84526077, 13.7462...     False  \n",
              "2  [0.464399092, 4.086712018, 7.430385487, 8.9164...     False  \n",
              "3  [0.464399092, 1.30031746, 2.972154195, 3.71519...     False  \n",
              "4  [0.464399092, 4.272471655, 5.665668934, 8.2663...     False  "
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = ds['train'].to_pandas()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfLuzZO4CQNQ",
        "outputId": "ff15f36e-c086-4a81-b73b-3650d9da9961"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial sample size after stratified sampling: 2842\n",
            "Final stratified sample size: 2842\n",
            "Stratified Sample DataFrame head:\n",
            "                                               location  \\\n",
            "65537   lmd_full/2/2a604c93ed4ee9d82d388da694e89e7c.mid   \n",
            "32776   lmd_full/0/0fd51dae1d5ffc871de6b8bd8ff3e5ce.mid   \n",
            "40971   lmd_full/0/00bb4be2822c3828935498af7b90b98e.mid   \n",
            "139280  lmd_full/e/e7394f75f6978369eb463abcb75a88da.mid   \n",
            "49169   lmd_full/f/f5ac97af893d6b5cec0324bc49ae10bb.mid   \n",
            "\n",
            "                                                  caption  \\\n",
            "65537   A cheerful reggae-pop song in C# major, featur...   \n",
            "32776   A cheerful and inspiring pop song featuring ac...   \n",
            "40971   A soothing Christmas pop song with jazz influe...   \n",
            "139280  A lively electronic and pop fusion, this Chris...   \n",
            "49169   A very short fragment of electronic music with...   \n",
            "\n",
            "                             genre        genre_prob  \\\n",
            "65537                [reggae, pop]  [0.3014, 0.2529]   \n",
            "32776               [pop, popfolk]  [0.5125, 0.1928]   \n",
            "40971                  [pop, jazz]  [0.2524, 0.2312]   \n",
            "139280           [electronic, pop]   [0.2931, 0.283]   \n",
            "49169   [electronic, experimental]   [0.717, 0.1675]   \n",
            "\n",
            "                                                     mood  \\\n",
            "65537   [happy, melodic, motivational, corporate, chri...   \n",
            "32776     [happy, love, inspiring, motivational, melodic]   \n",
            "40971   [christmas, relaxing, melodic, ballad, meditat...   \n",
            "139280  [happy, melodic, christmas, corporate, backgro...   \n",
            "49169               [space, happy, game, energetic, dark]   \n",
            "\n",
            "                                       mood_prob       key time_signature  \\\n",
            "65537     [0.2345, 0.122, 0.1119, 0.109, 0.1049]  C# major            4/4   \n",
            "32776    [0.2647, 0.1735, 0.1303, 0.114, 0.1034]   G major            4/4   \n",
            "40971    [0.1328, 0.129, 0.1008, 0.0986, 0.0731]   E minor            4/4   \n",
            "139280  [0.1293, 0.1277, 0.1012, 0.0726, 0.0605]   E minor            4/4   \n",
            "49169     [0.11, 0.0921, 0.0874, 0.0733, 0.0731]  Bb minor            4/4   \n",
            "\n",
            "        tempo tempo_word  duration   duration_word          chord_summary  \\\n",
            "65537   105.0   Moderato       190            Song               [C#, F#]   \n",
            "32776   110.0   Moderato       118      Short song                [A7, D]   \n",
            "40971    68.0     Adagio       258            Song  [B7, E7, A7, Daug, G]   \n",
            "139280  178.0  Very fast       272            Song     [Bm, A, Em7, G, A]   \n",
            "49169   140.0       Fast         3  Short fragment                [F, F#]   \n",
            "\n",
            "        chord_summary_occurence  \\\n",
            "65537                        20   \n",
            "32776                         2   \n",
            "40971                         4   \n",
            "139280                        5   \n",
            "49169                         1   \n",
            "\n",
            "                                       instrument_summary  \\\n",
            "65537     [Drums, Synth Bass, Tuba, Piano, Fretless Bass]   \n",
            "32776   [Acoustic Guitar, Drums, Acoustic Bass, Electr...   \n",
            "40971   [Vibraphone, Acoustic Bass, French Horn, Piano...   \n",
            "139280  [Piano, Electric Bass, Electric Guitar, Alto S...   \n",
            "49169                                        [Synth Lead]   \n",
            "\n",
            "                        instrument_numbers_sorted  \\\n",
            "65537   [128, 39, 58, 0, 35, 19, 75, 73, 72, 102]   \n",
            "32776           [25, 25, 25, 128, 25, 32, 28, 28]   \n",
            "40971                        [11, 32, 60, 0, 128]   \n",
            "139280           [4, 33, 28, 65, 128, 12, 73, 51]   \n",
            "49169                                        [81]   \n",
            "\n",
            "                                               all_chords  \\\n",
            "65537   [C#, F#, C#, F#, C#, F#, C#, F#, C#, F#, C#, F...   \n",
            "32776   [C, F, Bb, F, C, G/D, C, G7, Cmaj7, G7, C, F, ...   \n",
            "40971   [G, Em7, Em6, Am7, Gm, Gmaj7, Em7, A7, C#m7b5,...   \n",
            "139280  [B, A, Gm7, A, Bm, A, G, A, Bm, A, Gmaj7, A, B...   \n",
            "49169                                             [F, F#]   \n",
            "\n",
            "                                    all_chords_timestamps  test_set  \n",
            "65537   [0.464399092, 4.551111111, 6.965986394, 9.1951...     False  \n",
            "32776   [0.464399092, 4.272471655, 6.687346938, 8.9164...     False  \n",
            "40971   [0.464399092, 7.058866213, 11.609977324, 14.02...     False  \n",
            "139280  [1.114557823, 4.179591836, 6.8731065749999996,...     False  \n",
            "49169                   [0.464399092, 2.4148752829999998]     False  \n",
            "Stratified Sample DataFrame shape:\n",
            "(2842, 19)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "\n",
        "stratified_sample_rows = []\n",
        "sampled_indices = set()\n",
        "TARGET_SAMPLE_SIZE = 500\n",
        "\n",
        "# Explode the 'genre' column to get all unique genres\n",
        "exploded_genres = df['genre'].explode()\n",
        "list_of_unique_genres = exploded_genres.unique().tolist()\n",
        "\n",
        "for genre in list_of_unique_genres:\n",
        "    # Identify all rows that contain this specific genre and whose indices are not already in sampled_indices\n",
        "    available_for_genre_df = df[df['genre'].apply(lambda x: genre in x)]\n",
        "    available_for_genre_indices = available_for_genre_df.index.difference(sampled_indices)\n",
        "\n",
        "    # Randomly select up to 100 indices from available_for_genre\n",
        "    num_to_select = min(100, len(available_for_genre_indices))\n",
        "    if num_to_select > 0:\n",
        "        selected_indices = np.random.choice(available_for_genre_indices, num_to_select, replace=False)\n",
        "        stratified_sample_rows.extend(selected_indices)\n",
        "        sampled_indices.update(selected_indices)\n",
        "\n",
        "print(f\"Initial sample size after stratified sampling: {len(sampled_indices)}\")\n",
        "\n",
        "# If the total sample size is less than target sample size, randomly select additional unique rows\n",
        "if len(sampled_indices) < TARGET_SAMPLE_SIZE:\n",
        "    remaining_needed = TARGET_SAMPLE_SIZE - len(sampled_indices)\n",
        "\n",
        "    # Identify all indices in df that are not yet in sampled_indices\n",
        "    additional_available_indices = df.index.difference(sampled_indices)\n",
        "\n",
        "    # Randomly select remaining_needed unique indices from additional_available_indices\n",
        "    if len(additional_available_indices) >= remaining_needed:\n",
        "        additional_selection = np.random.choice(additional_available_indices, remaining_needed, replace=False)\n",
        "        stratified_sample_rows.extend(additional_selection)\n",
        "        sampled_indices.update(additional_selection)\n",
        "    else:\n",
        "        # If not enough unique rows to reach target size, take all available and print a warning\n",
        "        print(f\"Warning: Could not reach {TARGET_SAMPLE_SIZE} samples. Only {len(sampled_indices) + len(additional_available_indices)} unique rows available.\")\n",
        "        stratified_sample_rows.extend(additional_available_indices)\n",
        "        sampled_indices.update(additional_available_indices)\n",
        "\n",
        "# Create the sample_df DataFrame using df.loc[] with the unique indices collected in sampled_indices\n",
        "sample_df_stratified = df.loc[list(sampled_indices)]\n",
        "\n",
        "print(f\"Final stratified sample size: {len(sample_df_stratified)}\")\n",
        "print(\"Stratified Sample DataFrame head:\")\n",
        "print(sample_df_stratified.head())\n",
        "print(\"Stratified Sample DataFrame shape:\")\n",
        "print(sample_df_stratified.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "53cc0cd7",
        "outputId": "5f00aec4-be45-4c45-d20d-a7087466cd65"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"lmd_full/0/0fd51dae1d5ffc871de6b8bd8ff3e5ce.mid\",\n          \"lmd_full/f/f5ac97af893d6b5cec0324bc49ae10bb.mid\",\n          \"lmd_full/0/00bb4be2822c3828935498af7b90b98e.mid\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genre\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-746d18ce-c8ef-4905-ad1c-059af8f46559\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>location</th>\n",
              "      <th>genre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lmd_full/2/2a604c93ed4ee9d82d388da694e89e7c.mid</td>\n",
              "      <td>[reggae, pop]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lmd_full/0/0fd51dae1d5ffc871de6b8bd8ff3e5ce.mid</td>\n",
              "      <td>[pop, popfolk]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lmd_full/0/00bb4be2822c3828935498af7b90b98e.mid</td>\n",
              "      <td>[pop, jazz]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lmd_full/e/e7394f75f6978369eb463abcb75a88da.mid</td>\n",
              "      <td>[electronic, pop]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lmd_full/f/f5ac97af893d6b5cec0324bc49ae10bb.mid</td>\n",
              "      <td>[electronic, experimental]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-746d18ce-c8ef-4905-ad1c-059af8f46559')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-746d18ce-c8ef-4905-ad1c-059af8f46559 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-746d18ce-c8ef-4905-ad1c-059af8f46559');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7b0778b4-97e1-4040-a0e5-4a5bbbc0fbd2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7b0778b4-97e1-4040-a0e5-4a5bbbc0fbd2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7b0778b4-97e1-4040-a0e5-4a5bbbc0fbd2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                          location                       genre\n",
              "0  lmd_full/2/2a604c93ed4ee9d82d388da694e89e7c.mid               [reggae, pop]\n",
              "1  lmd_full/0/0fd51dae1d5ffc871de6b8bd8ff3e5ce.mid              [pop, popfolk]\n",
              "2  lmd_full/0/00bb4be2822c3828935498af7b90b98e.mid                 [pop, jazz]\n",
              "3  lmd_full/e/e7394f75f6978369eb463abcb75a88da.mid           [electronic, pop]\n",
              "4  lmd_full/f/f5ac97af893d6b5cec0324bc49ae10bb.mid  [electronic, experimental]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = sample_df_stratified[['location', 'genre']]\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGQ4Hdr8d_eG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18065cdd",
        "outputId": "e165a0d3-45ac-4720-fa05-b412a3f4223a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique genres: 42\n",
            "Unique genres: {'funk', 'instrumentalrock', 'easylistening', 'instrumentalpop', 'symphonic', 'chillout', 'punkrock', 'jazz', 'ambient', '90s', 'drumnbass', 'metal', 'hiphop', 'swing', 'newage', 'alternative', 'blues', 'dance', 'house', 'folk', 'experimental', 'soundtrack', 'indie', '80s', 'orchestral', 'poprock', 'jazzfusion', 'techno', 'pop', 'popfolk', 'lounge', 'electropop', 'electronic', 'reggae', 'rock', 'classical', 'latin', 'synthpop', 'world', 'celtic', 'trance', 'country'}\n"
          ]
        }
      ],
      "source": [
        "unique_genres = set()\n",
        "for genres_list in df['genre']:\n",
        "    for genre in genres_list:\n",
        "        unique_genres.add(genre)\n",
        "\n",
        "NUM_CLASSES = len(unique_genres)\n",
        "\n",
        "print(f\"Number of unique genres: {NUM_CLASSES}\")\n",
        "print(f\"Unique genres: {unique_genres}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGQSgln1f1rA",
        "outputId": "9b4cc570-c762-4665-d903-0207da1e8ddd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Genre to index mapping:\n",
            "{'80s': 0, '90s': 1, 'alternative': 2, 'ambient': 3, 'blues': 4, 'celtic': 5, 'chillout': 6, 'classical': 7, 'country': 8, 'dance': 9, 'drumnbass': 10, 'easylistening': 11, 'electronic': 12, 'electropop': 13, 'experimental': 14, 'folk': 15, 'funk': 16, 'hiphop': 17, 'house': 18, 'indie': 19, 'instrumentalpop': 20, 'instrumentalrock': 21, 'jazz': 22, 'jazzfusion': 23, 'latin': 24, 'lounge': 25, 'metal': 26, 'newage': 27, 'orchestral': 28, 'pop': 29, 'popfolk': 30, 'poprock': 31, 'punkrock': 32, 'reggae': 33, 'rock': 34, 'soundtrack': 35, 'swing': 36, 'symphonic': 37, 'synthpop': 38, 'techno': 39, 'trance': 40, 'world': 41}\n"
          ]
        }
      ],
      "source": [
        "CLASS_TO_INDEX = {genre: idx for idx, genre in enumerate(sorted(list(unique_genres)))}\n",
        "\n",
        "print(\"Genre to index mapping:\")\n",
        "print(CLASS_TO_INDEX)\n",
        "\n",
        "# # Function to convert a list of genre names to a list of genre indices\n",
        "# def get_genre_indices(genres):\n",
        "#     return [CLASS_TO_INDEX[g] for g in genres]\n",
        "\n",
        "# # Apply the function to create a new column 'genre_indices'\n",
        "# df['genre_indices'] = df['genre'].apply(get_genre_indices)\n",
        "\n",
        "# print(\"\\nDataFrame with genre indices:\")\n",
        "# display(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzPaaun1f1iZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMHkmF1lz5Xc",
        "outputId": "0677670c-1cef-47d9-cde3-cb1d01220e29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('/content/lmd_full/2/2a604c93ed4ee9d82d388da694e89e7c.mid',\n",
              " array(['reggae', 'pop'], dtype=object))"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "midi_fp = \"/content/\" + df['location'][0]\n",
        "labels = df['genre'][0]\n",
        "midi_fp, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RnZg3ka7CGi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hd1YF5HM7CDk"
      },
      "outputs": [],
      "source": [
        "import miditoolkit\n",
        "\n",
        "\n",
        "def load_midi(file_path=None, file=None, midi_checker='default'):\n",
        "    \"\"\"\n",
        "    Open and check MIDI file, return MIDI object by miditoolkit.\n",
        "    :param file_path:\n",
        "    :param midi_checker:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    midi_obj = miditoolkit.midi.parser.MidiFile(filename=file_path, file=file)\n",
        "\n",
        "    if midi_checker is not None and midi_checker != 'none':\n",
        "        if isinstance(midi_checker, str):\n",
        "            if midi_checker == 'default':\n",
        "                midi_checker = default_check_midi\n",
        "            else:\n",
        "                raise ValueError(\"midi checker does not support value: %s\" % midi_checker)\n",
        "\n",
        "        midi_checker(midi_obj)\n",
        "\n",
        "    return midi_obj\n",
        "\n",
        "\n",
        "def default_check_midi(midi_obj):\n",
        "    # check abnormal values in parse result\n",
        "    max_time_length = 2 ** 31\n",
        "    assert all(0 <= j.start < max_time_length\n",
        "               and 0 <= j.end < max_time_length\n",
        "               for i in midi_obj.instruments for j in i.notes), 'Bad note time'\n",
        "    assert all(0 < j.numerator < max_time_length and 0 < j.denominator < max_time_length for j in\n",
        "               midi_obj.time_signature_changes), 'Bad time signature value'\n",
        "    assert 0 < midi_obj.ticks_per_beat < max_time_length, 'Bad ticks per beat'\n",
        "\n",
        "    midi_notes_count = sum(len(inst.notes) for inst in midi_obj.instruments)\n",
        "    assert midi_notes_count > 0, 'Blank note.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMcfCXyZ7B_l",
        "outputId": "d67d6ddf-2f63-4d72-c65e-4d0a0f213a3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ticks per beat: 96\n",
            "max tick: 31873\n",
            "tempo changes: 1\n",
            "time sig: 1\n",
            "key sig: 0\n",
            "markers: 0\n",
            "lyrics: False\n",
            "instruments: 10\n"
          ]
        }
      ],
      "source": [
        "loaded_midi = load_midi(file_path=midi_fp)\n",
        "print(loaded_midi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwW-5_yd6yrM",
        "outputId": "3d42d93f-3958-48dc-ebbc-577b41d9ccc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultiTrack: 83 bars"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mt = MultiTrack.from_midi(midi_fp)\n",
        "mt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2XSidJrYQ90",
        "outputId": "4536bbe6-60d6-4792-c7c3-cc09cc741ad4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bar 0: 0 insts\n",
            "Bar 1: 5 insts\n"
          ]
        }
      ],
      "source": [
        "print(mt[0])\n",
        "print(mt[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8foDFBRYQ0d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eum6ELbF6ydc",
        "outputId": "bddea366-73e8-4d45-b49f-2187eb8e840a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'remi_z.core.MultiTrack'>\n",
            "<class 'str'>\n",
            "Number of tokens in REMI-z string: 9623\n",
            "s-9 t-33 b-1 s-9 t-33 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-0\n",
            "o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42\n",
            "p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30\n",
            "p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37\n",
            "d-6 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36\n",
            "p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2\n",
            "p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2\n",
            "p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66\n",
            "d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-6 o-36 p-42 d-9 b-1 s-9 t-33 i-58 o-0 p-73\n",
            "d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18\n",
            "p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6\n",
            "p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68\n",
            "d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-7 o-21 p-32 d-2 o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-78 d-22\n",
            "o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4\n",
            "o-45 p-85 d-2 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66\n",
            "d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66\n",
            "d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-9 o-21\n",
            "p-42 d-1 o-24 p-42 d-3 o-27 p-42 d-1 o-30 p-42 d-6 o-36 p-41 d-5 o-42 p-39 d-4 b-1 s-9 t-33 i-58 o-0\n",
            "p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3\n",
            "o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-35\n",
            "o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42\n",
            "p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9 t-33 i-58 o-0 p-78\n",
            "d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89\n",
            "d-4 o-45 p-85 d-2 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2\n",
            "p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2\n",
            "p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6\n",
            "o-21 p-37 d-2 o-24 p-42 d-6 o-36 p-42 d-9 b-1 s-9 t-33 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78\n",
            "d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2\n",
            "o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2\n",
            "o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39\n",
            "o-0 p-37 d-7 o-15 p-32 d-2 o-18 p-34 d-2 o-21 p-32 d-2 p-32 d-1 o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0\n",
            "p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42\n",
            "p-89 d-4 o-45 p-85 d-2 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70\n",
            "d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70\n",
            "d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42\n",
            "d-9 o-21 p-37 d-3 o-24 p-42 d-9 o-36 p-42 d-5 o-39 p-43 d-3 o-42 p-44 d-5 b-1 s-9 t-33 i-73 o-0 p-77\n",
            "d-5 o-6 p-77 d-1 o-9 p-77 d-1 o-12 p-77 d-2 o-15 p-75 d-1 o-18 p-75 d-4 o-24 p-75 d-5 o-30 p-73 d-9\n",
            "i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2\n",
            "o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2\n",
            "o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-102 o-0 p-61 d-1 p-56 d-2 p-53 d-1\n",
            "i-39 o-0 p-37 d-7 b-1 s-9 t-33 i-73 o-12 p-75 d-6 o-18 p-73 d-1 o-21 p-73 d-7 o-27 p-70 d-11 o-42\n",
            "p-70 d-1 o-45 p-70 d-3 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70\n",
            "d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70\n",
            "d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-102 o-0 p-66\n",
            "d-1 p-61 d-1 p-58 d-1 i-39 o-0 p-42 d-9 b-1 s-9 t-33 i-73 o-0 p-77 d-5 o-6 p-77 d-3 o-12 p-77 d-5\n",
            "o-18 p-75 d-1 o-21 p-75 d-8 o-30 p-73 d-2 o-36 p-73 d-9 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68\n",
            "d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68\n",
            "d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3\n",
            "p-65 d-2 p-61 d-2 i-102 o-0 p-61 d-1 p-56 d-1 p-53 d-1 i-39 o-0 p-37 d-8 o-21 p-32 d-2 o-24 p-37 d-7\n",
            "b-1 s-9 t-33 i-73 o-12 p-75 d-6 o-18 p-73 d-2 o-21 p-73 d-9 o-30 p-70 d-11 i-0 o-6 p-70 d-2 p-66 d-2\n",
            "p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61\n",
            "d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61\n",
            "d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-102 o-0 p-66 d-2 p-61 d-1 p-58 d-1 i-39 o-0 p-42 d-8 o-21 p-37\n",
            "d-2 o-24 p-42 d-6 o-36 p-37 d-7 b-1 s-9 t-33 i-73 o-12 p-75 d-5 o-18 p-75 d-2 o-21 p-75 d-6 o-30\n",
            "p-75 d-5 o-36 p-77 d-6 o-42 p-78 d-8 i-19 o-0 p-68 d-47 p-63 d-46 p-60 d-47 i-0 o-6 p-68 d-2 p-63\n",
            "d-2 p-60 d-1 o-18 p-68 d-2 p-63 d-2 p-60 d-1 o-30 p-68 d-2 p-63 d-2 p-60 d-1 o-42 p-68 d-2 p-63 d-2\n",
            "p-60 d-1 i-35 o-6 p-68 d-2 p-63 d-2 p-60 d-1 o-18 p-68 d-2 p-63 d-2 p-60 d-1 o-30 p-68 d-2 p-63 d-2\n",
            "p-60 d-1 o-42 p-68 d-2 p-63 d-2 p-60 d-1 i-102 o-0 p-63 d-2 p-60 d-1 p-56 d-2 i-39 o-0 p-44 d-7 o-21\n",
            "p-39 d-2 o-24 p-44 d-6 b-1 s-9 t-33 i-73 o-0 p-77 d-10 o-12 p-72 d-13 o-36 p-77 d-6 o-42 p-75 d-3\n",
            "o-45 p-73 d-7 i-19 o-0 p-68 d-46 p-65 d-46 p-60 d-45 i-0 o-6 p-68 d-2 p-65 d-2 p-60 d-1 o-18 p-68\n",
            "d-2 p-65 d-2 p-60 d-2 o-30 p-68 d-2 p-65 d-1 p-60 d-1 o-42 p-68 d-1 p-65 d-1 p-60 d-1 i-35 o-6 p-68\n",
            "d-2 p-65 d-2 p-60 d-1 o-18 p-68 d-2 p-65 d-2 p-60 d-2 o-30 p-68 d-2 p-65 d-1 p-60 d-1 o-42 p-68 d-1\n",
            "p-65 d-1 p-60 d-1 i-102 o-0 p-65 d-3 p-60 d-3 p-56 d-3 i-39 o-0 p-41 d-6 o-21 p-37 d-3 o-24 p-41 d-8\n",
            "o-36 p-32 d-6 b-1 s-9 t-33 i-73 o-6 p-70 d-9 o-30 p-70 d-6 o-36 p-78 d-6 o-42 p-77 d-5 i-19 o-0 p-70\n",
            "d-47 p-66 d-47 p-61 d-47 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-1 o-18 p-70 d-2 p-66 d-2 p-61 d-1 o-30\n",
            "p-70 d-2 p-66 d-1 p-61 d-1 o-42 p-70 d-1 p-66 d-1 p-61 d-1 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-1 o-18\n",
            "p-70 d-2 p-66 d-2 p-61 d-1 o-30 p-70 d-2 p-66 d-1 p-61 d-1 o-42 p-70 d-1 p-66 d-1 p-61 d-1 i-102 o-0\n",
            "p-66 d-2 p-61 d-2 p-58 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-7 b-1 s-9 t-33 i-73 o-0 p-75\n",
            "d-16 i-19 o-0 p-68 d-44 p-63 d-44 p-60 d-44 i-0 o-6 p-68 d-2 p-63 d-1 p-60 d-1 o-18 p-68 d-1 p-63\n",
            "d-1 p-60 d-1 o-30 p-68 d-1 p-63 d-1 p-60 d-1 o-42 p-68 d-1 p-63 d-1 p-60 d-1 i-35 o-6 p-68 d-2 p-63\n",
            "d-1 p-60 d-1 o-18 p-68 d-1 p-63 d-1 p-60 d-1 o-30 p-68 d-1 p-63 d-1 p-60 d-1 o-42 p-68 d-1 p-63 d-1\n",
            "p-60 d-1 i-102 o-0 p-63 d-2 p-60 d-1 p-56 d-2 i-39 o-0 p-44 d-7 o-21 p-39 d-2 o-24 p-44 d-9 o-36\n",
            "p-32 d-7 b-1 s-9 t-33 i-58 o-0 p-80 d-36 o-36 p-77 d-7 o-42 p-80 d-7 i-73 o-0 p-77 d-5 o-6 p-77 d-1\n",
            "o-9 p-77 d-1 o-12 p-77 d-2 o-15 p-75 d-1 o-18 p-75 d-4 o-24 p-75 d-5 o-30 p-73 d-9 i-0 o-6 p-68 d-3\n",
            "p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65\n",
            "d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65\n",
            "d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9\n",
            "t-33 i-58 o-0 p-82 d-12 o-12 p-85 d-24 o-36 p-89 d-4 o-39 p-87 d-4 o-42 p-85 d-4 o-45 p-82 d-3 i-73\n",
            "o-12 p-75 d-6 o-18 p-73 d-1 o-21 p-73 d-7 o-27 p-70 d-11 o-42 p-70 d-1 o-45 p-70 d-3 i-0 o-6 p-70\n",
            "d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2\n",
            "p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2\n",
            "p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-6 o-36\n",
            "p-42 d-9 b-1 s-9 t-33 i-58 o-0 p-80 d-36 o-36 p-77 d-7 o-42 p-80 d-7 i-73 o-0 p-77 d-5 o-6 p-77 d-3\n",
            "o-12 p-77 d-5 o-18 p-75 d-1 o-21 p-75 d-8 o-30 p-73 d-2 o-36 p-73 d-9 i-0 o-6 p-68 d-3 p-65 d-3 p-61\n",
            "d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2\n",
            "i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2\n",
            "o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-8 o-21 p-32 d-2 o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0\n",
            "p-82 d-12 o-12 p-85 d-24 o-36 p-89 d-4 o-39 p-87 d-4 o-42 p-85 d-4 o-45 p-82 d-3 i-73 o-12 p-75 d-6\n",
            "o-18 p-73 d-2 o-21 p-73 d-9 o-30 p-70 d-11 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3\n",
            "p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2\n",
            "p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61\n",
            "d-2 i-39 o-0 p-42 d-8 o-21 p-37 d-2 o-24 p-42 d-6 o-36 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-84 d-36 o-36\n",
            "p-82 d-6 o-42 p-84 d-6 i-73 o-12 p-75 d-5 o-18 p-75 d-2 o-21 p-75 d-6 o-30 p-75 d-5 o-36 p-77 d-6\n",
            "o-42 p-78 d-8 i-0 o-6 p-68 d-2 p-63 d-2 p-60 d-1 o-18 p-68 d-2 p-63 d-2 p-60 d-1 o-30 p-68 d-2 p-63\n",
            "d-2 p-60 d-1 o-42 p-68 d-2 p-63 d-2 p-60 d-1 i-35 o-6 p-68 d-2 p-63 d-2 p-60 d-1 o-18 p-68 d-2 p-63\n",
            "d-2 p-60 d-1 o-30 p-68 d-2 p-63 d-2 p-60 d-1 o-42 p-68 d-2 p-63 d-2 p-60 d-1 i-39 o-0 p-44 d-7 o-21\n",
            "p-39 d-2 o-24 p-44 d-6 b-1 s-9 t-33 i-58 o-0 p-80 d-12 o-12 p-77 d-34 i-73 o-0 p-77 d-10 o-12 p-72\n",
            "d-13 o-36 p-77 d-6 o-42 p-75 d-3 o-45 p-73 d-7 i-0 o-6 p-68 d-2 p-65 d-2 p-60 d-1 o-18 p-68 d-2 p-65\n",
            "d-2 p-60 d-2 o-30 p-68 d-2 p-65 d-1 p-60 d-1 o-42 p-68 d-1 p-65 d-1 p-60 d-1 i-35 o-6 p-68 d-2 p-65\n",
            "d-2 p-60 d-1 o-18 p-68 d-2 p-65 d-2 p-60 d-2 o-30 p-68 d-2 p-65 d-1 p-60 d-1 o-42 p-68 d-1 p-65 d-1\n",
            "p-60 d-1 i-39 o-0 p-41 d-6 o-21 p-37 d-3 o-24 p-41 d-8 o-36 p-32 d-6 b-1 s-9 t-33 i-58 o-0 p-75 d-13\n",
            "o-12 p-77 d-13 o-24 p-78 d-12 o-36 p-82 d-11 i-73 o-6 p-70 d-9 o-30 p-70 d-6 o-36 p-78 d-6 o-42 p-77\n",
            "d-5 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-1 o-18 p-70 d-2 p-66 d-2 p-61 d-1 o-30 p-70 d-2 p-66 d-1 p-61\n",
            "d-1 o-42 p-70 d-1 p-66 d-1 p-61 d-1 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-1 o-18 p-70 d-2 p-66 d-2 p-61\n",
            "d-1 o-30 p-70 d-2 p-66 d-1 p-61 d-1 o-42 p-70 d-1 p-66 d-1 p-61 d-1 i-39 o-0 p-42 d-6 o-21 p-37 d-2\n",
            "o-24 p-42 d-7 b-1 s-9 t-33 i-58 o-0 p-80 d-12 o-12 p-82 d-13 o-24 p-84 d-11 o-36 p-87 d-11 i-73 o-0\n",
            "p-75 d-16 i-0 o-6 p-68 d-2 p-63 d-1 p-60 d-1 o-18 p-68 d-1 p-63 d-1 p-60 d-1 o-30 p-68 d-1 p-63 d-1\n",
            "p-60 d-1 o-42 p-68 d-1 p-63 d-1 p-60 d-1 i-35 o-6 p-68 d-2 p-63 d-1 p-60 d-1 o-18 p-68 d-1 p-63 d-1\n",
            "p-60 d-1 o-30 p-68 d-1 p-63 d-1 p-60 d-1 o-42 p-68 d-1 p-63 d-1 p-60 d-1 i-39 o-0 p-44 d-7 o-21 p-39\n",
            "d-2 o-24 p-44 d-9 o-36 p-32 d-7 b-1 s-9 t-33 i-72 o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2 o-36\n",
            "p-82 d-2 o-42 p-82 d-1 o-45 p-82 d-8 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6\n",
            "o-42 p-73 d-6 i-73 o-18 p-73 d-2 o-24 p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-2 o-42 p-75 d-1 o-45 p-75\n",
            "d-8 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-7 p-61 d-7 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68\n",
            "d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68\n",
            "d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-2 p-61 d-2 o-30 p-68 d-2 p-65 d-2 p-61 d-2 o-42 p-68 d-3\n",
            "p-65 d-3 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3\n",
            "p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1\n",
            "s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3\n",
            "o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-6 p-80 d-12 i-73 o-6 p-73 d-12 i-0 o-6 p-70 d-2\n",
            "p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66\n",
            "d-2 p-61 d-2 i-19 o-6 p-70 d-3 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66\n",
            "d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66\n",
            "d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21\n",
            "p-37 d-2 o-24 p-42 d-6 o-36 p-42 d-9 b-1 s-9 t-33 i-72 o-36 p-82 d-2 o-42 p-82 d-1 o-45 p-82 d-1\n",
            "i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-36 p-75 d-2 o-42\n",
            "p-75 d-1 o-45 p-75 d-1 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-7 p-61 d-7 i-0 o-6 p-68 d-3 p-65 d-3\n",
            "p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61\n",
            "d-2 i-19 o-6 p-68 d-2 p-65 d-2 p-61 d-2 o-18 p-68 d-2 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61\n",
            "d-2 o-39 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61\n",
            "d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-7 o-21 p-32 d-2\n",
            "o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85\n",
            "d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-0 p-82 d-6 o-6 p-80 d-11 i-73 o-0\n",
            "p-75 d-6 o-6 p-73 d-11 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70\n",
            "d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70\n",
            "d-3 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70\n",
            "d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2\n",
            "p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-9 o-21 p-42 d-1 o-24 p-42 d-3 o-27 p-42 d-1 o-30 p-42 d-6 o-36\n",
            "p-41 d-5 o-42 p-39 d-4 b-1 s-9 t-33 i-72 o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2 o-36 p-82 d-3\n",
            "o-42 p-82 d-2 o-45 p-82 d-8 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73\n",
            "d-6 i-73 o-18 p-73 d-2 o-24 p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-3 o-42 p-75 d-2 o-45 p-75 d-8 i-75\n",
            "o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-10 p-61 d-10 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65\n",
            "d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-3 p-65\n",
            "d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-2 p-61 d-2 o-30 p-68 d-2 p-65 d-2 p-61 d-2 o-42 p-68 d-3 p-65 d-3\n",
            "p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3\n",
            "p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9 t-33\n",
            "i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85\n",
            "d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-6 p-80 d-13 i-73 o-6 p-73 d-13 i-0 o-6 p-70 d-2 p-66 d-3 p-61\n",
            "d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2\n",
            "i-19 o-6 p-70 d-3 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2\n",
            "o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2\n",
            "o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24\n",
            "p-42 d-6 o-36 p-42 d-9 b-1 s-9 t-33 i-72 o-18 p-80 d-1 o-21 p-80 d-2 o-24 p-80 d-2 o-27 p-80 d-1\n",
            "o-30 p-80 d-2 o-33 p-80 d-1 o-36 p-82 d-2 o-42 p-82 d-2 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78\n",
            "d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-18 p-73 d-1 o-21 p-73 d-2 o-24 p-73 d-2 o-27 p-73 d-1 o-30\n",
            "p-73 d-2 o-33 p-73 d-1 o-36 p-75 d-2 o-42 p-75 d-2 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-10 p-61\n",
            "d-10 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61\n",
            "d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-2 p-65 d-2 p-61 d-2 o-18 p-68 d-2 p-65 d-3 p-61\n",
            "d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-39 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61\n",
            "d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2\n",
            "i-39 o-0 p-37 d-7 o-15 p-32 d-2 o-18 p-34 d-2 o-21 p-32 d-2 p-32 d-1 o-24 p-37 d-7 b-1 s-9 t-33 i-58\n",
            "o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2\n",
            "o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-0 p-82 d-6 o-6 p-80 d-12 i-73 o-0 p-75 d-6 o-6 p-73 d-12 i-0 o-6\n",
            "p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70\n",
            "d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-3 p-66 d-2 p-61 d-2 o-30 p-70\n",
            "d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70\n",
            "d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42\n",
            "d-9 o-21 p-37 d-3 o-24 p-42 d-5 o-30 p-46 d-7 o-36 p-44 d-6 o-42 p-41 d-5 b-1 s-9 t-33 i-58 o-0 p-85\n",
            "d-48 i-73 o-0 p-77 d-5 o-6 p-77 d-1 o-9 p-77 d-1 o-12 p-77 d-2 o-15 p-75 d-1 o-18 p-75 d-4 o-24 p-75\n",
            "d-5 o-30 p-73 d-9 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3\n",
            "p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3\n",
            "p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9\n",
            "b-1 s-9 t-33 i-58 o-0 p-78 d-48 i-73 o-12 p-75 d-6 o-18 p-73 d-1 o-21 p-73 d-7 o-27 p-70 d-11 o-42\n",
            "p-70 d-1 o-45 p-70 d-3 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70\n",
            "d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70\n",
            "d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-45 p-32\n",
            "d-3 b-1 s-9 t-33 i-73 o-0 p-77 d-5 o-6 p-77 d-3 o-12 p-77 d-5 o-18 p-75 d-1 o-21 p-75 d-8 o-30 p-73\n",
            "d-2 o-36 p-73 d-9 i-58 o-0 p-73 d-48 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61\n",
            "d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61\n",
            "d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2\n",
            "i-39 o-0 p-37 d-8 b-1 s-9 t-33 i-58 o-0 p-97 d-48 i-73 o-12 p-75 d-6 o-18 p-73 d-2 o-21 p-73 d-9\n",
            "o-30 p-70 d-11 i-0 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-42 p-70 d-2 p-66 d-2 p-61 d-2 b-1 s-9 t-33\n",
            "i-73 o-12 p-75 d-5 o-18 p-75 d-2 o-21 p-75 d-6 o-30 p-75 d-5 o-36 p-77 d-6 o-42 p-78 d-8 i-19 o-0\n",
            "p-68 d-47 p-63 d-46 p-60 d-47 i-0 o-6 p-68 d-2 p-63 d-2 p-60 d-1 o-18 p-68 d-2 p-63 d-2 p-60 d-1\n",
            "o-30 p-68 d-2 p-63 d-2 p-60 d-1 o-42 p-68 d-2 p-63 d-2 p-60 d-1 i-35 o-6 p-68 d-2 p-63 d-2 p-60 d-1\n",
            "o-18 p-68 d-2 p-63 d-2 p-60 d-1 o-30 p-68 d-2 p-63 d-2 p-60 d-1 o-42 p-68 d-2 p-63 d-2 p-60 d-1 i-39\n",
            "o-0 p-44 d-7 o-21 p-39 d-2 o-24 p-44 d-6 b-1 s-9 t-33 i-73 o-0 p-77 d-10 o-12 p-72 d-13 o-36 p-77\n",
            "d-6 o-42 p-75 d-3 o-45 p-73 d-7 i-19 o-0 p-68 d-46 p-65 d-46 p-60 d-45 i-0 o-6 p-68 d-2 p-65 d-2\n",
            "p-60 d-1 o-18 p-68 d-2 p-65 d-2 p-60 d-2 o-30 p-68 d-2 p-65 d-1 p-60 d-1 o-42 p-68 d-1 p-65 d-1 p-60\n",
            "d-1 i-35 o-6 p-68 d-2 p-65 d-2 p-60 d-1 o-18 p-68 d-2 p-65 d-2 p-60 d-2 o-30 p-68 d-2 p-65 d-1 p-60\n",
            "d-1 o-42 p-68 d-1 p-65 d-1 p-60 d-1 i-39 o-0 p-41 d-6 o-21 p-37 d-3 o-24 p-41 d-8 o-36 p-32 d-6 b-1\n",
            "s-9 t-33 i-73 o-6 p-70 d-9 o-30 p-70 d-6 o-36 p-78 d-6 o-42 p-77 d-5 i-19 o-0 p-70 d-47 p-66 d-47\n",
            "p-61 d-47 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-1 o-18 p-70 d-2 p-66 d-2 p-61 d-1 o-30 p-70 d-2 p-66 d-1\n",
            "p-61 d-1 o-42 p-70 d-1 p-66 d-1 p-61 d-1 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-1 o-18 p-70 d-2 p-66 d-2\n",
            "p-61 d-1 o-30 p-70 d-2 p-66 d-1 p-61 d-1 o-42 p-70 d-1 p-66 d-1 p-61 d-1 i-39 o-0 p-42 d-6 o-21 p-37\n",
            "d-2 o-24 p-42 d-7 b-1 s-9 t-33 i-73 o-0 p-75 d-16 i-19 o-0 p-68 d-44 p-63 d-44 p-60 d-44 i-0 o-6\n",
            "p-68 d-2 p-63 d-1 p-60 d-1 o-18 p-68 d-1 p-63 d-1 p-60 d-1 o-30 p-68 d-1 p-63 d-1 p-60 d-1 o-42 p-68\n",
            "d-1 p-63 d-1 p-60 d-1 i-35 o-6 p-68 d-2 p-63 d-1 p-60 d-1 o-18 p-68 d-1 p-63 d-1 p-60 d-1 o-30 p-68\n",
            "d-1 p-63 d-1 p-60 d-1 o-42 p-68 d-1 p-63 d-1 p-60 d-1 i-39 o-0 p-44 d-7 o-21 p-39 d-2 o-24 p-44 d-9\n",
            "o-36 p-32 d-7 b-1 s-9 t-33 i-72 o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2 o-36 p-82 d-2 o-42 p-82\n",
            "d-1 o-45 p-82 d-8 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73\n",
            "o-18 p-73 d-2 o-24 p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-2 o-42 p-75 d-1 o-45 p-75 d-8 i-75 o-0 p-77\n",
            "d-5 p-65 d-6 o-6 p-73 d-7 p-61 d-7 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61\n",
            "d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-3 p-65 d-3 p-61\n",
            "d-2 o-18 p-68 d-3 p-65 d-2 p-61 d-2 o-30 p-68 d-2 p-65 d-2 p-61 d-2 o-42 p-68 d-3 p-65 d-3 p-61 d-2\n",
            "i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2\n",
            "o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9 t-33 i-58 o-0\n",
            "p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42\n",
            "p-89 d-4 o-45 p-85 d-2 i-72 o-6 p-80 d-12 i-73 o-6 p-73 d-12 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18\n",
            "p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6\n",
            "p-70 d-3 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70\n",
            "d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70\n",
            "d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-6\n",
            "o-36 p-42 d-9 b-1 s-9 t-33 i-72 o-36 p-82 d-2 o-42 p-82 d-1 o-45 p-82 d-1 i-58 o-0 p-73 d-25 o-24\n",
            "p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-36 p-75 d-2 o-42 p-75 d-1 o-45 p-75 d-1\n",
            "i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-7 p-61 d-7 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3\n",
            "p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-2\n",
            "p-65 d-2 p-61 d-2 o-18 p-68 d-2 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-39 p-68 d-3 p-65\n",
            "d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65\n",
            "d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-7 o-21 p-32 d-2 o-24 p-37 d-7 b-1 s-9\n",
            "t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39\n",
            "p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-0 p-82 d-6 o-6 p-80 d-11 i-73 o-0 p-75 d-6 o-6 p-73 d-11\n",
            "i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2\n",
            "o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-3 p-66 d-2 p-61 d-2\n",
            "o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2\n",
            "o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39\n",
            "o-0 p-42 d-9 o-21 p-42 d-1 o-24 p-42 d-3 o-27 p-42 d-1 o-30 p-42 d-6 o-36 p-41 d-5 o-42 p-39 d-4 b-1\n",
            "s-9 t-33 i-72 o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2 o-36 p-82 d-3 o-42 p-82 d-2 o-45 p-82 d-8\n",
            "i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-18 p-73 d-2 o-24\n",
            "p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-3 o-42 p-75 d-2 o-45 p-75 d-8 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73\n",
            "d-10 p-61 d-10 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65\n",
            "d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65\n",
            "d-2 p-61 d-2 o-30 p-68 d-2 p-65 d-2 p-61 d-2 o-42 p-68 d-3 p-65 d-3 p-61 d-2 i-35 o-6 p-68 d-3 p-65\n",
            "d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2\n",
            "p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3\n",
            "o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2\n",
            "i-72 o-6 p-80 d-13 i-73 o-6 p-73 d-13 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61\n",
            "d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-3 p-66 d-3 p-61\n",
            "d-2 o-18 p-70 d-2 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2\n",
            "i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2\n",
            "o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-6 o-36 p-42 d-9 b-1 s-9\n",
            "t-33 i-72 o-18 p-80 d-1 o-21 p-80 d-2 o-24 p-80 d-2 o-27 p-80 d-1 o-30 p-80 d-2 o-33 p-80 d-1 o-36\n",
            "p-82 d-2 o-42 p-82 d-2 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6\n",
            "i-73 o-18 p-73 d-1 o-21 p-73 d-2 o-24 p-73 d-2 o-27 p-73 d-1 o-30 p-73 d-2 o-33 p-73 d-1 o-36 p-75\n",
            "d-2 o-42 p-75 d-2 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-10 p-61 d-10 i-0 o-6 p-68 d-3 p-65 d-3 p-61\n",
            "d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2\n",
            "i-19 o-6 p-68 d-2 p-65 d-2 p-61 d-2 o-18 p-68 d-2 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2\n",
            "o-39 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2\n",
            "o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-7 o-15 p-32 d-2 o-18\n",
            "p-34 d-2 o-21 p-32 d-2 p-32 d-1 o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27\n",
            "p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72\n",
            "o-0 p-82 d-6 o-6 p-80 d-12 i-73 o-0 p-75 d-6 o-6 p-73 d-12 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18\n",
            "p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6\n",
            "p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-3 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70\n",
            "d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70\n",
            "d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-9 o-21 p-37 d-3 o-24 p-42 d-5\n",
            "o-30 p-46 d-7 o-36 p-44 d-6 o-42 p-41 d-5 b-1 s-9 t-33 i-72 o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80\n",
            "d-2 o-36 p-82 d-2 o-42 p-82 d-1 o-45 p-82 d-8 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36\n",
            "p-80 d-6 o-42 p-73 d-6 i-73 o-18 p-73 d-2 o-24 p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-2 o-42 p-75 d-1\n",
            "o-45 p-75 d-8 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-7 p-61 d-7 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3\n",
            "o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19\n",
            "o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-2 p-61 d-2 o-30 p-68 d-2 p-65 d-2 p-61 d-2 o-42\n",
            "p-68 d-3 p-65 d-3 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30\n",
            "p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37\n",
            "d-6 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36\n",
            "p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-6 p-80 d-12 i-73 o-6 p-73 d-12 i-0 o-6\n",
            "p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70\n",
            "d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-3 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-2 p-61 d-2 o-30 p-70\n",
            "d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70\n",
            "d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42\n",
            "d-6 o-21 p-37 d-2 o-24 p-42 d-6 o-36 p-42 d-9 b-1 s-9 t-33 i-72 o-36 p-82 d-2 o-42 p-82 d-1 o-45\n",
            "p-82 d-1 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-36 p-75\n",
            "d-2 o-42 p-75 d-1 o-45 p-75 d-1 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-7 p-61 d-7 i-0 o-6 p-68 d-3\n",
            "p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65\n",
            "d-2 p-61 d-2 i-19 o-6 p-68 d-2 p-65 d-2 p-61 d-2 o-18 p-68 d-2 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65\n",
            "d-3 p-61 d-2 o-39 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65\n",
            "d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-7 o-21\n",
            "p-32 d-2 o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4\n",
            "o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-0 p-82 d-6 o-6 p-80\n",
            "d-11 i-73 o-0 p-75 d-6 o-6 p-73 d-11 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61\n",
            "d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-2 p-66 d-2 p-61\n",
            "d-2 o-18 p-70 d-3 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2\n",
            "i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2\n",
            "o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-9 o-21 p-42 d-1 o-24 p-42 d-3 o-27 p-42 d-1 o-30\n",
            "p-42 d-6 o-36 p-41 d-5 o-42 p-39 d-4 b-1 s-9 t-33 i-72 o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2\n",
            "o-36 p-82 d-3 o-42 p-82 d-2 o-45 p-82 d-8 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80\n",
            "d-6 o-42 p-73 d-6 i-73 o-18 p-73 d-2 o-24 p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-3 o-42 p-75 d-2 o-45\n",
            "p-75 d-8 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-10 p-61 d-10 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18\n",
            "p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6\n",
            "p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-2 p-61 d-2 o-30 p-68 d-2 p-65 d-2 p-61 d-2 o-42 p-68\n",
            "d-3 p-65 d-3 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68\n",
            "d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6\n",
            "b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89\n",
            "d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-6 p-80 d-13 i-73 o-6 p-73 d-13 i-0 o-6 p-70 d-2\n",
            "p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66\n",
            "d-2 p-61 d-2 i-19 o-6 p-70 d-3 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66\n",
            "d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66\n",
            "d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21\n",
            "p-37 d-2 o-24 p-42 d-6 o-36 p-42 d-9 b-1 s-9 t-33 i-72 o-18 p-80 d-1 o-21 p-80 d-2 o-24 p-80 d-2\n",
            "o-27 p-80 d-1 o-30 p-80 d-2 o-33 p-80 d-1 o-36 p-82 d-2 o-42 p-82 d-2 i-58 o-0 p-73 d-25 o-24 p-77\n",
            "d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-18 p-73 d-1 o-21 p-73 d-2 o-24 p-73 d-2 o-27\n",
            "p-73 d-1 o-30 p-73 d-2 o-33 p-73 d-1 o-36 p-75 d-2 o-42 p-75 d-2 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73\n",
            "d-10 p-61 d-10 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65\n",
            "d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-2 p-65 d-2 p-61 d-2 o-18 p-68 d-2 p-65\n",
            "d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-39 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65\n",
            "d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2\n",
            "p-61 d-2 i-39 o-0 p-37 d-7 o-15 p-32 d-2 o-18 p-34 d-2 o-21 p-32 d-2 p-32 d-1 o-24 p-37 d-7 b-1 s-9\n",
            "t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39\n",
            "p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-0 p-82 d-6 o-6 p-80 d-12 i-73 o-0 p-75 d-6 o-6 p-73 d-12\n",
            "i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2\n",
            "o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-3 p-66 d-2 p-61 d-2\n",
            "o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2\n",
            "o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39\n",
            "o-0 p-42 d-9 o-21 p-37 d-3 o-24 p-42 d-5 o-30 p-46 d-7 o-36 p-44 d-6 o-42 p-41 d-5 b-1 s-9 t-33 i-72\n",
            "o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2 o-36 p-82 d-2 o-42 p-82 d-1 o-45 p-82 d-8 i-73 o-18 p-73\n",
            "d-2 o-24 p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-2 o-42 p-75 d-1 o-45 p-75 d-8 i-75 o-0 p-77 d-5 p-65 d-6\n",
            "o-6 p-73 d-7 p-61 d-7 i-39 o-0 p-37 d-11 b-1 s-9 t-33 i-72 o-6 p-80 d-12 i-73 o-6 p-73 d-12 b-1 s-9\n",
            "t-33 i-72 o-36 p-82 d-2 o-42 p-82 d-1 o-45 p-82 d-1 i-73 o-36 p-75 d-2 o-42 p-75 d-1 o-45 p-75 d-1\n",
            "i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-7 p-61 d-7 b-1 s-9 t-33 i-72 o-0 p-82 d-6 o-6 p-80 d-11 i-73\n",
            "o-0 p-75 d-6 o-6 p-73 d-11 b-1 s-9 t-33 i-72 o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2 o-36 p-82 d-3\n",
            "o-42 p-82 d-2 o-45 p-82 d-8 i-73 o-18 p-73 d-2 o-24 p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-3 o-42 p-75\n",
            "d-2 o-45 p-75 d-8 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-10 p-61 d-10 b-1 s-9 t-33 i-72 o-6 p-80 d-13\n",
            "i-73 o-6 p-73 d-13 b-1 s-9 t-33 i-72 o-18 p-80 d-1 o-21 p-80 d-2 o-24 p-80 d-2 o-27 p-80 d-1 o-30\n",
            "p-80 d-2 o-33 p-80 d-1 o-36 p-82 d-2 o-42 p-82 d-2 i-73 o-18 p-73 d-1 o-21 p-73 d-2 o-24 p-73 d-2\n",
            "o-27 p-73 d-1 o-30 p-73 d-2 o-33 p-73 d-1 o-36 p-75 d-2 o-42 p-75 d-2 i-75 o-0 p-77 d-5 p-65 d-6 o-6\n",
            "p-73 d-10 p-61 d-10 b-1 s-9 t-33 i-72 o-0 p-82 d-6 o-6 p-80 d-12 i-73 o-0 p-75 d-6 o-6 p-73 d-12 b-1\n",
            "s-9 t-33 i-72 o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2 o-36 p-82 d-2 o-42 p-82 d-1 o-45 p-82 d-8\n",
            "i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-18 p-73 d-2 o-24\n",
            "p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-2 o-42 p-75 d-1 o-45 p-75 d-8 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73\n",
            "d-7 p-61 d-7 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65\n",
            "d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65\n",
            "d-2 p-61 d-2 o-30 p-68 d-2 p-65 d-2 p-61 d-2 o-42 p-68 d-3 p-65 d-3 p-61 d-2 i-35 o-6 p-68 d-3 p-65\n",
            "d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2\n",
            "p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3\n",
            "o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2\n",
            "i-72 o-6 p-80 d-12 i-73 o-6 p-73 d-12 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61\n",
            "d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-3 p-66 d-3 p-61\n",
            "d-2 o-18 p-70 d-2 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2\n",
            "i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2\n",
            "o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-6 o-36 p-42 d-9 b-1 s-9\n",
            "t-33 i-72 o-36 p-82 d-2 o-42 p-82 d-1 o-45 p-82 d-1 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7\n",
            "o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-36 p-75 d-2 o-42 p-75 d-1 o-45 p-75 d-1 i-75 o-0 p-77 d-5 p-65\n",
            "d-6 o-6 p-73 d-7 p-61 d-7 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30\n",
            "p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-2 p-65 d-2 p-61 d-2 o-18\n",
            "p-68 d-2 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-39 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6\n",
            "p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68\n",
            "d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-7 o-21 p-32 d-2 o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-78 d-22\n",
            "o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4\n",
            "o-45 p-85 d-2 i-72 o-0 p-82 d-6 o-6 p-80 d-11 i-73 o-0 p-75 d-6 o-6 p-73 d-11 i-0 o-6 p-70 d-2 p-66\n",
            "d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2\n",
            "p-61 d-2 i-19 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-3 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-2\n",
            "p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3\n",
            "p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-9 o-21 p-42\n",
            "d-1 o-24 p-42 d-3 o-27 p-42 d-1 o-30 p-42 d-6 o-36 p-41 d-5 o-42 p-39 d-4 b-1 s-9 t-33 i-72 o-18\n",
            "p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2 o-36 p-82 d-3 o-42 p-82 d-2 o-45 p-82 d-8 i-58 o-0 p-73 d-25\n",
            "o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-18 p-73 d-2 o-24 p-73 d-2 o-30 p-73\n",
            "d-2 o-36 p-75 d-3 o-42 p-75 d-2 o-45 p-75 d-8 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-10 p-61 d-10 i-0\n",
            "o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42\n",
            "p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-2 p-61 d-2 o-30\n",
            "p-68 d-2 p-65 d-2 p-61 d-2 o-42 p-68 d-3 p-65 d-3 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18\n",
            "p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0\n",
            "p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2\n",
            "o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-6 p-80\n",
            "d-13 i-73 o-6 p-73 d-13 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70\n",
            "d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-3 p-66 d-3 p-61 d-2 o-18 p-70\n",
            "d-2 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70\n",
            "d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2\n",
            "p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-6 o-36 p-42 d-9 b-1 s-9 t-33 i-72 o-18\n",
            "p-80 d-1 o-21 p-80 d-2 o-24 p-80 d-2 o-27 p-80 d-1 o-30 p-80 d-2 o-33 p-80 d-1 o-36 p-82 d-2 o-42\n",
            "p-82 d-2 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-18 p-73\n",
            "d-1 o-21 p-73 d-2 o-24 p-73 d-2 o-27 p-73 d-1 o-30 p-73 d-2 o-33 p-73 d-1 o-36 p-75 d-2 o-42 p-75\n",
            "d-2 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-10 p-61 d-10 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68\n",
            "d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68\n",
            "d-2 p-65 d-2 p-61 d-2 o-18 p-68 d-2 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-39 p-68 d-3\n",
            "p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3\n",
            "p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-7 o-15 p-32 d-2 o-18 p-34 d-2 o-21\n",
            "p-32 d-2 p-32 d-1 o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30\n",
            "p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-0 p-82 d-6 o-6\n",
            "p-80 d-12 i-73 o-0 p-75 d-6 o-6 p-73 d-12 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3\n",
            "p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-2 p-66 d-2\n",
            "p-61 d-2 o-18 p-70 d-3 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61\n",
            "d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61\n",
            "d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-9 o-21 p-37 d-3 o-24 p-42 d-5 o-30 p-46 d-7 o-36\n",
            "p-44 d-6 o-42 p-41 d-5 b-1 s-9 t-33 i-72 o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2 o-36 p-82 d-2\n",
            "o-42 p-82 d-1 o-45 p-82 d-8 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73\n",
            "d-6 i-73 o-18 p-73 d-2 o-24 p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-2 o-42 p-75 d-1 o-45 p-75 d-8 i-75\n",
            "o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-7 p-61 d-7 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65\n",
            "d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-3 p-65\n",
            "d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-2 p-61 d-2 o-30 p-68 d-2 p-65 d-2 p-61 d-2 o-42 p-68 d-3 p-65 d-3\n",
            "p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3\n",
            "p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9 t-33\n",
            "i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85\n",
            "d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-6 p-80 d-12 i-73 o-6 p-73 d-12 i-0 o-6 p-70 d-2 p-66 d-3 p-61\n",
            "d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2\n",
            "i-19 o-6 p-70 d-3 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2\n",
            "o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2\n",
            "o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24\n",
            "p-42 d-6 o-36 p-42 d-9 b-1 s-9 t-33 i-72 o-36 p-82 d-2 o-42 p-82 d-1 o-45 p-82 d-1 i-58 o-0 p-73\n",
            "d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-36 p-75 d-2 o-42 p-75 d-1 o-45\n",
            "p-75 d-1 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-7 p-61 d-7 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18\n",
            "p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6\n",
            "p-68 d-2 p-65 d-2 p-61 d-2 o-18 p-68 d-2 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-39 p-68\n",
            "d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68\n",
            "d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-7 o-21 p-32 d-2 o-24 p-37 d-7\n",
            "b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89\n",
            "d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-0 p-82 d-6 o-6 p-80 d-11 i-73 o-0 p-75 d-6 o-6\n",
            "p-73 d-11 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3\n",
            "p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-3 p-66 d-2\n",
            "p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2\n",
            "p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61\n",
            "d-2 i-39 o-0 p-42 d-9 o-21 p-42 d-1 o-24 p-42 d-3 o-27 p-42 d-1 o-30 p-42 d-6 o-36 p-41 d-5 o-42\n",
            "p-39 d-4 b-1 s-9 t-33 i-72 o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2 o-36 p-82 d-3 o-42 p-82 d-2\n",
            "o-45 p-82 d-8 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-18\n",
            "p-73 d-2 o-24 p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-3 o-42 p-75 d-2 o-45 p-75 d-8 i-75 o-0 p-77 d-5\n",
            "p-65 d-6 o-6 p-73 d-10 p-61 d-10 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2\n",
            "o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-3 p-65 d-3 p-61 d-2\n",
            "o-18 p-68 d-3 p-65 d-2 p-61 d-2 o-30 p-68 d-2 p-65 d-2 p-61 d-2 o-42 p-68 d-3 p-65 d-3 p-61 d-2 i-35\n",
            "o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42\n",
            "p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9 t-33 i-58 o-0 p-78\n",
            "d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89\n",
            "d-4 o-45 p-85 d-2 i-72 o-6 p-80 d-13 i-73 o-6 p-73 d-13 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70\n",
            "d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70\n",
            "d-3 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2\n",
            "p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2\n",
            "p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-6 o-36\n",
            "p-42 d-9 b-1 s-9 t-33 i-72 o-18 p-80 d-1 o-21 p-80 d-2 o-24 p-80 d-2 o-27 p-80 d-1 o-30 p-80 d-2\n",
            "o-33 p-80 d-1 o-36 p-82 d-2 o-42 p-82 d-2 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80\n",
            "d-6 o-42 p-73 d-6 i-73 o-18 p-73 d-1 o-21 p-73 d-2 o-24 p-73 d-2 o-27 p-73 d-1 o-30 p-73 d-2 o-33\n",
            "p-73 d-1 o-36 p-75 d-2 o-42 p-75 d-2 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-10 p-61 d-10 i-0 o-6 p-68\n",
            "d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3\n",
            "p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-2 p-65 d-2 p-61 d-2 o-18 p-68 d-2 p-65 d-3 p-61 d-2 o-30 p-68 d-3\n",
            "p-65 d-3 p-61 d-2 o-39 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3\n",
            "p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-7\n",
            "o-15 p-32 d-2 o-18 p-34 d-2 o-21 p-32 d-2 p-32 d-1 o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-78 d-22\n",
            "o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4\n",
            "o-45 p-85 d-2 i-72 o-0 p-82 d-6 o-6 p-80 d-12 i-73 o-0 p-75 d-6 o-6 p-73 d-12 i-0 o-6 p-70 d-2 p-66\n",
            "d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2\n",
            "p-61 d-2 i-19 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-3 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-2\n",
            "p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3\n",
            "p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-9 o-21 p-37\n",
            "d-3 o-24 p-42 d-5 o-30 p-46 d-7 o-36 p-44 d-6 o-42 p-41 d-5 b-1 s-9 t-33 i-72 o-18 p-80 d-2 o-24\n",
            "p-80 d-2 o-30 p-80 d-2 o-36 p-82 d-2 o-42 p-82 d-1 o-45 p-82 d-8 i-73 o-18 p-73 d-2 o-24 p-73 d-2\n",
            "o-30 p-73 d-2 o-36 p-75 d-2 o-42 p-75 d-1 o-45 p-75 d-8 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-7 p-61\n",
            "d-7 i-39 o-0 p-37 d-9 b-1 s-9 t-33 i-72 o-6 p-80 d-12 i-73 o-6 p-73 d-12 b-1\n"
          ]
        }
      ],
      "source": [
        "# Convert to REMI-z format\n",
        "import textwrap\n",
        "\n",
        "clip = mt\n",
        "print(type(clip))\n",
        "remiz_format = clip.to_remiz_str(\n",
        "    with_ts=True,\n",
        "    with_tempo=True,\n",
        "    with_velocity=False\n",
        "    )\n",
        "print(type(remiz_format))\n",
        "print(f\"Number of tokens in REMI-z string: {len(remiz_format.split())}\")\n",
        "\n",
        "wrapped_output = textwrap.fill(remiz_format, width=100)\n",
        "print(wrapped_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69U-S-lw-L1E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5r96oBej-Luw"
      },
      "outputs": [],
      "source": [
        "mt = MultiTrack.from_midi(midi_fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qP1-3cI-Lgw",
        "outputId": "e8f0b019-b147-4adf-b932-819e7ec78af5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original MultiTrack: 83 bars\n",
            "Filtered MultiTrack (non-empty bars): 82 bars\n"
          ]
        }
      ],
      "source": [
        "from remi_z import MultiTrack\n",
        "\n",
        "def filter_empty_bars(multi_track_obj):\n",
        "    non_empty_bars = []\n",
        "\n",
        "    # Iterate through each bar of the input MultiTrack object\n",
        "    for bar_index in range(len(multi_track_obj)):\n",
        "        bar = multi_track_obj[bar_index]\n",
        "\n",
        "        # Check if the current bar contains any instruments\n",
        "        if len(bar) > 0:\n",
        "            non_empty_bars.append(bar)\n",
        "\n",
        "    # Create a new MultiTrack object from the non_empty_bars list\n",
        "    new_multi_track = MultiTrack(non_empty_bars)\n",
        "\n",
        "    return new_multi_track\n",
        "\n",
        "print(f\"Original MultiTrack: {len(mt)} bars\")\n",
        "filtered_mt = filter_empty_bars(mt)\n",
        "print(f\"Filtered MultiTrack (non-empty bars): {len(filtered_mt)} bars\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUVhTO5z-LeX",
        "outputId": "ad993581-bd28-4bbf-d9ed-1bd08c49cbc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of bars in filtered MultiTrack: 82\n",
            "Number of 8-bar segments created: 11\n",
            "Segment 1 has 8 bars\n",
            "Segment 2 has 8 bars\n",
            "Segment 3 has 8 bars\n",
            "Segment 4 has 8 bars\n",
            "Segment 5 has 8 bars\n",
            "Segment 6 has 8 bars\n",
            "Segment 7 has 8 bars\n",
            "Segment 8 has 8 bars\n",
            "Segment 9 has 8 bars\n",
            "Segment 10 has 8 bars\n",
            "Segment 11 has 2 bars\n"
          ]
        }
      ],
      "source": [
        "def segment_into_n_bars(multi_track_obj, n):\n",
        "    segmented_tracks = []\n",
        "    num_bars = len(multi_track_obj)\n",
        "\n",
        "    for i in range(0, num_bars, n):\n",
        "        # Extract a segment of bars. Access the .bars attribute to get the list of Bar objects.\n",
        "        segment_multi_track = multi_track_obj[i : i + n]\n",
        "        segment_bars = segment_multi_track.bars\n",
        "\n",
        "        # Create a new MultiTrack object for this segment\n",
        "        segmented_track = MultiTrack(segment_bars)\n",
        "        segmented_tracks.append(segmented_track)\n",
        "\n",
        "    return segmented_tracks\n",
        "\n",
        "\n",
        "print(f\"Number of bars in filtered MultiTrack: {len(filtered_mt)}\")\n",
        "segmented_list = segment_into_n_bars(filtered_mt, 8)\n",
        "print(f\"Number of 8-bar segments created: {len(segmented_list)}\")\n",
        "\n",
        "# Print the number of bars in each segment to verify\n",
        "for i, segment in enumerate(segmented_list):\n",
        "    print(f\"Segment {i+1} has {len(segment)} bars\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnJ9VcJS-Lbn",
        "outputId": "375e1e59-83ef-4f06-87dc-ad373927b8c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "REMI-z string representation of the first 8-bar segment:\n",
            "Number of tokens in the first segment's REMI-z string: 779\n",
            "s-9 t-33 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-0 o-6 p-68 d-3\n",
            "p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65\n",
            "d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65\n",
            "d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9\n",
            "t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39\n",
            "p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61\n",
            "d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61\n",
            "d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2\n",
            "i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-6 o-36 p-42 d-9 b-1 s-9 t-33 i-58 o-0 p-73 d-25 o-24\n",
            "p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3\n",
            "p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3\n",
            "p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65\n",
            "d-2 p-61 d-2 i-39 o-0 p-37 d-7 o-21 p-32 d-2 o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89\n",
            "d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85\n",
            "d-2 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61\n",
            "d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61\n",
            "d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-9 o-21 p-42 d-1\n",
            "o-24 p-42 d-3 o-27 p-42 d-1 o-30 p-42 d-6 o-36 p-41 d-5 o-42 p-39 d-4 b-1 s-9 t-33 i-58 o-0 p-73\n",
            "d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18\n",
            "p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6\n",
            "p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68\n",
            "d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9 t-33 i-58 o-0 p-78 d-22\n",
            "o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4\n",
            "o-45 p-85 d-2 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66\n",
            "d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66\n",
            "d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21\n",
            "p-37 d-2 o-24 p-42 d-6 o-36 p-42 d-9 b-1 s-9 t-33 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7\n",
            "o-36 p-80 d-6 o-42 p-73 d-6 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30\n",
            "p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18\n",
            "p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0\n",
            "p-37 d-7 o-15 p-32 d-2 o-18 p-34 d-2 o-21 p-32 d-2 p-32 d-1 o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-78\n",
            "d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89\n",
            "d-4 o-45 p-85 d-2 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2\n",
            "p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2\n",
            "p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-9\n",
            "o-21 p-37 d-3 o-24 p-42 d-9 o-36 p-42 d-5 o-39 p-43 d-3 o-42 p-44 d-5 b-1\n"
          ]
        }
      ],
      "source": [
        "import textwrap\n",
        "\n",
        "# Convert the first 8-bar segment to its REMI-z string representation\n",
        "first_segment = segmented_list[0]\n",
        "first_segment_remiz_str = first_segment.to_remiz_str(\n",
        "    with_ts=True,\n",
        "    with_tempo=True,\n",
        "    with_velocity=False\n",
        ")\n",
        "\n",
        "print(\"\\nREMI-z string representation of the first 8-bar segment:\")\n",
        "print(f\"Number of tokens in the first segment's REMI-z string: {len(first_segment_remiz_str.split())}\")\n",
        "wrapped_output_first_segment = textwrap.fill(first_segment_remiz_str, width=100)\n",
        "print(wrapped_output_first_segment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGqxtY_CuUGP"
      },
      "outputs": [],
      "source": [
        "# def create_classification_samples(midi_fp, labels):\n",
        "\n",
        "#     label_vector = [0] * NUM_CLASSES\n",
        "#     for genre in labels:\n",
        "#         if genre in GENRE_TO_INDEX:\n",
        "#             label_vector[GENRE_TO_INDEX[genre]] = 1\n",
        "\n",
        "#     mt = MultiTrack.from_midi(midi_fp)\n",
        "#     filtered_mt = filter_empty_bars(mt)\n",
        "#     bar_segments = segment_into_n_bars(filtered_mt, 8)\n",
        "\n",
        "#     final_dataset = []\n",
        "#     for segment in bar_segments:\n",
        "#         segment_remiz_str = segment.to_remiz_str(\n",
        "#             with_ts=True,\n",
        "#             with_tempo=True,\n",
        "#             with_velocity=False\n",
        "#         )\n",
        "#         final_dataset.append({\n",
        "#             \"input\": segment_remiz_str,\n",
        "#             \"labels\": label_vector\n",
        "#             })\n",
        "\n",
        "#     return final_dataset\n",
        "\n",
        "# create_classification_samples(midi_fp, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezWP4D8MuT9G"
      },
      "outputs": [],
      "source": [
        "# from tqdm import tqdm\n",
        "\n",
        "# classification_samples = []\n",
        "\n",
        "# for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Genrating Classification samples\"):\n",
        "#     midi_fp = \"/content/\" + row['location']\n",
        "#     labels = row['genre']\n",
        "\n",
        "#     samples = create_classification_samples(midi_fp, labels)\n",
        "#     classification_samples.extend(samples)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsHnwIWlH8fj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "NLC-U1LIH26f",
        "outputId": "19f4b208-8466-4456-b704-94379a8dffba"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'s-9 t-33 b-1 s-9 t-33 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-6 o-36 p-42 d-9 b-1 s-9 t-33 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-7 o-21 p-32 d-2 o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-9 o-21 p-42 d-1 o-24 p-42 d-3 o-27 p-42 d-1 o-30 p-42 d-6 o-36 p-41 d-5 o-42 p-39 d-4 b-1 s-9 t-33 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-6 o-36 p-42 d-9 b-1 s-9 t-33 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-7 o-15 p-32 d-2 o-18 p-34 d-2 o-21 p-32 d-2 p-32 d-1 o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-9 o-21 p-37 d-3 o-24 p-42 d-9 o-36 p-42 d-5 o-39 p-43 d-3 o-42 p-44 d-5 b-1 s-9 t-33 i-73 o-0 p-77 d-5 o-6 p-77 d-1 o-9 p-77 d-1 o-12 p-77 d-2 o-15 p-75 d-1 o-18 p-75 d-4 o-24 p-75 d-5 o-30 p-73 d-9 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-102 o-0 p-61 d-1 p-56 d-2 p-53 d-1 i-39 o-0 p-37 d-7 b-1 s-9 t-33 i-73 o-12 p-75 d-6 o-18 p-73 d-1 o-21 p-73 d-7 o-27 p-70 d-11 o-42 p-70 d-1 o-45 p-70 d-3 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-102 o-0 p-66 d-1 p-61 d-1 p-58 d-1 i-39 o-0 p-42 d-9 b-1 s-9 t-33 i-73 o-0 p-77 d-5 o-6 p-77 d-3 o-12 p-77 d-5 o-18 p-75 d-1 o-21 p-75 d-8 o-30 p-73 d-2 o-36 p-73 d-9 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-102 o-0 p-61 d-1 p-56 d-1 p-53 d-1 i-39 o-0 p-37 d-8 o-21 p-32 d-2 o-24 p-37 d-7 b-1 s-9 t-33 i-73 o-12 p-75 d-6 o-18 p-73 d-2 o-21 p-73 d-9 o-30 p-70 d-11 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-102 o-0 p-66 d-2 p-61 d-1 p-58 d-1 i-39 o-0 p-42 d-8 o-21 p-37 d-2 o-24 p-42 d-6 o-36 p-37 d-7 b-1 s-9 t-33 i-73 o-12 p-75 d-5 o-18 p-75 d-2 o-21 p-75 d-6 o-30 p-75 d-5 o-36 p-77 d-6 o-42 p-78 d-8 i-19 o-0 p-68 d-47 p-63 d-46 p-60 d-47 i-0 o-6 p-68 d-2 p-63 d-2 p-60 d-1 o-18 p-68 d-2 p-63 d-2 p-60 d-1 o-30 p-68 d-2 p-63 d-2 p-60 d-1 o-42 p-68 d-2 p-63 d-2 p-60 d-1 i-35 o-6 p-68 d-2 p-63 d-2 p-60 d-1 o-18 p-68 d-2 p-63 d-2 p-60 d-1 o-30 p-68 d-2 p-63 d-2 p-60 d-1 o-42 p-68 d-2 p-63 d-2 p-60 d-1 i-102 o-0 p-63 d-2 p-60 d-1 p-56 d-2 i-39 o-0 p-44 d-7 o-21 p-39 d-2 o-24 p-44 d-6 b-1 s-9 t-33 i-73 o-0 p-77 d-10 o-12 p-72 d-13 o-36 p-77 d-6 o-42 p-75 d-3 o-45 p-73 d-7 i-19 o-0 p-68 d-46 p-65 d-46 p-60 d-45 i-0 o-6 p-68 d-2 p-65 d-2 p-60 d-1 o-18 p-68 d-2 p-65 d-2 p-60 d-2 o-30 p-68 d-2 p-65 d-1 p-60 d-1 o-42 p-68 d-1 p-65 d-1 p-60 d-1 i-35 o-6 p-68 d-2 p-65 d-2 p-60 d-1 o-18 p-68 d-2 p-65 d-2 p-60 d-2 o-30 p-68 d-2 p-65 d-1 p-60 d-1 o-42 p-68 d-1 p-65 d-1 p-60 d-1 i-102 o-0 p-65 d-3 p-60 d-3 p-56 d-3 i-39 o-0 p-41 d-6 o-21 p-37 d-3 o-24 p-41 d-8 o-36 p-32 d-6 b-1 s-9 t-33 i-73 o-6 p-70 d-9 o-30 p-70 d-6 o-36 p-78 d-6 o-42 p-77 d-5 i-19 o-0 p-70 d-47 p-66 d-47 p-61 d-47 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-1 o-18 p-70 d-2 p-66 d-2 p-61 d-1 o-30 p-70 d-2 p-66 d-1 p-61 d-1 o-42 p-70 d-1 p-66 d-1 p-61 d-1 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-1 o-18 p-70 d-2 p-66 d-2 p-61 d-1 o-30 p-70 d-2 p-66 d-1 p-61 d-1 o-42 p-70 d-1 p-66 d-1 p-61 d-1 i-102 o-0 p-66 d-2 p-61 d-2 p-58 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-7 b-1 s-9 t-33 i-73 o-0 p-75 d-16 i-19 o-0 p-68 d-44 p-63 d-44 p-60 d-44 i-0 o-6 p-68 d-2 p-63 d-1 p-60 d-1 o-18 p-68 d-1 p-63 d-1 p-60 d-1 o-30 p-68 d-1 p-63 d-1 p-60 d-1 o-42 p-68 d-1 p-63 d-1 p-60 d-1 i-35 o-6 p-68 d-2 p-63 d-1 p-60 d-1 o-18 p-68 d-1 p-63 d-1 p-60 d-1 o-30 p-68 d-1 p-63 d-1 p-60 d-1 o-42 p-68 d-1 p-63 d-1 p-60 d-1 i-102 o-0 p-63 d-2 p-60 d-1 p-56 d-2 i-39 o-0 p-44 d-7 o-21 p-39 d-2 o-24 p-44 d-9 o-36 p-32 d-7 b-1 s-9 t-33 i-58 o-0 p-80 d-36 o-36 p-77 d-7 o-42 p-80 d-7 i-73 o-0 p-77 d-5 o-6 p-77 d-1 o-9 p-77 d-1 o-12 p-77 d-2 o-15 p-75 d-1 o-18 p-75 d-4 o-24 p-75 d-5 o-30 p-73 d-9 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9 t-33 i-58 o-0 p-82 d-12 o-12 p-85 d-24 o-36 p-89 d-4 o-39 p-87 d-4 o-42 p-85 d-4 o-45 p-82 d-3 i-73 o-12 p-75 d-6 o-18 p-73 d-1 o-21 p-73 d-7 o-27 p-70 d-11 o-42 p-70 d-1 o-45 p-70 d-3 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-6 o-36 p-42 d-9 b-1 s-9 t-33 i-58 o-0 p-80 d-36 o-36 p-77 d-7 o-42 p-80 d-7 i-73 o-0 p-77 d-5 o-6 p-77 d-3 o-12 p-77 d-5 o-18 p-75 d-1 o-21 p-75 d-8 o-30 p-73 d-2 o-36 p-73 d-9 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-8 o-21 p-32 d-2 o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-82 d-12 o-12 p-85 d-24 o-36 p-89 d-4 o-39 p-87 d-4 o-42 p-85 d-4 o-45 p-82 d-3 i-73 o-12 p-75 d-6 o-18 p-73 d-2 o-21 p-73 d-9 o-30 p-70 d-11 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-8 o-21 p-37 d-2 o-24 p-42 d-6 o-36 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-84 d-36 o-36 p-82 d-6 o-42 p-84 d-6 i-73 o-12 p-75 d-5 o-18 p-75 d-2 o-21 p-75 d-6 o-30 p-75 d-5 o-36 p-77 d-6 o-42 p-78 d-8 i-0 o-6 p-68 d-2 p-63 d-2 p-60 d-1 o-18 p-68 d-2 p-63 d-2 p-60 d-1 o-30 p-68 d-2 p-63 d-2 p-60 d-1 o-42 p-68 d-2 p-63 d-2 p-60 d-1 i-35 o-6 p-68 d-2 p-63 d-2 p-60 d-1 o-18 p-68 d-2 p-63 d-2 p-60 d-1 o-30 p-68 d-2 p-63 d-2 p-60 d-1 o-42 p-68 d-2 p-63 d-2 p-60 d-1 i-39 o-0 p-44 d-7 o-21 p-39 d-2 o-24 p-44 d-6 b-1 s-9 t-33 i-58 o-0 p-80 d-12 o-12 p-77 d-34 i-73 o-0 p-77 d-10 o-12 p-72 d-13 o-36 p-77 d-6 o-42 p-75 d-3 o-45 p-73 d-7 i-0 o-6 p-68 d-2 p-65 d-2 p-60 d-1 o-18 p-68 d-2 p-65 d-2 p-60 d-2 o-30 p-68 d-2 p-65 d-1 p-60 d-1 o-42 p-68 d-1 p-65 d-1 p-60 d-1 i-35 o-6 p-68 d-2 p-65 d-2 p-60 d-1 o-18 p-68 d-2 p-65 d-2 p-60 d-2 o-30 p-68 d-2 p-65 d-1 p-60 d-1 o-42 p-68 d-1 p-65 d-1 p-60 d-1 i-39 o-0 p-41 d-6 o-21 p-37 d-3 o-24 p-41 d-8 o-36 p-32 d-6 b-1 s-9 t-33 i-58 o-0 p-75 d-13 o-12 p-77 d-13 o-24 p-78 d-12 o-36 p-82 d-11 i-73 o-6 p-70 d-9 o-30 p-70 d-6 o-36 p-78 d-6 o-42 p-77 d-5 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-1 o-18 p-70 d-2 p-66 d-2 p-61 d-1 o-30 p-70 d-2 p-66 d-1 p-61 d-1 o-42 p-70 d-1 p-66 d-1 p-61 d-1 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-1 o-18 p-70 d-2 p-66 d-2 p-61 d-1 o-30 p-70 d-2 p-66 d-1 p-61 d-1 o-42 p-70 d-1 p-66 d-1 p-61 d-1 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-7 b-1 s-9 t-33 i-58 o-0 p-80 d-12 o-12 p-82 d-13 o-24 p-84 d-11 o-36 p-87 d-11 i-73 o-0 p-75 d-16 i-0 o-6 p-68 d-2 p-63 d-1 p-60 d-1 o-18 p-68 d-1 p-63 d-1 p-60 d-1 o-30 p-68 d-1 p-63 d-1 p-60 d-1 o-42 p-68 d-1 p-63 d-1 p-60 d-1 i-35 o-6 p-68 d-2 p-63 d-1 p-60 d-1 o-18 p-68 d-1 p-63 d-1 p-60 d-1 o-30 p-68 d-1 p-63 d-1 p-60 d-1 o-42 p-68 d-1 p-63 d-1 p-60 d-1 i-39 o-0 p-44 d-7 o-21 p-39 d-2 o-24 p-44 d-9 o-36 p-32 d-7 b-1 s-9 t-33 i-72 o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2 o-36 p-82 d-2 o-42 p-82 d-1 o-45 p-82 d-8 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-18 p-73 d-2 o-24 p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-2 o-42 p-75 d-1 o-45 p-75 d-8 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-7 p-61 d-7 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-2 p-61 d-2 o-30 p-68 d-2 p-65 d-2 p-61 d-2 o-42 p-68 d-3 p-65 d-3 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-6 p-80 d-12 i-73 o-6 p-73 d-12 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-3 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-6 o-36 p-42 d-9 b-1 s-9 t-33 i-72 o-36 p-82 d-2 o-42 p-82 d-1 o-45 p-82 d-1 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-36 p-75 d-2 o-42 p-75 d-1 o-45 p-75 d-1 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-7 p-61 d-7 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-2 p-65 d-2 p-61 d-2 o-18 p-68 d-2 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-39 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-7 o-21 p-32 d-2 o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-0 p-82 d-6 o-6 p-80 d-11 i-73 o-0 p-75 d-6 o-6 p-73 d-11 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-3 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-9 o-21 p-42 d-1 o-24 p-42 d-3 o-27 p-42 d-1 o-30 p-42 d-6 o-36 p-41 d-5 o-42 p-39 d-4 b-1 s-9 t-33 i-72 o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2 o-36 p-82 d-3 o-42 p-82 d-2 o-45 p-82 d-8 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-18 p-73 d-2 o-24 p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-3 o-42 p-75 d-2 o-45 p-75 d-8 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-10 p-61 d-10 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-2 p-61 d-2 o-30 p-68 d-2 p-65 d-2 p-61 d-2 o-42 p-68 d-3 p-65 d-3 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-6 p-80 d-13 i-73 o-6 p-73 d-13 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-3 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-6 o-36 p-42 d-9 b-1 s-9 t-33 i-72 o-18 p-80 d-1 o-21 p-80 d-2 o-24 p-80 d-2 o-27 p-80 d-1 o-30 p-80 d-2 o-33 p-80 d-1 o-36 p-82 d-2 o-42 p-82 d-2 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-18 p-73 d-1 o-21 p-73 d-2 o-24 p-73 d-2 o-27 p-73 d-1 o-30 p-73 d-2 o-33 p-73 d-1 o-36 p-75 d-2 o-42 p-75 d-2 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-10 p-61 d-10 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-2 p-65 d-2 p-61 d-2 o-18 p-68 d-2 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-39 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-7 o-15 p-32 d-2 o-18 p-34 d-2 o-21 p-32 d-2 p-32 d-1 o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-0 p-82 d-6 o-6 p-80 d-12 i-73 o-0 p-75 d-6 o-6 p-73 d-12 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-3 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-9 o-21 p-37 d-3 o-24 p-42 d-5 o-30 p-46 d-7 o-36 p-44 d-6 o-42 p-41 d-5 b-1 s-9 t-33 i-58 o-0 p-85 d-48 i-73 o-0 p-77 d-5 o-6 p-77 d-1 o-9 p-77 d-1 o-12 p-77 d-2 o-15 p-75 d-1 o-18 p-75 d-4 o-24 p-75 d-5 o-30 p-73 d-9 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 b-1 s-9 t-33 i-58 o-0 p-78 d-48 i-73 o-12 p-75 d-6 o-18 p-73 d-1 o-21 p-73 d-7 o-27 p-70 d-11 o-42 p-70 d-1 o-45 p-70 d-3 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-45 p-32 d-3 b-1 s-9 t-33 i-73 o-0 p-77 d-5 o-6 p-77 d-3 o-12 p-77 d-5 o-18 p-75 d-1 o-21 p-75 d-8 o-30 p-73 d-2 o-36 p-73 d-9 i-58 o-0 p-73 d-48 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-8 b-1 s-9 t-33 i-58 o-0 p-97 d-48 i-73 o-12 p-75 d-6 o-18 p-73 d-2 o-21 p-73 d-9 o-30 p-70 d-11 i-0 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-42 p-70 d-2 p-66 d-2 p-61 d-2 b-1 s-9 t-33 i-73 o-12 p-75 d-5 o-18 p-75 d-2 o-21 p-75 d-6 o-30 p-75 d-5 o-36 p-77 d-6 o-42 p-78 d-8 i-19 o-0 p-68 d-47 p-63 d-46 p-60 d-47 i-0 o-6 p-68 d-2 p-63 d-2 p-60 d-1 o-18 p-68 d-2 p-63 d-2 p-60 d-1 o-30 p-68 d-2 p-63 d-2 p-60 d-1 o-42 p-68 d-2 p-63 d-2 p-60 d-1 i-35 o-6 p-68 d-2 p-63 d-2 p-60 d-1 o-18 p-68 d-2 p-63 d-2 p-60 d-1 o-30 p-68 d-2 p-63 d-2 p-60 d-1 o-42 p-68 d-2 p-63 d-2 p-60 d-1 i-39 o-0 p-44 d-7 o-21 p-39 d-2 o-24 p-44 d-6 b-1 s-9 t-33 i-73 o-0 p-77 d-10 o-12 p-72 d-13 o-36 p-77 d-6 o-42 p-75 d-3 o-45 p-73 d-7 i-19 o-0 p-68 d-46 p-65 d-46 p-60 d-45 i-0 o-6 p-68 d-2 p-65 d-2 p-60 d-1 o-18 p-68 d-2 p-65 d-2 p-60 d-2 o-30 p-68 d-2 p-65 d-1 p-60 d-1 o-42 p-68 d-1 p-65 d-1 p-60 d-1 i-35 o-6 p-68 d-2 p-65 d-2 p-60 d-1 o-18 p-68 d-2 p-65 d-2 p-60 d-2 o-30 p-68 d-2 p-65 d-1 p-60 d-1 o-42 p-68 d-1 p-65 d-1 p-60 d-1 i-39 o-0 p-41 d-6 o-21 p-37 d-3 o-24 p-41 d-8 o-36 p-32 d-6 b-1 s-9 t-33 i-73 o-6 p-70 d-9 o-30 p-70 d-6 o-36 p-78 d-6 o-42 p-77 d-5 i-19 o-0 p-70 d-47 p-66 d-47 p-61 d-47 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-1 o-18 p-70 d-2 p-66 d-2 p-61 d-1 o-30 p-70 d-2 p-66 d-1 p-61 d-1 o-42 p-70 d-1 p-66 d-1 p-61 d-1 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-1 o-18 p-70 d-2 p-66 d-2 p-61 d-1 o-30 p-70 d-2 p-66 d-1 p-61 d-1 o-42 p-70 d-1 p-66 d-1 p-61 d-1 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-7 b-1 s-9 t-33 i-73 o-0 p-75 d-16 i-19 o-0 p-68 d-44 p-63 d-44 p-60 d-44 i-0 o-6 p-68 d-2 p-63 d-1 p-60 d-1 o-18 p-68 d-1 p-63 d-1 p-60 d-1 o-30 p-68 d-1 p-63 d-1 p-60 d-1 o-42 p-68 d-1 p-63 d-1 p-60 d-1 i-35 o-6 p-68 d-2 p-63 d-1 p-60 d-1 o-18 p-68 d-1 p-63 d-1 p-60 d-1 o-30 p-68 d-1 p-63 d-1 p-60 d-1 o-42 p-68 d-1 p-63 d-1 p-60 d-1 i-39 o-0 p-44 d-7 o-21 p-39 d-2 o-24 p-44 d-9 o-36 p-32 d-7 b-1 s-9 t-33 i-72 o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2 o-36 p-82 d-2 o-42 p-82 d-1 o-45 p-82 d-8 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-18 p-73 d-2 o-24 p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-2 o-42 p-75 d-1 o-45 p-75 d-8 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-7 p-61 d-7 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-2 p-61 d-2 o-30 p-68 d-2 p-65 d-2 p-61 d-2 o-42 p-68 d-3 p-65 d-3 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-6 p-80 d-12 i-73 o-6 p-73 d-12 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-3 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-6 o-36 p-42 d-9 b-1 s-9 t-33 i-72 o-36 p-82 d-2 o-42 p-82 d-1 o-45 p-82 d-1 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-36 p-75 d-2 o-42 p-75 d-1 o-45 p-75 d-1 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-7 p-61 d-7 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-2 p-65 d-2 p-61 d-2 o-18 p-68 d-2 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-39 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-7 o-21 p-32 d-2 o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-0 p-82 d-6 o-6 p-80 d-11 i-73 o-0 p-75 d-6 o-6 p-73 d-11 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-3 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-9 o-21 p-42 d-1 o-24 p-42 d-3 o-27 p-42 d-1 o-30 p-42 d-6 o-36 p-41 d-5 o-42 p-39 d-4 b-1 s-9 t-33 i-72 o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2 o-36 p-82 d-3 o-42 p-82 d-2 o-45 p-82 d-8 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-18 p-73 d-2 o-24 p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-3 o-42 p-75 d-2 o-45 p-75 d-8 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-10 p-61 d-10 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-2 p-61 d-2 o-30 p-68 d-2 p-65 d-2 p-61 d-2 o-42 p-68 d-3 p-65 d-3 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-6 p-80 d-13 i-73 o-6 p-73 d-13 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-3 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-6 o-36 p-42 d-9 b-1 s-9 t-33 i-72 o-18 p-80 d-1 o-21 p-80 d-2 o-24 p-80 d-2 o-27 p-80 d-1 o-30 p-80 d-2 o-33 p-80 d-1 o-36 p-82 d-2 o-42 p-82 d-2 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-18 p-73 d-1 o-21 p-73 d-2 o-24 p-73 d-2 o-27 p-73 d-1 o-30 p-73 d-2 o-33 p-73 d-1 o-36 p-75 d-2 o-42 p-75 d-2 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-10 p-61 d-10 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-2 p-65 d-2 p-61 d-2 o-18 p-68 d-2 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-39 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-7 o-15 p-32 d-2 o-18 p-34 d-2 o-21 p-32 d-2 p-32 d-1 o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-0 p-82 d-6 o-6 p-80 d-12 i-73 o-0 p-75 d-6 o-6 p-73 d-12 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-3 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-9 o-21 p-37 d-3 o-24 p-42 d-5 o-30 p-46 d-7 o-36 p-44 d-6 o-42 p-41 d-5 b-1 s-9 t-33 i-72 o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2 o-36 p-82 d-2 o-42 p-82 d-1 o-45 p-82 d-8 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-18 p-73 d-2 o-24 p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-2 o-42 p-75 d-1 o-45 p-75 d-8 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-7 p-61 d-7 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-2 p-61 d-2 o-30 p-68 d-2 p-65 d-2 p-61 d-2 o-42 p-68 d-3 p-65 d-3 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-6 p-80 d-12 i-73 o-6 p-73 d-12 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-3 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-6 o-36 p-42 d-9 b-1 s-9 t-33 i-72 o-36 p-82 d-2 o-42 p-82 d-1 o-45 p-82 d-1 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-36 p-75 d-2 o-42 p-75 d-1 o-45 p-75 d-1 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-7 p-61 d-7 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-2 p-65 d-2 p-61 d-2 o-18 p-68 d-2 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-39 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-7 o-21 p-32 d-2 o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-0 p-82 d-6 o-6 p-80 d-11 i-73 o-0 p-75 d-6 o-6 p-73 d-11 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-3 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-9 o-21 p-42 d-1 o-24 p-42 d-3 o-27 p-42 d-1 o-30 p-42 d-6 o-36 p-41 d-5 o-42 p-39 d-4 b-1 s-9 t-33 i-72 o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2 o-36 p-82 d-3 o-42 p-82 d-2 o-45 p-82 d-8 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-18 p-73 d-2 o-24 p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-3 o-42 p-75 d-2 o-45 p-75 d-8 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-10 p-61 d-10 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-2 p-61 d-2 o-30 p-68 d-2 p-65 d-2 p-61 d-2 o-42 p-68 d-3 p-65 d-3 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-6 p-80 d-13 i-73 o-6 p-73 d-13 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-3 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-6 o-36 p-42 d-9 b-1 s-9 t-33 i-72 o-18 p-80 d-1 o-21 p-80 d-2 o-24 p-80 d-2 o-27 p-80 d-1 o-30 p-80 d-2 o-33 p-80 d-1 o-36 p-82 d-2 o-42 p-82 d-2 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-18 p-73 d-1 o-21 p-73 d-2 o-24 p-73 d-2 o-27 p-73 d-1 o-30 p-73 d-2 o-33 p-73 d-1 o-36 p-75 d-2 o-42 p-75 d-2 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-10 p-61 d-10 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-2 p-65 d-2 p-61 d-2 o-18 p-68 d-2 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-39 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-7 o-15 p-32 d-2 o-18 p-34 d-2 o-21 p-32 d-2 p-32 d-1 o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-0 p-82 d-6 o-6 p-80 d-12 i-73 o-0 p-75 d-6 o-6 p-73 d-12 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-3 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-9 o-21 p-37 d-3 o-24 p-42 d-5 o-30 p-46 d-7 o-36 p-44 d-6 o-42 p-41 d-5 b-1 s-9 t-33 i-72 o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2 o-36 p-82 d-2 o-42 p-82 d-1 o-45 p-82 d-8 i-73 o-18 p-73 d-2 o-24 p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-2 o-42 p-75 d-1 o-45 p-75 d-8 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-7 p-61 d-7 i-39 o-0 p-37 d-11 b-1 s-9 t-33 i-72 o-6 p-80 d-12 i-73 o-6 p-73 d-12 b-1 s-9 t-33 i-72 o-36 p-82 d-2 o-42 p-82 d-1 o-45 p-82 d-1 i-73 o-36 p-75 d-2 o-42 p-75 d-1 o-45 p-75 d-1 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-7 p-61 d-7 b-1 s-9 t-33 i-72 o-0 p-82 d-6 o-6 p-80 d-11 i-73 o-0 p-75 d-6 o-6 p-73 d-11 b-1 s-9 t-33 i-72 o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2 o-36 p-82 d-3 o-42 p-82 d-2 o-45 p-82 d-8 i-73 o-18 p-73 d-2 o-24 p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-3 o-42 p-75 d-2 o-45 p-75 d-8 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-10 p-61 d-10 b-1 s-9 t-33 i-72 o-6 p-80 d-13 i-73 o-6 p-73 d-13 b-1 s-9 t-33 i-72 o-18 p-80 d-1 o-21 p-80 d-2 o-24 p-80 d-2 o-27 p-80 d-1 o-30 p-80 d-2 o-33 p-80 d-1 o-36 p-82 d-2 o-42 p-82 d-2 i-73 o-18 p-73 d-1 o-21 p-73 d-2 o-24 p-73 d-2 o-27 p-73 d-1 o-30 p-73 d-2 o-33 p-73 d-1 o-36 p-75 d-2 o-42 p-75 d-2 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-10 p-61 d-10 b-1 s-9 t-33 i-72 o-0 p-82 d-6 o-6 p-80 d-12 i-73 o-0 p-75 d-6 o-6 p-73 d-12 b-1 s-9 t-33 i-72 o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2 o-36 p-82 d-2 o-42 p-82 d-1 o-45 p-82 d-8 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-18 p-73 d-2 o-24 p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-2 o-42 p-75 d-1 o-45 p-75 d-8 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-7 p-61 d-7 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-2 p-61 d-2 o-30 p-68 d-2 p-65 d-2 p-61 d-2 o-42 p-68 d-3 p-65 d-3 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-6 p-80 d-12 i-73 o-6 p-73 d-12 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-3 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-6 o-36 p-42 d-9 b-1 s-9 t-33 i-72 o-36 p-82 d-2 o-42 p-82 d-1 o-45 p-82 d-1 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-36 p-75 d-2 o-42 p-75 d-1 o-45 p-75 d-1 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-7 p-61 d-7 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-2 p-65 d-2 p-61 d-2 o-18 p-68 d-2 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-39 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-7 o-21 p-32 d-2 o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-0 p-82 d-6 o-6 p-80 d-11 i-73 o-0 p-75 d-6 o-6 p-73 d-11 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-3 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-9 o-21 p-42 d-1 o-24 p-42 d-3 o-27 p-42 d-1 o-30 p-42 d-6 o-36 p-41 d-5 o-42 p-39 d-4 b-1 s-9 t-33 i-72 o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2 o-36 p-82 d-3 o-42 p-82 d-2 o-45 p-82 d-8 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-18 p-73 d-2 o-24 p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-3 o-42 p-75 d-2 o-45 p-75 d-8 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-10 p-61 d-10 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-2 p-61 d-2 o-30 p-68 d-2 p-65 d-2 p-61 d-2 o-42 p-68 d-3 p-65 d-3 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-6 p-80 d-13 i-73 o-6 p-73 d-13 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-3 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-6 o-36 p-42 d-9 b-1 s-9 t-33 i-72 o-18 p-80 d-1 o-21 p-80 d-2 o-24 p-80 d-2 o-27 p-80 d-1 o-30 p-80 d-2 o-33 p-80 d-1 o-36 p-82 d-2 o-42 p-82 d-2 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-18 p-73 d-1 o-21 p-73 d-2 o-24 p-73 d-2 o-27 p-73 d-1 o-30 p-73 d-2 o-33 p-73 d-1 o-36 p-75 d-2 o-42 p-75 d-2 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-10 p-61 d-10 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-2 p-65 d-2 p-61 d-2 o-18 p-68 d-2 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-39 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-7 o-15 p-32 d-2 o-18 p-34 d-2 o-21 p-32 d-2 p-32 d-1 o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-0 p-82 d-6 o-6 p-80 d-12 i-73 o-0 p-75 d-6 o-6 p-73 d-12 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-3 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-9 o-21 p-37 d-3 o-24 p-42 d-5 o-30 p-46 d-7 o-36 p-44 d-6 o-42 p-41 d-5 b-1 s-9 t-33 i-72 o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2 o-36 p-82 d-2 o-42 p-82 d-1 o-45 p-82 d-8 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-18 p-73 d-2 o-24 p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-2 o-42 p-75 d-1 o-45 p-75 d-8 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-7 p-61 d-7 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-2 p-61 d-2 o-30 p-68 d-2 p-65 d-2 p-61 d-2 o-42 p-68 d-3 p-65 d-3 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-6 p-80 d-12 i-73 o-6 p-73 d-12 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-3 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-6 o-36 p-42 d-9 b-1 s-9 t-33 i-72 o-36 p-82 d-2 o-42 p-82 d-1 o-45 p-82 d-1 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-36 p-75 d-2 o-42 p-75 d-1 o-45 p-75 d-1 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-7 p-61 d-7 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-2 p-65 d-2 p-61 d-2 o-18 p-68 d-2 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-39 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-7 o-21 p-32 d-2 o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-0 p-82 d-6 o-6 p-80 d-11 i-73 o-0 p-75 d-6 o-6 p-73 d-11 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-3 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-9 o-21 p-42 d-1 o-24 p-42 d-3 o-27 p-42 d-1 o-30 p-42 d-6 o-36 p-41 d-5 o-42 p-39 d-4 b-1 s-9 t-33 i-72 o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2 o-36 p-82 d-3 o-42 p-82 d-2 o-45 p-82 d-8 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-18 p-73 d-2 o-24 p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-3 o-42 p-75 d-2 o-45 p-75 d-8 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-10 p-61 d-10 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-2 p-61 d-2 o-30 p-68 d-2 p-65 d-2 p-61 d-2 o-42 p-68 d-3 p-65 d-3 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-3 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-9 o-21 p-32 d-2 o-24 p-37 d-6 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-6 p-80 d-13 i-73 o-6 p-73 d-13 i-0 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-3 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-3 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-6 o-21 p-37 d-2 o-24 p-42 d-6 o-36 p-42 d-9 b-1 s-9 t-33 i-72 o-18 p-80 d-1 o-21 p-80 d-2 o-24 p-80 d-2 o-27 p-80 d-1 o-30 p-80 d-2 o-33 p-80 d-1 o-36 p-82 d-2 o-42 p-82 d-2 i-58 o-0 p-73 d-25 o-24 p-77 d-8 o-30 p-78 d-7 o-36 p-80 d-6 o-42 p-73 d-6 i-73 o-18 p-73 d-1 o-21 p-73 d-2 o-24 p-73 d-2 o-27 p-73 d-1 o-30 p-73 d-2 o-33 p-73 d-1 o-36 p-75 d-2 o-42 p-75 d-2 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-10 p-61 d-10 i-0 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-19 o-6 p-68 d-2 p-65 d-2 p-61 d-2 o-18 p-68 d-2 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-39 p-68 d-3 p-65 d-2 p-61 d-2 i-35 o-6 p-68 d-3 p-65 d-3 p-61 d-2 o-18 p-68 d-3 p-65 d-3 p-61 d-2 o-30 p-68 d-3 p-65 d-3 p-61 d-2 o-42 p-68 d-3 p-65 d-2 p-61 d-2 i-39 o-0 p-37 d-7 o-15 p-32 d-2 o-18 p-34 d-2 o-21 p-32 d-2 p-32 d-1 o-24 p-37 d-7 b-1 s-9 t-33 i-58 o-0 p-78 d-22 o-24 p-89 d-3 o-27 p-85 d-2 o-30 p-89 d-4 o-33 p-85 d-2 o-36 p-89 d-3 o-39 p-85 d-2 o-42 p-89 d-4 o-45 p-85 d-2 i-72 o-0 p-82 d-6 o-6 p-80 d-12 i-73 o-0 p-75 d-6 o-6 p-73 d-12 i-0 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-19 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-3 p-66 d-2 p-61 d-2 o-30 p-70 d-2 p-66 d-2 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-35 o-6 p-70 d-2 p-66 d-2 p-61 d-2 o-18 p-70 d-2 p-66 d-3 p-61 d-2 o-30 p-70 d-2 p-66 d-3 p-61 d-2 o-42 p-70 d-2 p-66 d-2 p-61 d-2 i-39 o-0 p-42 d-9 o-21 p-37 d-3 o-24 p-42 d-5 o-30 p-46 d-7 o-36 p-44 d-6 o-42 p-41 d-5 b-1 s-9 t-33 i-72 o-18 p-80 d-2 o-24 p-80 d-2 o-30 p-80 d-2 o-36 p-82 d-2 o-42 p-82 d-1 o-45 p-82 d-8 i-73 o-18 p-73 d-2 o-24 p-73 d-2 o-30 p-73 d-2 o-36 p-75 d-2 o-42 p-75 d-1 o-45 p-75 d-8 i-75 o-0 p-77 d-5 p-65 d-6 o-6 p-73 d-7 p-61 d-7 i-39 o-0 p-37 d-9 b-1 s-9 t-33 i-72 o-6 p-80 d-12 i-73 o-6 p-73 d-12 b-1'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def midi_to_remiz_str(midi_fp):\n",
        "    midi_fp = \"/content/\" + midi_fp\n",
        "    mt = MultiTrack.from_midi(midi_fp)\n",
        "    remiz_str = mt.to_remiz_str(\n",
        "        with_ts=True,\n",
        "        with_tempo=True,\n",
        "        with_velocity=False\n",
        "    )\n",
        "    return remiz_str\n",
        "\n",
        "midi_to_remiz_str(df['location'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbblqbxfIE38"
      },
      "outputs": [],
      "source": [
        "# df['remiz_str'] = df['location'].progress_apply(midi_to_remiz_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tWOsLYMeIE1N",
        "outputId": "d0b87791-6521-405b-b133-cc4b7295e4e8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2842,\n  \"fields\": [\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2842,\n        \"samples\": [\n          \"lmd_full/0/05fbec1fc6c901ddb61d713b4e9af591.mid\",\n          \"lmd_full/7/725a15c9f572f3fe21abd5b7effd1f2a.mid\",\n          \"lmd_full/3/36b93c462d21e3045bf4af6f2753e25b.mid\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genre\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"remiz_str\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2753,\n        \"samples\": [\n          \"s-9 t-27 b-1 s-9 t-27 i-49 o-47 p-45 d-16 b-1 s-9 t-27 i-70 o-0 p-57 d-12 o-18 p-57 d-1 o-24 p-53 d-9 o-36 p-58 d-8 i-52 o-0 p-57 d-15 o-17 p-57 d-4 o-23 p-53 d-11 o-35 p-58 d-12 o-47 p-49 d-17 i-49 o-0 p-57 d-15 o-17 p-45 d-5 o-18 p-57 d-4 o-24 p-53 d-10 p-41 d-10 o-35 p-46 d-11 o-36 p-58 d-10 o-47 p-37 d-15 b-1 s-9 t-27 i-71 o-6 p-64 d-2 o-12 p-64 d-2 o-18 p-64 d-2 o-24 p-65 d-2 o-27 p-67 d-1 o-30 p-65 d-1 o-32 p-64 d-2 o-36 p-65 d-1 o-38 p-67 d-2 o-41 p-64 d-2 o-44 p-65 d-2 o-47 p-67 d-2 i-52 o-5 p-64 d-4 o-11 p-64 d-4 o-17 p-64 d-4 o-18 p-49 d-4 o-23 p-65 d-3 p-50 d-17 o-26 p-67 d-2 o-30 p-65 d-1 o-32 p-64 d-2 o-35 p-65 d-2 o-38 p-67 d-2 o-41 p-64 d-2 p-50 d-5 o-44 p-65 d-2 o-47 p-67 d-2 p-52 d-16 i-49 o-0 p-49 d-16 o-6 p-64 d-1 p-64 d-1 o-12 p-64 d-1 p-64 d-1 o-17 p-64 d-2 o-18 p-64 d-1 p-49 d-4 p-37 d-1 o-23 p-65 d-2 p-38 d-16 o-24 p-65 d-1 p-50 d-15 o-26 p-67 d-2 p-67 d-2 o-29 p-65 d-1 p-65 d-1 o-32 p-64 d-1 p-64 d-1 o-35 p-65 d-1 p-65 d-1 o-38 p-67 d-1 p-67 d-1 o-41 p-64 d-1 p-64 d-1 p-50 d-5 p-38 d-4 o-44 p-65 d-1 p-65 d-1 o-47 p-67 d-2 p-67 d-1 p-40 d-16 i-70 o-0 p-49 d-14 o-18 p-49 d-2 o-24 p-50 d-14 o-42 p-50 d-2 b-1 s-9 t-27 i-71 o-2 p-69 d-2 o-6 p-67 d-1 o-8 p-65 d-2 o-12 p-67 d-1 o-14 p-69 d-2 o-17 p-65 d-2 o-21 p-67 d-1 o-24 p-69 d-5 o-30 p-70 d-2 o-33 p-69 d-1 o-36 p-67 d-1 o-38 p-65 d-2 o-41 p-64 d-2 o-44 p-62 d-1 o-47 p-61 d-5 i-52 o-2 p-69 d-2 o-5 p-67 d-2 o-8 p-65 d-2 o-11 p-67 d-1 o-13 p-69 d-2 o-16 p-65 d-2 o-17 p-50 d-1 o-19 p-67 d-2 o-20 p-52 d-1 o-22 p-69 d-6 o-23 p-53 d-5 o-29 p-70 d-2 p-52 d-1 o-32 p-69 d-2 p-53 d-2 o-35 p-67 d-1 p-55 d-5 o-37 p-65 d-2 o-40 p-64 d-2 o-41 p-53 d-2 o-43 p-62 d-3 o-44 p-55 d-2 o-47 p-61 d-5 p-57 d-5 i-49 o-0 p-52 d-15 o-2 p-69 d-2 p-69 d-1 o-5 p-67 d-1 o-6 p-67 d-1 o-8 p-65 d-2 p-65 d-1 o-11 p-67 d-1 o-12 p-67 d-1 o-14 p-69 d-2 p-69 d-1 o-17 p-65 d-2 p-65 d-1 p-50 d-2 p-38 d-1 o-20 p-67 d-2 p-67 d-1 p-52 d-1 p-40 d-1 o-23 p-69 d-5 p-53 d-5 p-41 d-5 o-24 p-69 d-4 o-29 p-70 d-2 p-52 d-2 p-40 d-2 o-30 p-70 d-1 o-32 p-69 d-1 p-69 d-1 p-53 d-1 p-41 d-1 o-35 p-67 d-2 p-67 d-1 p-55 d-5 p-43 d-5 o-38 p-65 d-1 p-65 d-1 o-41 p-64 d-1 p-64 d-1 p-53 d-1 p-41 d-2 o-44 p-62 d-1 p-62 d-1 p-55 d-1 p-43 d-1 o-47 p-61 d-5 p-61 d-5 p-57 d-5 p-45 d-5 i-70 o-0 p-52 d-15 o-18 p-50 d-1 o-21 p-52 d-1 o-24 p-53 d-4 o-30 p-52 d-1 o-32 p-53 d-2 o-36 p-55 d-4 o-42 p-53 d-1 o-44 p-55 d-2 b-1 s-9 t-27 i-71 o-6 p-64 d-4 o-12 p-69 d-4 o-18 p-67 d-4 o-24 p-74 d-17 p-65 d-4 o-30 p-64 d-1 o-33 p-65 d-1 o-36 p-62 d-1 o-39 p-64 d-1 o-42 p-74 d-5 p-66 d-1 o-45 p-68 d-1 i-52 o-5 p-64 d-4 p-55 d-5 o-11 p-69 d-5 p-53 d-5 o-17 p-67 d-5 p-52 d-5 o-23 p-65 d-5 p-50 d-5 o-24 p-74 d-16 o-29 p-64 d-2 p-48 d-6 o-32 p-65 d-3 o-35 p-62 d-2 p-47 d-5 o-38 p-64 d-2 o-41 p-74 d-5 p-66 d-1 p-52 d-5 o-43 p-68 d-2 o-47 p-72 d-11 p-69 d-8 p-45 d-5 i-49 o-5 p-64 d-4 p-55 d-5 p-43 d-5 o-6 p-64 d-4 o-11 p-69 d-5 p-69 d-5 p-53 d-5 p-41 d-4 o-17 p-67 d-4 p-67 d-3 p-52 d-5 p-40 d-5 o-23 p-50 d-5 p-38 d-5 o-24 p-74 d-16 p-65 d-4 o-29 p-64 d-1 p-48 d-5 p-36 d-4 o-32 p-65 d-2 o-35 p-47 d-5 p-35 d-5 o-36 p-62 d-1 o-39 p-64 d-1 o-41 p-66 d-2 p-52 d-5 p-40 d-4 o-42 p-74 d-4 o-44 p-68 d-2 o-47 p-69 d-6 p-33 d-5 i-70 o-0 p-57 d-3 o-6 p-55 d-4 o-12 p-53 d-4 o-18 p-52 d-3 o-24 p-50 d-4 o-30 p-48 d-4 o-36 p-47 d-3 o-42 p-52 d-4 b-1 s-9 t-27 i-71 o-0 p-72 d-10 p-69 d-5 o-12 p-77 d-9 o-24 p-68 d-15 o-42 p-68 d-4 i-52 o-5 p-53 d-2 o-8 p-52 d-1 o-11 p-50 d-1 o-12 p-77 d-10 o-13 p-47 d-2 o-16 p-48 d-2 o-19 p-50 d-1 o-23 p-68 d-17 p-52 d-11 o-24 p-68 d-16 o-30 p-59 d-2 o-35 p-59 d-3 o-41 p-68 d-6 p-68 d-5 p-59 d-4 o-47 p-69 d-16 p-69 d-16 i-70 o-0 p-45 d-4 o-6 p-53 d-1 o-9 p-52 d-1 o-12 p-50 d-1 o-14 p-47 d-2 o-17 p-48 d-2 o-20 p-50 d-2 o-24 p-52 d-11 p-52 d-1 o-30 p-59 d-1 o-36 p-59 d-1 o-42 p-59 d-1 i-49 o-0 p-72 d-10 p-45 d-4 o-5 p-41 d-2 o-6 p-53 d-1 o-8 p-52 d-2 p-40 d-1 o-11 p-50 d-2 p-38 d-1 o-12 p-77 d-10 o-14 p-47 d-1 p-35 d-1 o-17 p-48 d-1 p-36 d-1 o-20 p-50 d-1 p-38 d-1 o-23 p-52 d-17 p-40 d-14 o-24 p-68 d-16 p-68 d-13 o-30 p-59 d-1 o-36 p-59 d-1 o-41 p-40 d-4 o-42 p-68 d-4 p-68 d-3 p-59 d-1 p-52 d-4 o-47 p-57 d-4 p-45 d-3 b-1 s-9 t-27 i-71 o-0 p-69 d-13 o-18 p-69 d-4 o-24 p-71 d-15 o-41 p-69 d-2 o-44 p-71 d-2 o-47 p-72 d-5 i-52 o-0 p-60 d-1 o-2 p-62 d-2 o-5 p-60 d-2 o-8 p-59 d-1 o-11 p-60 d-2 p-57 d-23 o-14 p-62 d-2 o-17 p-69 d-5 p-59 d-2 o-18 p-69 d-4 o-20 p-60 d-2 o-23 p-71 d-17 p-71 d-16 p-62 d-2 o-26 p-64 d-2 o-29 p-62 d-2 o-32 p-60 d-2 o-35 p-62 d-2 p-55 d-2 o-38 p-64 d-2 p-53 d-1 o-41 p-69 d-2 p-69 d-2 p-60 d-2 p-52 d-1 o-43 p-50 d-2 o-44 p-71 d-2 p-71 d-2 p-62 d-1 o-47 p-72 d-6 p-72 d-5 p-64 d-5 p-48 d-10 i-70 o-0 p-60 d-2 o-3 p-62 d-1 o-6 p-60 d-1 o-8 p-59 d-2 o-12 p-60 d-1 p-57 d-21 o-14 p-62 d-2 o-17 p-59 d-2 o-20 p-60 d-2 o-23 p-62 d-2 o-26 p-64 d-2 o-30 p-62 d-1 o-32 p-60 d-2 o-36 p-62 d-1 p-55 d-1 o-38 p-53 d-2 o-39 p-64 d-1 o-41 p-52 d-2 o-42 p-60 d-1 o-44 p-62 d-2 p-50 d-1 o-47 p-48 d-11 i-49 o-0 p-69 d-13 p-69 d-11 p-60 d-2 o-3 p-62 d-1 o-5 p-45 d-4 p-33 d-3 o-6 p-60 d-1 o-8 p-59 d-2 o-11 p-60 d-1 p-57 d-22 p-45 d-22 o-14 p-62 d-2 o-17 p-69 d-5 p-69 d-3 p-59 d-2 o-20 p-60 d-2 o-23 p-71 d-16 p-71 d-14 p-62 d-2 o-26 p-64 d-2 o-29 p-62 d-1 o-32 p-60 d-1 o-35 p-62 d-1 p-55 d-2 p-43 d-2 o-38 p-64 d-1 p-53 d-1 p-41 d-1 o-41 p-69 d-2 p-69 d-1 p-60 d-1 p-52 d-1 p-40 d-1 o-44 p-71 d-2 p-71 d-2 p-62 d-1 p-50 d-1 p-38 d-1 o-47 p-72 d-5 p-72 d-5 p-64 d-5 p-48 d-10 p-36 d-10 b-1 s-9 t-27 i-71 o-6 p-71 d-1 o-8 p-72 d-2 o-11 p-74 d-6 o-18 p-72 d-2 o-21 p-74 d-1 o-24 p-76 d-4 o-30 p-74 d-5 o-36 p-72 d-5 o-42 p-71 d-5 i-52 o-5 p-71 d-2 p-71 d-2 p-65 d-2 o-8 p-72 d-2 p-72 d-2 p-64 d-1 o-11 p-74 d-5 p-74 d-5 p-62 d-1 p-47 d-5 o-13 p-60 d-2 o-16 p-59 d-2 o-17 p-72 d-2 p-72 d-2 p-53 d-5 o-19 p-57 d-2 o-20 p-74 d-2 p-74 d-2 o-23 p-76 d-5 p-76 d-5 p-56 d-5 p-52 d-8 o-29 p-74 d-5 p-74 d-5 p-59 d-4 o-32 p-54 d-2 o-35 p-72 d-6 p-72 d-5 p-64 d-4 p-56 d-1 o-38 p-57 d-1 o-40 p-62 d-6 o-41 p-71 d-5 p-71 d-5 p-54 d-1 o-44 p-56 d-1 o-47 p-69 d-16 p-69 d-5 p-60 d-5 p-57 d-3 i-49 o-5 p-71 d-2 p-65 d-1 o-6 p-71 d-1 o-8 p-72 d-1 p-64 d-1 o-9 p-72 d-1 o-11 p-74 d-5 p-62 d-2 p-35 d-5 o-12 p-74 d-4 p-47 d-4 o-14 p-60 d-1 o-17 p-59 d-1 p-53 d-5 p-41 d-4 o-18 p-72 d-1 p-72 d-1 o-20 p-74 d-2 p-57 d-1 o-21 p-74 d-1 o-23 p-56 d-4 p-40 d-7 o-24 p-76 d-4 p-76 d-4 p-52 d-7 o-29 p-59 d-4 o-30 p-74 d-4 p-74 d-4 o-32 p-54 d-2 p-42 d-1 o-35 p-72 d-5 p-72 d-5 p-64 d-5 p-56 d-1 p-44 d-1 o-38 p-57 d-1 p-45 d-1 o-41 p-71 d-5 p-71 d-4 p-62 d-4 p-54 d-1 p-42 d-1 o-43 p-44 d-2 o-44 p-56 d-1 o-47 p-69 d-13 p-69 d-5 p-60 d-4 p-57 d-4 p-45 d-4 i-70 o-0 p-64 d-4 o-6 p-65 d-1 o-9 p-64 d-1 o-12 p-62 d-1 p-47 d-4 o-15 p-60 d-1 o-17 p-59 d-2 o-18 p-53 d-3 o-20 p-57 d-2 o-24 p-56 d-3 p-52 d-7 o-30 p-59 d-3 o-33 p-54 d-1 o-36 p-64 d-4 p-56 d-1 o-38 p-57 d-2 o-41 p-54 d-2 o-42 p-62 d-4 o-44 p-56 d-1 b-1 s-9 t-27 i-71 o-0 p-69 d-4 p-69 d-1 o-6 p-79 d-5 o-12 p-77 d-4 o-18 p-76 d-4 p-69 d-4 o-24 p-74 d-11 p-62 d-14 o-42 p-62 d-3 p-62 d-1 i-56 o-0 p-69 d-9 p-57 d-10 o-12 p-69 d-2 p-57 d-2 o-18 p-69 d-2 p-57 d-1 o-24 p-69 d-10 p-62 d-10 i-52 o-5 p-79 d-5 p-61 d-5 p-45 d-5 o-11 p-77 d-5 p-62 d-5 p-47 d-4 o-17 p-76 d-5 p-69 d-5 p-64 d-5 p-49 d-5 o-23 p-74 d-9 p-65 d-11 p-57 d-5 p-50 d-7 o-29 p-50 d-5 o-35 p-70 d-10 p-55 d-5 o-41 p-62 d-5 p-53 d-5 o-47 p-67 d-17 p-61 d-17 p-52 d-5 i-70 o-0 p-60 d-4 p-57 d-3 o-6 p-61 d-4 p-45 d-4 o-12 p-62 d-4 p-47 d-4 o-18 p-64 d-4 p-49 d-3 o-24 p-57 d-4 p-50 d-6 o-30 p-50 d-4 o-36 p-55 d-4 o-42 p-53 d-4 i-49 o-5 p-61 d-5 p-45 d-5 p-33 d-4 o-6 p-79 d-4 o-11 p-62 d-5 p-47 d-5 p-35 d-4 o-12 p-77 d-4 o-17 p-76 d-4 p-64 d-3 p-49 d-5 p-37 d-4 o-18 p-69 d-4 o-23 p-74 d-17 p-57 d-4 p-50 d-5 p-38 d-4 o-24 p-65 d-9 o-29 p-50 d-5 p-50 d-5 p-38 d-4 o-35 p-55 d-5 p-55 d-5 p-43 d-4 o-36 p-70 d-5 o-41 p-53 d-5 p-53 d-5 p-41 d-3 o-42 p-62 d-4 p-62 d-2 o-47 p-52 d-5 p-52 d-4 p-40 d-2 i-47 o-0 p-45 d-1 p-33 d-1 o-6 p-45 d-1 p-33 d-1 o-8 p-45 d-1 p-33 d-1 o-11 p-45 d-1 p-33 d-1 o-17 p-45 d-1 p-33 d-1 o-24 p-50 d-3 p-38 d-2 b-1 s-9 t-27 i-71 o-0 p-67 d-16 p-61 d-16 o-1 p-71 d-1 o-18 p-65 d-1 p-61 d-4 o-20 p-64 d-3 o-24 p-69 d-4 p-62 d-6 o-30 p-62 d-4 o-36 p-74 d-23 o-42 p-62 d-3 o-47 p-64 d-16 i-52 o-5 p-55 d-5 p-52 d-4 o-11 p-58 d-12 p-52 d-3 o-17 p-65 d-2 p-61 d-5 p-52 d-4 o-20 p-64 d-2 o-23 p-69 d-4 p-62 d-14 p-57 d-7 p-53 d-3 o-26 p-55 d-2 o-29 p-62 d-4 p-53 d-2 o-32 p-52 d-2 o-35 p-74 d-23 p-53 d-2 o-38 p-55 d-2 o-41 p-62 d-4 p-52 d-1 o-44 p-53 d-1 o-47 p-64 d-16 p-55 d-2 i-70 o-0 p-52 d-5 o-6 p-55 d-4 p-52 d-2 o-12 p-58 d-10 p-52 d-2 o-18 p-52 d-4 o-24 p-57 d-10 p-53 d-2 o-27 p-55 d-1 o-30 p-53 d-1 o-33 p-52 d-1 o-36 p-53 d-1 o-38 p-55 d-2 o-41 p-52 d-2 o-44 p-53 d-2 o-47 p-55 d-2 i-49 o-0 p-67 d-16 p-61 d-15 o-5 p-55 d-5 p-40 d-2 o-6 p-52 d-3 o-11 p-58 d-11 p-52 d-4 p-40 d-1 o-17 p-61 d-5 p-40 d-2 o-18 p-65 d-1 p-52 d-4 o-20 p-64 d-2 o-23 p-69 d-3 p-57 d-7 p-53 d-2 p-41 d-2 o-24 p-62 d-11 o-26 p-55 d-2 p-43 d-2 o-29 p-62 d-4 p-53 d-2 p-41 d-2 o-32 p-52 d-1 p-40 d-2 o-35 p-74 d-23 p-53 d-2 p-41 d-1 o-38 p-55 d-2 p-43 d-1 o-41 p-52 d-2 p-40 d-2 o-42 p-62 d-3 o-44 p-53 d-2 p-41 d-1 o-47 p-55 d-2 p-43 d-2 b-1 s-9 t-27 i-71 o-12 p-74 d-16 o-18 p-62 d-1 o-20 p-64 d-2 o-23 p-65 d-5 o-29 p-73 d-2 o-30 p-64 d-1 o-32 p-74 d-2 p-65 d-2 o-35 p-76 d-23 o-36 p-67 d-4 o-42 p-65 d-1 o-44 p-67 d-2 o-47 p-69 d-5 i-52 o-2 p-57 d-1 o-4 p-55 d-2 o-7 p-53 d-2 o-11 p-74 d-11 p-55 d-1 o-13 p-57 d-2 o-17 p-62 d-2 p-53 d-1 o-19 p-55 d-2 o-20 p-64 d-2 o-23 p-65 d-5 p-57 d-5 o-24 p-74 d-4 o-29 p-73 d-2 p-64 d-2 p-58 d-2 o-32 p-74 d-2 p-65 d-2 p-57 d-1 o-35 p-76 d-23 p-67 d-5 p-55 d-2 o-38 p-53 d-1 o-40 p-52 d-2 o-41 p-65 d-2 o-44 p-67 d-1 p-50 d-1 o-47 p-69 d-5 p-49 d-5 i-70 o-2 p-57 d-2 o-5 p-55 d-2 o-8 p-53 d-2 o-11 p-55 d-1 o-14 p-57 d-1 o-17 p-53 d-1 o-20 p-55 d-1 o-23 p-57 d-5 o-30 p-58 d-1 o-32 p-57 d-2 o-35 p-55 d-2 o-38 p-53 d-1 o-41 p-52 d-2 o-44 p-50 d-2 i-49 o-0 p-64 d-14 o-2 p-57 d-2 p-45 d-1 o-5 p-55 d-1 p-43 d-1 o-8 p-53 d-1 p-41 d-1 o-11 p-74 d-17 p-55 d-1 p-43 d-1 o-14 p-57 d-1 p-45 d-1 o-17 p-62 d-2 p-53 d-1 p-41 d-1 o-20 p-64 d-2 p-55 d-1 p-43 d-1 o-23 p-65 d-5 p-57 d-4 p-45 d-5 o-29 p-73 d-2 p-64 d-2 p-58 d-1 p-46 d-1 o-32 p-74 d-2 p-65 d-2 p-57 d-1 p-45 d-1 o-35 p-76 d-23 p-67 d-5 p-55 d-1 p-43 d-1 o-38 p-53 d-1 p-41 d-1 o-40 p-40 d-2 o-41 p-65 d-2 p-52 d-1 o-44 p-67 d-2 p-50 d-1 p-38 d-1 o-47 p-69 d-5 p-49 d-5 p-37 d-4 b-1 s-9 t-27 i-71 o-6 p-67 d-4 o-12 p-74 d-5 p-65 d-4 o-18 p-73 d-4 p-64 d-4 o-23 p-74 d-9 o-24 p-62 d-7 o-32 p-64 d-2 o-35 p-66 d-5 o-42 p-68 d-4 i-56 o-5 p-69 d-2 p-57 d-2 o-12 p-69 d-1 p-57 d-1 o-17 p-69 d-2 p-57 d-2 o-23 p-69 d-7 o-24 p-62 d-6 i-52 o-5 p-67 d-5 p-52 d-5 o-11 p-65 d-5 p-57 d-5 o-12 p-74 d-4 o-17 p-73 d-5 p-64 d-5 p-55 d-5 o-23 p-74 d-8 p-62 d-8 p-53 d-1 o-24 p-62 d-15 o-25 p-52 d-2 o-28 p-50 d-1 o-31 p-48 d-1 o-32 p-64 d-2 o-35 p-66 d-5 p-47 d-11 o-41 p-68 d-5 p-62 d-5 o-47 p-69 d-4 p-60 d-11 p-48 d-11 i-49 o-5 p-67 d-5 p-52 d-4 p-40 d-5 o-11 p-57 d-5 p-45 d-4 o-12 p-74 d-4 p-65 d-4 o-17 p-73 d-5 p-64 d-4 p-55 d-4 p-43 d-4 o-23 p-53 d-1 p-41 d-1 o-24 p-74 d-6 p-62 d-16 p-62 d-6 o-26 p-52 d-1 p-40 d-1 o-29 p-50 d-1 p-38 d-1 o-31 p-36 d-2 o-32 p-64 d-1 p-48 d-1 o-35 p-66 d-4 p-47 d-10 p-35 d-10 o-41 p-68 d-5 p-62 d-6 o-47 p-48 d-11 i-70 o-0 p-49 d-4 o-6 p-52 d-4 o-12 p-57 d-4 o-18 p-55 d-4 o-24 p-62 d-15 p-53 d-1 o-27 p-52 d-1 o-30 p-50 d-1 o-33 p-48 d-1 o-35 p-47 d-11 o-42 p-62 d-5 i-47 o-6 p-45 d-1 p-33 d-1 o-12 p-45 d-1 p-33 d-1 o-18 p-45 d-1 p-33 d-1 o-24 p-50 d-2 p-38 d-1 b-1 s-9 t-27 i-71 o-0 p-69 d-4 o-6 p-64 d-10 o-18 p-62 d-1 o-20 p-60 d-2 o-23 p-59 d-6 o-30 p-71 d-3 o-36 p-71 d-3 o-42 p-71 d-3 i-52 o-6 p-64 d-10 o-11 p-65 d-11 p-50 d-12 o-17 p-62 d-3 o-20 p-60 d-2 o-23 p-59 d-8 p-56 d-17 p-52 d-12 o-29 p-71 d-3 o-35 p-71 d-4 o-41 p-71 d-4 p-52 d-6 o-42 p-56 d-5 i-49 o-0 p-69 d-4 p-60 d-11 p-36 d-10 o-6 p-64 d-9 o-11 p-50 d-11 p-38 d-11 o-12 p-65 d-10 o-18 p-62 d-1 o-20 p-60 d-2 o-23 p-56 d-17 o-24 p-59 d-11 p-52 d-12 p-40 d-12 o-30 p-71 d-2 o-36 p-71 d-2 o-42 p-71 d-4 p-56 d-5 p-52 d-4 p-40 d-2 o-47 p-57 d-15 i-70 o-0 p-60 d-10 p-48 d-10 o-12 p-65 d-10 p-50 d-10 o-24 p-56 d-16 p-52 d-15 o-42 p-56 d-4 p-52 d-4 b-1 s-9 t-27 i-71 o-0 p-72 d-2 o-3 p-74 d-2 o-6 p-72 d-2 p-64 d-2 o-9 p-71 d-2 o-12 p-72 d-2 p-69 d-14 o-15 p-74 d-2 o-18 p-71 d-2 o-21 p-72 d-1 o-24 p-74 d-1 o-26 p-76 d-2 o-27 p-67 d-2 o-29 p-74 d-2 o-30 p-65 d-1 o-32 p-72 d-2 p-64 d-2 o-35 p-74 d-2 o-36 p-65 d-4 o-38 p-76 d-2 o-41 p-72 d-2 o-42 p-67 d-1 o-44 p-74 d-2 o-45 p-65 d-1 i-52 o-0 p-72 d-2 p-57 d-14 p-57 d-13 o-3 p-74 d-2 o-6 p-72 d-1 p-64 d-3 o-8 p-71 d-2 o-11 p-72 d-2 o-12 p-69 d-13 o-14 p-74 d-2 p-55 d-2 o-17 p-71 d-2 p-57 d-6 p-53 d-1 o-20 p-72 d-2 p-52 d-1 o-23 p-74 d-2 p-53 d-4 o-24 p-59 d-15 o-26 p-76 d-2 p-67 d-2 o-29 p-74 d-2 p-65 d-2 p-50 d-5 o-32 p-72 d-2 p-64 d-2 o-35 p-74 d-2 p-65 d-5 p-55 d-10 o-38 p-76 d-2 o-41 p-72 d-2 p-67 d-2 p-57 d-2 o-44 p-74 d-1 p-65 d-2 p-59 d-2 o-47 p-76 d-5 p-64 d-8 p-60 d-5 p-48 d-6 i-49 o-0 p-72 d-2 p-57 d-12 p-45 d-13 o-3 p-74 d-1 o-6 p-72 d-1 p-64 d-3 o-8 p-71 d-2 o-11 p-69 d-14 o-12 p-72 d-1 o-14 p-74 d-2 o-15 p-55 d-1 p-43 d-1 o-17 p-71 d-2 p-57 d-5 p-53 d-1 o-18 p-41 d-1 o-20 p-72 d-2 p-52 d-1 p-40 d-1 o-23 p-59 d-16 p-53 d-4 p-41 d-4 o-24 p-74 d-1 o-26 p-76 d-2 o-27 p-67 d-1 o-29 p-74 d-2 p-50 d-4 p-38 d-4 o-30 p-65 d-1 o-32 p-72 d-2 p-64 d-1 o-35 p-65 d-5 p-55 d-11 p-43 d-11 o-36 p-74 d-1 o-38 p-76 d-2 o-41 p-72 d-2 p-57 d-2 o-42 p-67 d-1 o-44 p-74 d-2 p-65 d-1 p-59 d-2 o-47 p-76 d-5 p-64 d-8 p-60 d-5 p-48 d-5 i-70 o-0 p-57 d-13 p-57 d-1 o-15 p-55 d-1 o-18 p-57 d-3 p-53 d-1 o-20 p-52 d-2 o-24 p-59 d-15 p-53 d-3 o-30 p-50 d-3 o-36 p-55 d-9 o-42 p-57 d-1 o-44 p-59 d-2 b-1 s-9 t-27 i-71 o-0 p-76 d-4 p-64 d-5 o-6 p-77 d-1 o-9 p-76 d-1 o-12 p-74 d-1 o-14 p-72 d-2 o-17 p-71 d-2 o-20 p-69 d-2 o-24 p-68 d-4 o-30 p-71 d-4 p-64 d-4 o-36 p-76 d-4 p-66 d-4 o-42 p-74 d-4 p-68 d-4 i-52 o-5 p-77 d-2 p-59 d-2 p-45 d-5 o-8 p-76 d-2 p-60 d-2 o-11 p-74 d-2 p-62 d-5 p-53 d-7 o-14 p-72 d-2 o-17 p-71 d-1 p-60 d-2 o-19 p-53 d-3 o-20 p-69 d-2 p-62 d-2 o-23 p-68 d-5 p-64 d-5 p-52 d-11 o-29 p-71 d-4 p-64 d-5 p-62 d-5 o-35 p-76 d-5 p-66 d-5 p-60 d-5 o-41 p-74 d-5 p-68 d-5 p-59 d-5 o-47 p-72 d-3 p-69 d-10 p-57 d-2 i-49 o-0 p-36 d-4 o-5 p-59 d-2 p-45 d-6 p-33 d-4 o-6 p-77 d-1 o-8 p-60 d-2 o-9 p-76 d-1 o-11 p-74 d-2 p-62 d-5 p-53 d-11 p-41 d-11 o-14 p-72 d-2 o-17 p-71 d-2 p-60 d-2 o-20 p-69 d-2 p-62 d-2 o-23 p-68 d-5 p-64 d-5 p-52 d-5 p-40 d-5 o-29 p-71 d-5 p-62 d-5 p-50 d-5 o-30 p-64 d-4 p-62 d-4 o-35 p-60 d-5 o-36 p-76 d-4 p-66 d-4 p-60 d-4 p-48 d-3 o-41 p-59 d-5 p-59 d-5 p-47 d-4 o-42 p-74 d-4 p-68 d-4 o-47 p-57 d-6 p-57 d-2 p-45 d-4 i-70 o-0 p-60 d-4 p-48 d-3 o-6 p-59 d-2 p-45 d-2 o-9 p-60 d-1 o-12 p-62 d-4 p-53 d-9 o-18 p-60 d-2 o-21 p-62 d-2 o-24 p-64 d-4 p-52 d-18 o-30 p-62 d-4 o-36 p-60 d-4 o-42 p-59 d-4 b-1 s-9 t-27 i-71 o-0 p-72 d-1 p-69 d-5 o-2 p-71 d-2 o-5 p-69 d-7 o-15 p-70 d-2 o-18 p-67 d-1 o-21 p-69 d-1 o-23 p-66 d-6 o-30 p-69 d-4 p-69 d-1 o-36 p-74 d-4 p-74 d-1 p-67 d-5 o-42 p-72 d-4 p-72 d-1 p-69 d-4 i-52 o-2 p-71 d-2 p-59 d-1 o-5 p-69 d-8 p-60 d-11 p-57 d-2 o-8 p-55 d-1 o-11 p-53 d-4 o-14 p-70 d-2 o-17 p-67 d-2 p-61 d-5 p-51 d-5 o-20 p-69 d-2 o-23 p-66 d-10 p-62 d-5 p-50 d-6 o-29 p-69 d-5 p-50 d-5 o-35 p-74 d-6 p-67 d-5 p-52 d-5 o-41 p-69 d-5 p-54 d-5 o-42 p-72 d-4 o-47 p-62 d-10 p-55 d-2 i-49 o-0 p-72 d-1 p-69 d-3 o-2 p-71 d-2 p-59 d-1 o-5 p-60 d-11 o-6 p-69 d-7 p-57 d-1 p-57 d-1 o-8 p-55 d-2 p-55 d-1 o-11 p-53 d-5 p-53 d-4 o-15 p-70 d-2 o-17 p-61 d-5 p-51 d-5 p-51 d-5 o-18 p-67 d-1 o-20 p-69 d-2 o-23 p-66 d-11 p-62 d-6 p-50 d-1 o-24 p-50 d-3 o-29 p-50 d-5 p-50 d-5 o-30 p-69 d-4 p-38 d-4 o-35 p-74 d-5 p-52 d-6 p-52 d-5 p-40 d-5 o-36 p-67 d-4 o-41 p-54 d-5 p-54 d-5 p-42 d-6 o-42 p-72 d-4 p-69 d-4 o-47 p-62 d-11 p-55 d-5 p-55 d-2 p-43 d-4 i-70 o-0 p-57 d-1 o-3 p-59 d-1 o-6 p-60 d-10 p-57 d-1 o-9 p-55 d-1 o-12 p-53 d-4 o-17 p-61 d-6 p-51 d-5 o-24 p-62 d-4 p-50 d-6 o-30 p-50 d-5 o-36 p-52 d-4 o-42 p-54 d-4 b-1 s-9 t-27 i-71 o-0 p-70 d-1 p-70 d-1 p-62 d-9 o-2 p-69 d-2 p-69 d-1 o-5 p-67 d-8 p-67 d-1 o-14 p-69 d-1 o-15 p-69 d-1 p-69 d-1 o-17 p-65 d-1 o-18 p-65 d-1 p-65 d-1 o-20 p-67 d-1 p-67 d-1 p-67 d-1 o-23 p-72 d-16 p-64 d-1 o-24 p-64 d-6 p-64 d-1 o-36 p-65 d-4 o-42 p-72 d-4 p-67 d-3 i-52 o-0 p-70 d-1 o-2 p-69 d-2 p-57 d-2 o-5 p-67 d-8 p-58 d-11 p-55 d-2 o-8 p-53 d-2 o-11 p-52 d-5 o-14 p-69 d-2 o-17 p-65 d-2 p-59 d-5 p-50 d-5 o-20 p-67 d-2 o-23 p-72 d-17 p-64 d-11 p-60 d-5 p-48 d-11 o-29 p-58 d-5 o-35 p-65 d-5 p-57 d-5 p-50 d-5 o-41 p-72 d-6 p-67 d-5 p-55 d-5 p-52 d-6 o-47 p-60 d-8 p-53 d-11 i-49 o-0 p-70 d-1 o-2 p-69 d-2 p-57 d-2 o-5 p-67 d-8 p-58 d-11 p-43 d-2 o-6 p-55 d-1 o-8 p-53 d-2 p-41 d-1 o-11 p-52 d-5 p-40 d-4 o-14 p-69 d-2 o-17 p-65 d-2 p-59 d-5 p-50 d-5 p-38 d-4 o-20 p-67 d-2 o-23 p-64 d-11 p-60 d-5 p-48 d-11 p-36 d-10 o-24 p-72 d-17 o-29 p-58 d-5 o-35 p-65 d-5 p-57 d-4 o-36 p-50 d-4 p-38 d-4 o-41 p-55 d-5 p-40 d-4 o-42 p-72 d-5 p-67 d-4 p-52 d-4 o-47 p-41 d-5 i-70 o-0 p-55 d-1 o-2 p-57 d-2 o-6 p-58 d-10 p-55 d-1 o-8 p-53 d-2 o-12 p-52 d-4 o-18 p-59 d-4 p-50 d-4 o-24 p-60 d-4 p-48 d-10 o-30 p-58 d-5 o-36 p-57 d-4 p-50 d-4 o-42 p-55 d-4 p-52 d-4 b-1 s-9 t-27 i-71 o-0 p-69 d-10 p-60 d-6 o-12 p-74 d-10 o-24 p-64 d-15 o-29 p-60 d-1 o-30 p-60 d-10 o-41 p-58 d-1 o-42 p-64 d-4 p-58 d-4 i-52 o-0 p-69 d-10 p-57 d-1 o-2 p-53 d-2 o-5 p-55 d-2 o-8 p-57 d-1 o-11 p-74 d-11 p-58 d-2 o-14 p-55 d-1 o-17 p-57 d-1 o-19 p-58 d-2 o-23 p-64 d-17 p-60 d-4 o-29 p-60 d-10 p-55 d-4 p-48 d-3 o-35 p-60 d-17 p-48 d-3 o-41 p-64 d-5 p-58 d-5 p-48 d-5 o-47 p-65 d-17 p-57 d-4 p-50 d-2 i-70 o-0 p-57 d-1 p-53 d-2 o-2 p-53 d-2 o-5 p-55 d-2 o-8 p-57 d-2 o-11 p-58 d-2 o-14 p-55 d-2 o-17 p-57 d-1 o-20 p-58 d-1 o-23 p-60 d-4 o-29 p-55 d-4 o-30 p-48 d-1 o-36 p-60 d-16 p-48 d-1 o-42 p-48 d-1 i-49 o-0 p-69 d-11 p-60 d-6 p-57 d-1 p-53 d-4 o-2 p-53 d-2 o-5 p-55 d-2 p-55 d-2 p-43 d-2 o-8 p-57 d-1 p-57 d-1 p-45 d-1 o-11 p-58 d-2 p-58 d-1 p-46 d-2 o-12 p-74 d-10 o-14 p-55 d-1 p-55 d-1 p-43 d-1 o-17 p-57 d-1 p-57 d-1 p-45 d-1 o-20 p-58 d-1 p-58 d-1 p-46 d-1 o-23 p-60 d-4 p-60 d-3 p-48 d-4 o-24 p-64 d-16 o-29 p-60 d-10 p-55 d-4 p-48 d-3 p-36 d-4 o-35 p-60 d-16 p-48 d-4 p-36 d-3 o-41 p-64 d-5 p-58 d-4 p-48 d-4 p-36 d-4 o-47 p-65 d-16 p-50 d-2 p-38 d-2 b-1 s-9 t-27 i-71 o-0 p-65 d-6 p-57 d-5 p-57 d-1 o-6 p-65 d-5 o-12 p-62 d-4 o-17 p-58 d-6 o-18 p-65 d-4 o-24 p-67 d-5 o-29 p-67 d-5 o-35 p-64 d-5 o-41 p-65 d-2 p-60 d-4 o-44 p-67 d-2 i-52 o-2 p-52 d-2 o-5 p-65 d-5 p-58 d-2 p-50 d-1 o-8 p-57 d-2 p-48 d-1 o-11 p-62 d-3 p-58 d-2 p-50 d-2 o-14 p-60 d-2 p-52 d-1 o-17 p-65 d-5 p-58 d-5 p-57 d-2 p-48 d-2 o-20 p-58 d-3 p-50 d-2 o-23 p-67 d-17 p-55 d-5 p-52 d-1 o-26 p-53 d-1 o-29 p-67 d-4 p-57 d-2 p-52 d-1 o-31 p-50 d-2 o-32 p-58 d-2 o-34 p-52 d-2 o-35 p-64 d-3 p-60 d-9 o-37 p-53 d-2 o-41 p-65 d-2 p-60 d-4 p-50 d-1 o-44 p-67 d-2 p-52 d-1 o-47 p-69 d-5 p-53 d-3 i-70 o-0 p-50 d-1 o-2 p-52 d-2 o-6 p-58 d-2 p-50 d-1 o-8 p-57 d-2 p-48 d-1 o-11 p-58 d-2 p-50 d-2 o-14 p-60 d-2 p-52 d-2 o-17 p-57 d-1 p-48 d-2 o-20 p-58 d-2 p-50 d-1 o-23 p-55 d-5 p-52 d-2 o-26 p-53 d-1 o-29 p-52 d-1 o-30 p-57 d-1 o-32 p-58 d-2 p-50 d-1 o-35 p-52 d-1 o-36 p-60 d-10 o-38 p-53 d-1 o-41 p-50 d-1 o-44 p-52 d-1 o-47 p-53 d-1 i-49 o-0 p-57 d-3 o-2 p-52 d-2 p-40 d-2 o-5 p-58 d-2 p-50 d-1 p-38 d-2 o-6 p-65 d-2 o-8 p-57 d-1 p-48 d-1 p-36 d-2 o-11 p-62 d-3 p-58 d-1 p-50 d-2 p-38 d-2 o-14 p-60 d-1 p-52 d-1 p-40 d-1 o-17 p-58 d-3 p-57 d-1 p-48 d-1 p-36 d-1 o-18 p-65 d-4 o-20 p-58 d-2 p-50 d-1 p-38 d-1 o-23 p-55 d-5 p-52 d-1 p-40 d-1 o-24 p-67 d-16 o-26 p-53 d-1 p-41 d-1 o-29 p-67 d-2 p-57 d-2 p-52 d-1 p-40 d-1 o-32 p-58 d-2 p-50 d-1 p-38 d-1 o-35 p-64 d-2 p-60 d-11 p-52 d-1 p-40 d-1 o-37 p-41 d-2 o-38 p-53 d-1 o-41 p-65 d-2 p-60 d-2 p-50 d-1 p-38 d-1 o-44 p-67 d-2 p-52 d-1 p-40 d-1 o-47 p-69 d-5 p-53 d-4 p-41 d-5 b-1 s-9 t-27 i-71 o-0 p-69 d-4 o-5 p-67 d-2 p-64 d-2 o-8 p-69 d-2 p-65 d-2 o-11 p-70 d-5 p-67 d-5 o-17 p-65 d-2 o-18 p-69 d-1 o-20 p-70 d-2 p-67 d-2 o-23 p-72 d-5 p-69 d-5 o-30 p-70 d-4 p-64 d-4 o-36 p-69 d-4 p-62 d-4 o-41 p-61 d-5 o-42 p-67 d-4 i-52 o-5 p-67 d-2 p-64 d-2 p-55 d-1 o-8 p-69 d-2 p-65 d-2 p-53 d-1 o-11 p-70 d-5 p-67 d-5 p-52 d-1 o-14 p-50 d-1 o-17 p-69 d-2 p-65 d-2 p-48 d-1 o-20 p-70 d-2 p-67 d-2 p-46 d-1 o-23 p-72 d-5 p-69 d-5 p-45 d-5 o-29 p-70 d-5 p-64 d-5 p-48 d-4 o-35 p-69 d-5 p-65 d-5 p-53 d-4 o-41 p-67 d-5 p-61 d-5 p-51 d-5 o-47 p-66 d-12 p-62 d-12 p-50 d-4 i-49 o-5 p-67 d-1 p-64 d-1 p-55 d-1 p-43 d-1 o-8 p-69 d-1 p-65 d-1 p-53 d-2 p-41 d-1 o-11 p-70 d-5 p-67 d-5 p-52 d-1 p-40 d-1 o-14 p-50 d-1 p-38 d-1 o-16 p-36 d-1 o-17 p-69 d-2 p-48 d-1 o-18 p-65 d-1 o-19 p-34 d-2 o-20 p-70 d-2 p-67 d-1 p-46 d-1 o-23 p-72 d-5 p-69 d-4 p-45 d-4 p-33 d-4 o-29 p-70 d-5 p-64 d-4 p-48 d-4 p-36 d-5 o-35 p-69 d-5 p-65 d-4 p-53 d-4 p-41 d-4 o-41 p-67 d-5 p-61 d-4 p-51 d-4 p-39 d-4 o-47 p-66 d-12 p-50 d-4 p-38 d-4 i-70 o-0 p-53 d-2 o-6 p-55 d-1 o-8 p-53 d-2 o-11 p-52 d-2 o-14 p-50 d-2 o-17 p-48 d-1 o-20 p-46 d-2 o-24 p-45 d-3 o-29 p-48 d-5 o-36 p-53 d-4 o-42 p-51 d-3 b-1 s-9 t-27 i-71 o-0 p-66 d-11 p-62 d-10 o-12 p-67 d-5 p-64 d-4 o-18 p-69 d-4 p-66 d-4 o-24 p-70 d-7 p-67 d-4 i-56 o-0 p-62 d-9 o-12 p-62 d-1 o-18 p-62 d-1 o-24 p-62 d-9 i-52 o-0 p-62 d-16 o-5 p-60 d-10 o-11 p-67 d-5 p-64 d-5 o-17 p-69 d-5 p-66 d-5 p-58 d-1 o-18 p-62 d-4 o-19 p-57 d-2 o-23 p-70 d-9 p-67 d-8 p-58 d-11 p-55 d-2 o-26 p-53 d-1 o-29 p-51 d-2 o-32 p-50 d-2 o-35 p-63 d-11 p-48 d-1 o-38 p-50 d-1 o-41 p-46 d-1 o-44 p-48 d-1 o-47 p-54 d-17 p-50 d-15 i-70 o-0 p-62 d-13 p-50 d-2 o-6 p-60 d-10 o-17 p-58 d-2 o-18 p-62 d-3 o-20 p-57 d-2 o-24 p-58 d-10 p-55 d-1 o-27 p-53 d-1 o-30 p-51 d-1 o-33 p-50 d-1 o-36 p-63 d-9 p-48 d-1 o-39 p-50 d-1 o-42 p-46 d-1 o-45 p-48 d-1 i-49 o-0 p-62 d-16 p-62 d-10 p-62 d-1 o-5 p-60 d-10 p-48 d-10 o-12 p-67 d-5 p-64 d-4 o-17 p-66 d-5 p-62 d-5 p-46 d-2 o-18 p-69 d-4 p-58 d-1 o-20 p-57 d-2 p-45 d-2 o-23 p-70 d-9 p-67 d-6 p-58 d-11 p-55 d-2 p-43 d-2 o-26 p-53 d-2 p-41 d-2 o-29 p-51 d-2 p-39 d-1 o-32 p-50 d-1 p-38 d-1 o-35 p-63 d-11 p-48 d-1 p-36 d-1 o-38 p-50 d-1 p-38 d-1 o-41 p-46 d-1 p-34 d-1 o-44 p-48 d-1 p-36 d-1 o-47 p-54 d-15 p-50 d-16 p-38 d-15 i-47 o-0 p-50 d-1 p-38 d-2 b-1 s-9 t-27 i-71 o-6 p-69 d-1 p-63 d-4 o-12 p-69 d-1 p-62 d-5 o-18 p-69 d-1 p-60 d-4 o-24 p-70 d-2 p-58 d-4 o-27 p-72 d-1 o-30 p-70 d-2 p-55 d-4 o-33 p-69 d-1 o-35 p-70 d-2 o-36 p-63 d-16 o-38 p-72 d-2 o-41 p-69 d-2 o-44 p-70 d-2 o-47 p-72 d-2 i-52 o-5 p-69 d-3 p-63 d-5 o-11 p-62 d-5 o-12 p-69 d-2 o-17 p-69 d-4 p-60 d-5 p-54 d-5 p-50 d-5 o-23 p-58 d-5 p-55 d-15 p-43 d-9 o-24 p-70 d-1 o-26 p-72 d-2 o-29 p-70 d-2 p-55 d-5 o-32 p-70 d-1 p-69 d-2 o-35 p-70 d-2 p-63 d-17 o-38 p-72 d-2 o-41 p-69 d-1 p-55 d-5 o-44 p-70 d-2 o-47 p-72 d-2 p-57 d-16 i-49 o-6 p-69 d-2 p-63 d-4 o-12 p-69 d-2 p-62 d-4 o-17 p-60 d-4 p-54 d-5 p-50 d-4 p-38 d-4 o-18 p-69 d-3 o-23 p-55 d-13 p-31 d-12 o-24 p-70 d-2 p-58 d-4 p-43 d-15 o-27 p-72 d-1 o-29 p-55 d-4 o-30 p-70 d-1 o-33 p-69 d-1 o-35 p-63 d-17 o-36 p-70 d-1 o-38 p-72 d-2 o-41 p-55 d-4 p-55 d-4 o-42 p-69 d-1 p-43 d-2 o-44 p-70 d-2 o-47 p-57 d-16 p-57 d-16 i-70 o-0 p-54 d-15 p-50 d-14 o-17 p-50 d-2 o-18 p-54 d-4 o-24 p-55 d-13 p-43 d-11 o-42 p-55 d-4 b-1 s-9 t-27 i-71 o-2 p-74 d-2 o-6 p-72 d-1 p-60 d-4 o-9 p-70 d-1 o-11 p-72 d-2 o-12 p-65 d-22 o-14 p-74 d-2 o-17 p-70 d-2 o-20 p-72 d-2 o-24 p-74 d-4 o-29 p-75 d-2 o-32 p-74 d-2 o-35 p-72 d-2 p-63 d-11 o-38 p-70 d-2 o-42 p-69 d-1 o-44 p-67 d-2 i-52 o-2 p-74 d-2 o-5 p-72 d-2 p-60 d-5 o-8 p-70 d-2 o-11 p-72 d-2 p-65 d-23 o-14 p-74 d-2 o-17 p-70 d-1 p-55 d-2 o-20 p-72 d-2 p-57 d-2 o-23 p-74 d-5 p-58 d-5 o-29 p-75 d-2 p-57 d-2 o-32 p-74 d-2 p-58 d-2 o-35 p-72 d-2 p-63 d-11 p-60 d-5 o-38 p-70 d-2 o-41 p-69 d-1 p-58 d-1 o-43 p-67 d-3 p-60 d-3 o-47 p-66 d-5 p-62 d-6 p-62 d-5 i-49 o-0 p-72 d-1 p-45 d-6 o-2 p-74 d-2 o-5 p-60 d-5 o-6 p-72 d-1 o-8 p-70 d-2 o-12 p-72 d-1 p-65 d-21 o-14 p-74 d-2 o-17 p-70 d-2 p-55 d-2 p-55 d-1 o-18 p-43 d-1 o-20 p-72 d-2 p-57 d-2 p-57 d-1 p-45 d-1 o-23 p-74 d-5 p-58 d-5 p-58 d-5 p-46 d-5 o-29 p-75 d-2 p-57 d-2 p-57 d-1 p-45 d-2 o-32 p-74 d-2 p-58 d-2 p-58 d-1 p-46 d-1 o-35 p-72 d-1 p-60 d-5 p-60 d-4 p-48 d-5 o-36 p-63 d-9 o-38 p-70 d-2 o-41 p-69 d-2 p-58 d-2 p-58 d-1 p-46 d-1 o-44 p-67 d-1 p-60 d-2 p-60 d-1 p-48 d-1 o-47 p-66 d-5 p-62 d-5 p-62 d-5 p-62 d-5 p-50 d-5 i-70 o-0 p-57 d-15 o-17 p-55 d-2 o-20 p-57 d-2 o-23 p-58 d-5 o-30 p-57 d-1 o-32 p-58 d-2 o-36 p-60 d-4 o-42 p-58 d-1 o-44 p-60 d-2 b-1 s-9 t-27 i-71 o-0 p-66 d-4 p-62 d-4 o-5 p-69 d-5 o-6 p-66 d-5 o-12 p-74 d-4 p-67 d-5 o-18 p-72 d-4 p-69 d-4 o-24 p-70 d-4 p-62 d-4 o-30 p-71 d-4 p-69 d-4 o-36 p-72 d-4 p-67 d-4 o-41 p-74 d-5 i-52 o-5 p-69 d-5 p-66 d-5 p-60 d-5 o-11 p-74 d-4 p-67 d-5 p-58 d-5 o-17 p-72 d-5 p-69 d-5 p-57 d-5 o-23 p-70 d-5 p-62 d-5 p-55 d-5 o-24 p-55 d-16 o-29 p-68 d-5 p-65 d-5 o-30 p-71 d-3 o-35 p-72 d-5 p-67 d-8 p-63 d-6 o-41 p-74 d-4 p-59 d-4 o-42 p-55 d-4 o-47 p-75 d-2 p-60 d-5 p-51 d-11 i-49 o-5 p-69 d-5 p-60 d-5 p-60 d-4 p-48 d-5 o-6 p-66 d-4 o-11 p-74 d-5 p-58 d-5 p-58 d-4 p-46 d-5 o-12 p-67 d-4 o-17 p-69 d-5 p-57 d-4 p-45 d-4 o-18 p-72 d-4 p-57 d-4 o-23 p-62 d-4 p-55 d-17 p-55 d-5 p-43 d-16 o-24 p-70 d-5 o-29 p-68 d-5 o-30 p-71 d-4 p-65 d-4 o-35 p-67 d-7 p-63 d-5 o-36 p-72 d-4 o-41 p-59 d-5 o-42 p-74 d-4 p-55 d-4 p-43 d-4 o-47 p-75 d-2 p-60 d-5 p-51 d-11 p-39 d-11 i-70 o-0 p-62 d-4 o-6 p-60 d-4 o-12 p-58 d-4 o-18 p-57 d-4 o-24 p-55 d-4 p-55 d-1 o-30 p-65 d-4 o-36 p-63 d-4 o-42 p-59 d-4 p-55 d-2 b-1 s-9 t-27 i-71 o-0 p-75 d-1 p-75 d-1 o-2 p-74 d-2 o-5 p-72 d-6 o-30 p-62 d-3 o-36 p-62 d-3 o-42 p-62 d-4 i-52 o-2 p-74 d-1 o-5 p-72 d-3 p-67 d-5 o-11 p-65 d-2 p-56 d-11 o-14 p-63 d-2 o-17 p-62 d-2 o-20 p-60 d-2 o-23 p-62 d-3 p-47 d-17 o-26 p-60 d-2 o-29 p-62 d-4 p-59 d-2 o-32 p-57 d-2 o-35 p-62 d-4 p-55 d-2 o-38 p-56 d-2 o-41 p-62 d-5 p-53 d-2 p-47 d-5 o-44 p-55 d-3 o-47 p-63 d-3 p-51 d-6 p-48 d-14 i-70 o-0 p-60 d-4 p-51 d-10 o-6 p-67 d-4 o-12 p-65 d-1 p-56 d-8 o-14 p-63 d-2 o-17 p-62 d-2 o-20 p-60 d-2 o-23 p-62 d-2 o-24 p-47 d-13 o-26 p-60 d-2 o-29 p-59 d-2 o-30 p-60 d-1 o-32 p-57 d-2 o-35 p-55 d-2 o-38 p-56 d-2 o-41 p-55 d-2 o-42 p-47 d-1 o-44 p-53 d-2 i-49 o-2 p-74 d-2 o-5 p-72 d-4 o-6 p-67 d-4 o-11 p-56 d-11 o-12 p-65 d-1 p-44 d-10 o-14 p-63 d-2 o-17 p-62 d-2 o-20 p-60 d-2 o-23 p-62 d-2 p-48 d-3 p-47 d-16 p-35 d-17 o-26 p-60 d-2 o-29 p-62 d-2 p-59 d-1 o-32 p-57 d-1 o-35 p-62 d-2 p-55 d-2 o-38 p-56 d-2 o-41 p-53 d-2 p-47 d-4 p-35 d-4 o-42 p-62 d-2 o-44 p-55 d-2 o-47 p-51 d-6 p-48 d-15 p-36 d-12 b-1 s-9 t-27 i-71 o-0 p-63 d-2 o-3 p-65 d-2 o-6 p-63 d-1 o-9 p-62 d-1 o-12 p-63 d-1 o-14 p-65 d-2 o-18 p-62 d-1 o-20 p-63 d-2 o-24 p-65 d-2 o-27 p-67 d-1 o-30 p-65 d-1 o-32 p-63 d-2 o-35 p-65 d-2 o-38 p-67 d-2 o-41 p-63 d-2 o-44 p-65 d-2 o-47 p-67 d-5 i-52 o-2 p-65 d-3 o-5 p-48 d-3 o-6 p-63 d-2 o-8 p-62 d-2 o-11 p-63 d-2 p-56 d-17 o-14 p-65 d-2 o-17 p-62 d-2 p-48 d-5 o-20 p-63 d-2 o-23 p-65 d-2 p-50 d-16 o-26 p-67 d-2 o-29 p-65 d-2 p-53 d-4 o-32 p-63 d-2 o-35 p-65 d-1 p-58 d-23 o-38 p-67 d-1 o-40 p-63 d-2 o-41 p-48 d-2 o-43 p-65 d-2 o-44 p-50 d-2 o-46 p-67 d-6 o-47 p-51 d-5 i-49 o-0 p-63 d-1 o-3 p-65 d-1 o-5 p-63 d-2 p-48 d-5 o-8 p-62 d-2 o-11 p-56 d-17 o-12 p-63 d-1 o-14 p-65 d-2 o-17 p-48 d-5 p-36 d-4 o-18 p-62 d-1 o-20 p-63 d-2 o-23 p-65 d-2 p-38 d-14 o-24 p-50 d-15 o-26 p-67 d-2 o-29 p-65 d-2 p-53 d-5 o-32 p-63 d-2 o-35 p-65 d-2 p-58 d-23 o-38 p-67 d-1 o-41 p-63 d-1 p-48 d-2 p-36 d-1 o-44 p-65 d-2 p-50 d-1 p-38 d-1 o-47 p-67 d-5 p-51 d-4 p-39 d-4 i-70 o-0 p-51 d-3 p-48 d-5 o-5 p-48 d-3 o-12 p-56 d-14 o-18 p-48 d-1 o-24 p-50 d-15 o-30 p-53 d-2 o-35 p-58 d-23 o-42 p-48 d-1 o-45 p-50 d-1 b-1 s-9 t-27 i-71 o-6 p-68 d-2 o-9 p-67 d-1 o-12 p-65 d-1 o-15 p-63 d-1 o-17 p-62 d-2 o-20 p-60 d-2 o-23 p-59 d-5 o-30 p-62 d-4 o-36 p-67 d-4 o-42 p-65 d-4 i-52 o-5 p-68 d-2 p-50 d-2 o-7 p-51 d-2 o-8 p-67 d-2 o-11 p-65 d-1 p-56 d-11 p-53 d-4 o-14 p-63 d-2 o-17 p-62 d-1 p-51 d-2 o-19 p-60 d-3 o-20 p-53 d-1 o-23 p-59 d-4 p-55 d-5 p-55 d-5 o-29 p-62 d-4 p-57 d-2 p-53 d-5 o-32 p-59 d-2 o-35 p-67 d-4 p-60 d-6 p-51 d-5 o-41 p-65 d-4 p-50 d-5 o-42 p-62 d-4 o-47 p-63 d-16 p-63 d-3 p-48 d-5 i-70 o-0 p-51 d-4 o-6 p-50 d-1 o-8 p-51 d-2 o-11 p-53 d-5 o-12 p-56 d-10 o-18 p-51 d-1 o-20 p-53 d-1 o-23 p-55 d-1 o-24 p-55 d-3 o-30 p-57 d-1 p-53 d-4 o-33 p-59 d-1 o-36 p-60 d-4 p-51 d-4 o-42 p-62 d-4 p-50 d-4 i-49 o-5 p-68 d-2 p-50 d-1 p-38 d-1 o-8 p-67 d-2 p-51 d-1 p-39 d-1 o-11 p-65 d-2 p-53 d-4 p-41 d-4 o-12 p-56 d-10 o-14 p-63 d-2 o-17 p-62 d-2 p-51 d-1 p-39 d-1 o-20 p-60 d-2 p-53 d-1 p-41 d-1 o-23 p-59 d-5 p-55 d-5 p-43 d-4 o-24 p-55 d-5 o-29 p-62 d-5 p-53 d-5 p-41 d-4 o-30 p-57 d-1 o-32 p-59 d-2 o-35 p-67 d-5 p-60 d-5 p-51 d-5 p-39 d-5 o-41 p-62 d-5 p-50 d-4 p-38 d-4 o-42 p-65 d-4 o-47 p-63 d-16 p-63 d-2 p-48 d-5 p-36 d-4 b-1 s-9 t-27 i-71 o-0 p-63 d-15 o-17 p-62 d-5 o-24 p-77 d-16 p-60 d-4 o-30 p-65 d-4 o-36 p-67 d-4 o-42 p-77 d-4 p-69 d-3 i-52 o-2 p-62 d-2 o-5 p-60 d-3 p-50 d-2 o-8 p-58 d-2 p-51 d-1 o-11 p-57 d-5 p-53 d-17 o-17 p-62 d-5 p-58 d-11 o-23 p-77 d-18 p-60 d-5 o-29 p-65 d-5 p-57 d-5 p-51 d-6 o-35 p-67 d-5 p-58 d-6 p-50 d-5 o-41 p-69 d-4 p-48 d-5 o-42 p-77 d-5 p-60 d-4 o-47 p-70 d-4 p-62 d-12 p-46 d-5 i-70 o-0 p-63 d-2 p-48 d-4 o-2 p-62 d-2 o-5 p-60 d-2 o-6 p-50 d-1 o-8 p-58 d-2 o-9 p-51 d-1 o-11 p-57 d-4 o-12 p-53 d-15 o-17 p-58 d-11 o-30 p-57 d-4 p-51 d-4 o-36 p-58 d-4 p-50 d-4 o-42 p-60 d-3 p-48 d-4 i-49 o-2 p-62 d-2 o-5 p-60 d-2 p-50 d-2 p-38 d-1 o-8 p-58 d-2 p-51 d-1 p-39 d-1 o-11 p-53 d-17 p-41 d-17 o-12 p-57 d-3 o-17 p-62 d-5 p-58 d-11 o-23 p-77 d-18 p-60 d-5 o-29 p-57 d-5 p-51 d-5 p-39 d-6 o-30 p-65 d-4 o-35 p-58 d-5 p-50 d-5 p-38 d-5 o-36 p-67 d-4 o-41 p-60 d-5 p-48 d-5 p-36 d-5 o-42 p-77 d-6 p-69 d-4 o-47 p-62 d-8 p-46 d-5 p-34 d-5 b-1 s-9 t-27 i-71 o-0 p-74 d-10 p-70 d-4 o-6 p-58 d-4 o-12 p-79 d-10 p-63 d-6 o-21 p-62 d-1 o-24 p-69 d-15 p-60 d-4 o-30 p-60 d-3 o-36 p-65 d-16 o-42 p-69 d-3 o-47 p-70 d-13 i-52 o-0 p-74 d-10 o-5 p-58 d-5 p-55 d-2 o-8 p-53 d-2 o-11 p-79 d-11 p-63 d-7 p-51 d-2 o-14 p-48 d-2 o-17 p-50 d-2 o-20 p-62 d-1 p-51 d-1 o-23 p-69 d-17 p-60 d-3 p-53 d-6 o-29 p-60 d-4 p-53 d-3 o-35 p-65 d-16 p-53 d-3 o-41 p-69 d-5 o-42 p-53 d-3 o-47 p-70 d-12 i-49 o-0 p-74 d-10 p-70 d-4 o-5 p-55 d-2 p-43 d-2 o-6 p-58 d-4 o-8 p-53 d-2 p-41 d-1 o-11 p-51 d-2 p-39 d-1 o-12 p-79 d-11 p-63 d-6 o-14 p-48 d-2 p-36 d-1 o-17 p-50 d-1 p-38 d-1 o-20 p-62 d-2 p-51 d-1 p-39 d-1 o-23 p-69 d-17 p-60 d-4 p-53 d-4 p-41 d-4 o-29 p-60 d-4 p-53 d-3 p-53 d-3 p-41 d-2 o-35 p-65 d-16 p-53 d-3 p-53 d-3 p-41 d-2 o-41 p-53 d-5 p-53 d-3 p-41 d-1 o-42 p-69 d-5 o-47 p-70 d-12 i-70 o-0 p-62 d-4 p-46 d-4 o-6 p-55 d-2 o-9 p-53 d-1 o-12 p-51 d-1 o-15 p-48 d-1 o-18 p-50 d-1 o-20 p-51 d-2 o-24 p-53 d-6 o-30 p-53 d-3 o-36 p-53 d-2 o-42 p-53 d-4 b-1 s-9 t-27 i-71 o-6 p-63 d-2 o-9 p-62 d-1 o-12 p-63 d-1 o-14 p-65 d-2 o-17 p-70 d-5 p-62 d-2 o-20 p-63 d-2 o-23 p-60 d-5 o-24 p-72 d-15 o-29 p-62 d-2 o-32 p-63 d-2 o-35 p-65 d-15 o-41 p-70 d-2 o-44 p-72 d-2 i-52 o-0 p-55 d-1 o-2 p-57 d-2 o-5 p-63 d-2 p-55 d-2 o-8 p-62 d-2 p-53 d-1 o-11 p-63 d-2 p-55 d-2 o-14 p-65 d-2 p-57 d-2 o-17 p-70 d-5 p-62 d-1 p-53 d-1 o-19 p-63 d-2 o-20 p-55 d-1 o-23 p-72 d-17 p-60 d-5 p-57 d-1 p-53 d-17 o-25 p-58 d-2 o-28 p-57 d-2 o-29 p-62 d-1 o-31 p-55 d-2 o-32 p-63 d-2 o-35 p-65 d-15 p-57 d-1 o-38 p-58 d-1 o-40 p-55 d-2 o-41 p-70 d-2 p-53 d-5 o-43 p-57 d-2 o-44 p-72 d-2 o-47 p-74 d-5 p-58 d-12 p-50 d-11 i-70 o-0 p-55 d-2 o-3 p-57 d-1 o-6 p-55 d-1 o-8 p-53 d-2 o-11 p-55 d-2 o-14 p-57 d-2 o-17 p-53 d-2 o-20 p-55 d-2 o-23 p-57 d-2 o-24 p-53 d-15 o-26 p-58 d-2 o-29 p-57 d-2 o-32 p-55 d-2 o-35 p-57 d-1 o-38 p-58 d-1 o-41 p-55 d-1 o-42 p-53 d-3 o-44 p-57 d-1 o-47 p-58 d-6 i-49 o-0 p-55 d-2 p-55 d-1 p-43 d-1 o-2 p-57 d-2 p-45 d-1 o-3 p-57 d-1 o-5 p-43 d-1 o-6 p-63 d-1 p-55 d-1 p-55 d-1 o-8 p-62 d-2 p-53 d-2 p-53 d-2 p-41 d-1 o-11 p-63 d-2 p-55 d-2 p-55 d-2 p-43 d-1 o-14 p-65 d-2 p-57 d-2 p-57 d-1 p-45 d-1 o-17 p-70 d-5 p-62 d-2 p-53 d-2 p-53 d-1 p-41 d-1 o-19 p-43 d-1 o-20 p-63 d-2 p-55 d-2 p-55 d-1 o-23 p-72 d-16 p-60 d-5 p-57 d-2 p-53 d-16 o-24 p-41 d-15 o-26 p-58 d-2 o-29 p-57 d-1 o-30 p-62 d-1 o-32 p-63 d-2 p-55 d-1 o-35 p-65 d-15 p-57 d-1 o-37 p-58 d-2 o-41 p-70 d-2 p-55 d-1 p-53 d-5 p-41 d-5 o-43 p-57 d-2 o-44 p-72 d-2 o-47 p-74 d-5 p-58 d-8 p-50 d-11 p-38 d-11 b-1 s-9 t-27 i-71 o-0 p-74 d-4 o-6 p-72 d-1 p-58 d-9 o-9 p-74 d-1 o-12 p-75 d-5 o-18 p-74 d-1 p-67 d-4 o-20 p-75 d-2 o-24 p-77 d-5 p-65 d-15 o-30 p-72 d-4 o-36 p-77 d-4 o-42 p-75 d-4 i-52 o-5 p-72 d-2 p-58 d-10 o-8 p-74 d-2 o-11 p-75 d-5 o-12 p-55 d-10 o-17 p-74 d-2 p-67 d-5 o-20 p-75 d-2 o-23 p-77 d-5 p-65 d-7 p-45 d-16 o-29 p-72 d-5 p-60 d-4 o-35 p-77 d-5 o-36 p-60 d-3 o-41 p-75 d-5 p-45 d-5 o-42 p-60 d-3 o-47 p-74 d-4 p-62 d-2 p-46 d-17 i-49 o-5 p-72 d-2 p-58 d-10 o-8 p-74 d-2 o-11 p-75 d-5 o-12 p-55 d-10 p-43 d-10 o-17 p-74 d-2 o-18 p-67 d-3 o-20 p-75 d-2 o-23 p-77 d-5 p-65 d-9 p-33 d-15 o-24 p-45 d-17 o-29 p-72 d-5 p-60 d-4 o-35 p-77 d-5 o-36 p-60 d-3 o-41 p-75 d-5 p-33 d-4 o-42 p-60 d-3 p-45 d-4 o-47 p-74 d-5 p-34 d-12 i-70 o-0 p-50 d-10 o-12 p-55 d-10 o-24 p-45 d-13 o-30 p-60 d-4 o-36 p-60 d-4 o-42 p-60 d-4 p-45 d-3 b-1 s-9 t-27 i-71 o-0 p-74 d-4 o-6 p-65 d-4 o-12 p-70 d-23 o-36 p-69 d-10 o-47 p-70 d-4 i-52 o-2 p-63 d-2 o-5 p-65 d-5 p-62 d-2 o-8 p-60 d-2 o-11 p-62 d-2 o-12 p-70 d-22 o-14 p-63 d-2 o-17 p-60 d-2 p-46 d-5 o-20 p-62 d-2 o-23 p-63 d-2 p-48 d-16 o-26 p-65 d-2 o-29 p-63 d-2 o-32 p-62 d-1 o-35 p-69 d-12 p-63 d-1 o-38 p-65 d-2 o-41 p-62 d-1 p-46 d-2 o-43 p-63 d-2 o-44 p-48 d-2 o-47 p-70 d-5 p-65 d-5 p-50 d-3 i-70 o-0 p-62 d-2 p-46 d-12 o-3 p-63 d-2 o-6 p-62 d-1 o-8 p-60 d-2 o-12 p-62 d-1 o-14 p-63 d-2 o-17 p-60 d-2 o-18 p-46 d-2 o-20 p-62 d-2 o-23 p-63 d-2 o-24 p-48 d-14 o-26 p-65 d-2 o-29 p-63 d-2 o-32 p-62 d-1 o-35 p-63 d-2 o-38 p-65 d-1 o-41 p-62 d-2 p-46 d-1 o-44 p-63 d-1 p-48 d-1 o-47 p-65 d-4 p-50 d-2 i-49 o-0 p-62 d-1 p-46 d-15 o-2 p-63 d-2 o-5 p-65 d-6 p-62 d-1 o-8 p-60 d-2 o-11 p-62 d-2 o-12 p-70 d-22 o-14 p-63 d-2 o-17 p-60 d-2 p-46 d-5 p-34 d-4 o-20 p-62 d-2 o-23 p-63 d-2 p-48 d-16 p-36 d-14 o-26 p-65 d-2 o-29 p-63 d-1 o-32 p-62 d-1 o-35 p-69 d-11 p-63 d-1 o-38 p-65 d-1 o-41 p-62 d-1 p-46 d-1 p-34 d-2 o-43 p-63 d-2 o-44 p-48 d-2 p-36 d-2 o-47 p-70 d-4 p-65 d-4 p-50 d-4 p-38 d-4 b-1 s-9 t-27 i-71 o-5 p-70 d-4 o-11 p-70 d-24 o-24 p-72 d-16 o-41 p-72 d-1 o-42 p-72 d-4 o-47 p-68 d-1 i-52 o-5 p-70 d-5 p-62 d-5 p-58 d-1 o-8 p-57 d-2 o-11 p-70 d-24 p-64 d-5 p-55 d-5 o-17 p-65 d-5 p-53 d-5 o-23 p-72 d-17 p-67 d-11 p-52 d-5 o-29 p-55 d-5 o-35 p-68 d-6 p-65 d-5 p-48 d-10 o-41 p-72 d-6 p-67 d-5 p-64 d-5 o-47 p-68 d-12 p-68 d-9 p-65 d-6 i-70 o-5 p-58 d-2 o-6 p-62 d-3 o-8 p-57 d-1 o-11 p-55 d-4 o-12 p-64 d-3 o-17 p-53 d-4 o-18 p-65 d-4 o-24 p-67 d-10 p-52 d-3 o-30 p-55 d-3 o-35 p-48 d-12 o-36 p-65 d-4 o-42 p-64 d-4 i-49 o-5 p-70 d-5 p-62 d-5 p-58 d-1 p-46 d-2 o-8 p-57 d-1 p-45 d-1 o-11 p-70 d-24 p-64 d-5 p-55 d-5 p-43 d-4 o-17 p-65 d-5 p-53 d-5 p-41 d-4 o-23 p-67 d-12 p-52 d-5 p-40 d-5 o-24 p-72 d-16 o-29 p-55 d-5 p-43 d-4 o-35 p-68 d-6 p-65 d-5 p-48 d-12 p-36 d-13 o-41 p-72 d-6 p-67 d-6 p-64 d-6 o-47 p-68 d-10 p-65 d-6 b-1 s-9 t-27 i-71 o-0 p-68 d-10 o-12 p-73 d-9 p-73 d-1 o-24 p-64 d-4 p-64 d-1 o-42 p-64 d-4 i-52 o-5 p-53 d-5 o-11 p-58 d-5 o-12 p-73 d-11 o-17 p-55 d-5 o-23 p-64 d-17 p-60 d-8 o-29 p-48 d-3 o-35 p-48 d-4 o-41 p-64 d-5 p-48 d-4 o-47 p-65 d-11 p-49 d-2 i-70 o-0 p-65 d-4 o-6 p-53 d-4 o-12 p-58 d-4 o-18 p-55 d-4 o-24 p-60 d-7 o-30 p-48 d-3 o-36 p-48 d-4 o-42 p-48 d-4 i-49 o-0 p-68 d-11 o-5 p-53 d-5 o-6 p-53 d-4 p-41 d-4 o-11 p-58 d-6 p-58 d-5 p-46 d-5 o-12 p-73 d-11 o-17 p-55 d-5 p-55 d-4 p-43 d-4 o-23 p-60 d-7 p-60 d-3 p-48 d-3 o-24 p-64 d-16 o-29 p-48 d-2 p-36 d-4 o-35 p-48 d-2 p-36 d-4 o-41 p-64 d-5 p-48 d-2 p-36 d-4 o-47 p-65 d-8 p-49 d-2 p-37 d-2 b-1 s-9 t-27 i-71 o-0 p-65 d-6 o-6 p-65 d-3 o-11 p-70 d-5 o-17 p-68 d-5 o-23 p-67 d-4 o-29 p-60 d-5 o-35 p-72 d-5 o-42 p-70 d-4 i-52 o-2 p-51 d-2 o-5 p-65 d-4 p-49 d-1 o-8 p-48 d-2 o-11 p-70 d-5 p-50 d-2 o-14 p-51 d-2 o-17 p-68 d-4 p-48 d-2 o-20 p-50 d-2 o-23 p-67 d-4 p-51 d-2 o-26 p-53 d-2 o-28 p-60 d-6 o-29 p-55 d-4 p-51 d-1 o-32 p-50 d-2 o-35 p-72 d-5 p-55 d-4 p-52 d-2 o-38 p-53 d-1 o-41 p-70 d-5 p-55 d-5 p-50 d-2 o-44 p-52 d-1 o-47 p-68 d-5 p-56 d-2 p-53 d-4 i-70 o-0 p-49 d-1 o-2 p-51 d-2 o-5 p-49 d-2 o-8 p-48 d-2 o-11 p-50 d-2 o-14 p-51 d-2 o-17 p-48 d-2 o-20 p-50 d-1 o-23 p-51 d-1 o-26 p-53 d-1 o-29 p-50 d-2 o-30 p-55 d-4 o-32 p-51 d-1 o-35 p-52 d-2 o-36 p-55 d-4 o-38 p-53 d-2 o-41 p-50 d-2 o-42 p-55 d-4 o-45 p-52 d-1 i-49 o-2 p-51 d-2 p-39 d-2 o-5 p-65 d-6 p-49 d-2 p-37 d-1 o-7 p-36 d-2 o-8 p-48 d-1 o-11 p-70 d-5 p-50 d-2 p-38 d-1 o-14 p-51 d-2 p-39 d-2 o-17 p-68 d-5 p-48 d-2 p-36 d-1 o-20 p-50 d-1 p-38 d-1 o-23 p-67 d-5 p-51 d-2 p-39 d-2 o-26 p-53 d-1 p-41 d-1 o-29 p-60 d-5 p-55 d-3 p-51 d-2 p-39 d-1 o-32 p-50 d-1 p-38 d-1 o-35 p-72 d-5 p-55 d-3 p-52 d-2 p-40 d-1 o-38 p-53 d-2 p-41 d-1 o-41 p-70 d-5 p-55 d-3 p-50 d-1 p-38 d-1 o-44 p-52 d-1 p-40 d-1 o-47 p-68 d-7 p-56 d-2 p-41 d-4 b-1 s-9 t-27 i-71 o-0 p-68 d-4 o-29 p-62 d-3 o-36 p-62 d-3 o-42 p-62 d-4 i-52 o-2 p-58 d-2 o-5 p-56 d-2 p-48 d-4 o-8 p-55 d-2 o-11 p-57 d-2 p-53 d-4 o-14 p-58 d-2 o-17 p-55 d-2 p-51 d-5 o-20 p-57 d-2 o-23 p-58 d-2 p-50 d-4 o-26 p-60 d-2 o-29 p-62 d-4 p-58 d-2 p-43 d-5 o-32 p-57 d-1 o-35 p-62 d-4 p-59 d-2 p-55 d-4 o-38 p-60 d-1 o-41 p-57 d-1 p-53 d-5 o-42 p-62 d-4 o-44 p-59 d-2 o-47 p-63 d-2 p-60 d-4 p-51 d-5 i-70 o-0 p-56 d-2 p-53 d-3 o-3 p-58 d-1 o-6 p-56 d-1 p-48 d-3 o-8 p-55 d-3 o-12 p-57 d-1 p-53 d-4 o-14 p-58 d-2 o-17 p-55 d-2 o-18 p-51 d-3 o-20 p-57 d-2 o-23 p-58 d-2 p-50 d-4 o-26 p-60 d-2 o-29 p-58 d-2 p-43 d-4 o-32 p-57 d-2 o-35 p-55 d-5 o-36 p-59 d-1 o-38 p-60 d-2 o-41 p-57 d-2 o-42 p-53 d-4 o-44 p-59 d-2 i-49 o-0 p-53 d-3 o-2 p-58 d-2 o-5 p-56 d-2 p-48 d-4 p-36 d-4 o-8 p-55 d-2 o-11 p-57 d-2 p-53 d-4 p-41 d-4 o-14 p-58 d-2 o-17 p-55 d-2 p-51 d-4 p-39 d-4 o-20 p-57 d-2 o-23 p-58 d-2 p-50 d-4 p-38 d-4 o-26 p-60 d-1 o-29 p-62 d-2 p-58 d-1 p-43 d-4 p-31 d-4 o-32 p-57 d-1 o-35 p-62 d-2 p-59 d-2 p-55 d-4 p-43 d-4 o-38 p-60 d-2 o-41 p-57 d-1 p-53 d-4 p-41 d-4 o-42 p-62 d-1 o-44 p-59 d-2 o-47 p-51 d-3 p-39 d-4 b-1 s-9 t-27 i-71 o-0 p-63 d-2 o-3 p-65 d-2 o-6 p-63 d-1 o-8 p-62 d-2 o-12 p-64 d-1 o-14 p-65 d-2 o-17 p-62 d-2 o-21 p-64 d-1 o-24 p-65 d-2 o-27 p-67 d-1 o-30 p-69 d-3 p-65 d-1 o-32 p-64 d-2 o-36 p-69 d-4 p-66 d-1 o-38 p-67 d-2 o-42 p-69 d-4 p-64 d-1 o-44 p-66 d-2 i-52 o-2 p-65 d-2 o-5 p-63 d-2 p-55 d-5 o-8 p-62 d-2 o-11 p-64 d-2 p-60 d-5 o-14 p-65 d-2 o-17 p-62 d-2 p-58 d-4 o-20 p-64 d-2 o-22 p-57 d-6 o-23 p-65 d-2 o-26 p-67 d-2 o-29 p-69 d-4 p-65 d-2 p-53 d-4 o-31 p-64 d-3 o-35 p-69 d-4 p-66 d-2 p-62 d-5 o-38 p-67 d-3 o-41 p-69 d-5 p-64 d-2 p-60 d-5 o-44 p-66 d-2 o-47 p-70 d-2 p-67 d-5 p-58 d-6 i-49 o-0 p-63 d-1 p-60 d-4 o-2 p-65 d-2 o-5 p-55 d-5 p-55 d-4 p-43 d-4 o-6 p-63 d-1 o-8 p-62 d-1 o-11 p-64 d-2 p-60 d-4 p-48 d-4 o-12 p-60 d-4 o-14 p-65 d-2 o-17 p-62 d-1 p-58 d-5 p-58 d-4 p-46 d-5 o-20 p-64 d-1 o-23 p-65 d-2 p-57 d-6 p-57 d-4 p-45 d-4 o-26 p-67 d-1 o-29 p-65 d-2 p-50 d-5 p-50 d-4 p-38 d-5 o-30 p-69 d-3 o-32 p-64 d-2 o-35 p-69 d-4 p-66 d-2 p-62 d-5 p-62 d-5 p-50 d-4 o-38 p-67 d-2 o-41 p-64 d-2 p-60 d-5 p-48 d-5 o-42 p-69 d-4 p-60 d-4 o-44 p-66 d-2 o-47 p-67 d-4 p-58 d-4 p-46 d-5 i-70 o-0 p-60 d-3 p-51 d-6 o-6 p-55 d-4 o-12 p-60 d-3 o-18 p-58 d-4 o-24 p-57 d-2 o-30 p-50 d-4 o-36 p-62 d-4 o-42 p-60 d-4 b-1 s-9 t-27 i-71 o-0 p-70 d-2 p-67 d-4 o-3 p-72 d-2 o-6 p-70 d-2 p-62 d-4 o-9 p-69 d-1 o-12 p-71 d-2 p-67 d-4 o-14 p-72 d-2 o-18 p-69 d-1 p-65 d-4 o-20 p-71 d-2 o-24 p-72 d-1 p-64 d-3 o-26 p-74 d-2 o-29 p-72 d-2 o-30 p-57 d-4 o-32 p-71 d-2 o-36 p-73 d-1 p-69 d-4 o-38 p-74 d-2 o-42 p-71 d-1 p-67 d-4 o-44 p-73 d-2 i-52 o-2 p-72 d-2 o-5 p-70 d-2 o-6 p-62 d-4 o-8 p-69 d-2 o-11 p-71 d-2 p-67 d-5 o-14 p-72 d-2 o-17 p-69 d-2 p-65 d-5 o-20 p-71 d-2 o-23 p-72 d-2 p-64 d-5 o-26 p-74 d-2 o-29 p-72 d-2 p-57 d-5 o-30 p-55 d-3 p-52 d-3 o-32 p-71 d-2 o-35 p-73 d-2 p-69 d-5 o-36 p-55 d-3 p-52 d-3 o-38 p-74 d-2 o-41 p-71 d-1 p-67 d-5 p-52 d-5 o-42 p-57 d-4 o-44 p-73 d-2 o-47 p-74 d-5 p-65 d-9 i-49 o-0 p-70 d-2 p-58 d-4 o-3 p-72 d-1 o-6 p-70 d-2 p-62 d-4 p-62 d-3 p-38 d-4 o-8 p-69 d-2 o-11 p-67 d-4 o-12 p-71 d-1 p-67 d-4 p-43 d-3 o-14 p-72 d-2 o-17 p-69 d-2 o-18 p-65 d-4 p-65 d-3 p-41 d-3 o-20 p-71 d-2 o-23 p-72 d-2 p-64 d-3 o-24 p-64 d-1 p-40 d-2 o-26 p-74 d-2 o-29 p-57 d-3 p-55 d-4 o-30 p-72 d-1 p-52 d-2 p-40 d-2 o-32 p-71 d-2 o-35 p-73 d-2 p-55 d-4 o-36 p-69 d-3 p-52 d-1 p-40 d-3 o-38 p-74 d-2 o-41 p-67 d-3 p-57 d-4 p-52 d-3 o-42 p-71 d-1 p-40 d-3 o-44 p-73 d-2 o-47 p-65 d-9 p-57 d-9 i-70 o-0 p-58 d-6 o-30 p-55 d-3 p-52 d-4 o-36 p-55 d-4 p-52 d-4 o-42 p-57 d-3 p-52 d-4 b-1 s-9 t-27 i-71 o-0 p-74 d-4 p-65 d-9 o-6 p-69 d-4 o-12 p-74 d-4 p-69 d-7 o-18 p-72 d-4 o-21 p-69 d-2 o-24 p-71 d-3 p-62 d-5 o-30 p-71 d-3 p-71 d-1 o-36 p-76 d-4 p-71 d-10 o-42 p-74 d-4 i-56 o-0 p-74 d-10 p-62 d-10 o-12 p-74 d-10 p-62 d-10 o-24 p-74 d-8 p-62 d-9 i-52 o-0 p-57 d-8 p-53 d-1 o-2 p-55 d-2 o-5 p-69 d-5 p-53 d-2 o-8 p-52 d-2 o-11 p-74 d-5 p-54 d-2 o-12 p-69 d-6 p-57 d-6 o-14 p-55 d-2 o-17 p-72 d-5 p-52 d-2 o-20 p-69 d-2 p-54 d-2 o-21 p-57 d-1 o-23 p-71 d-5 p-62 d-5 p-55 d-2 o-24 p-59 d-9 o-26 p-57 d-2 o-29 p-64 d-5 p-55 d-1 o-30 p-71 d-3 o-32 p-54 d-1 o-35 p-76 d-5 p-56 d-1 o-36 p-71 d-10 p-59 d-7 o-38 p-57 d-1 o-41 p-74 d-4 p-54 d-1 o-44 p-59 d-2 p-56 d-1 o-47 p-73 d-7 p-64 d-5 p-61 d-5 p-57 d-2 i-49 o-0 p-74 d-4 p-53 d-1 p-41 d-1 o-2 p-55 d-2 p-43 d-2 o-5 p-53 d-2 p-41 d-1 o-6 p-69 d-4 o-8 p-52 d-1 p-40 d-1 o-11 p-42 d-1 o-12 p-74 d-4 p-69 d-6 p-57 d-6 p-54 d-1 o-14 p-55 d-2 p-43 d-1 o-17 p-72 d-5 p-52 d-2 p-40 d-1 o-20 p-69 d-2 p-54 d-2 p-42 d-1 o-21 p-57 d-1 o-23 p-71 d-5 p-59 d-8 p-55 d-2 p-43 d-2 o-24 p-62 d-3 o-26 p-57 d-2 p-45 d-2 o-29 p-71 d-3 p-55 d-1 p-43 d-1 o-30 p-64 d-4 o-32 p-54 d-1 p-42 d-1 o-35 p-76 d-5 p-71 d-8 p-56 d-1 p-44 d-1 o-36 p-59 d-6 o-38 p-57 d-1 p-45 d-1 o-41 p-74 d-5 p-54 d-1 p-42 d-1 o-43 p-44 d-1 o-44 p-59 d-2 p-56 d-1 o-47 p-73 d-11 p-64 d-4 p-61 d-5 p-57 d-17 p-45 d-15 i-70 o-0 p-57 d-9 p-53 d-2 o-3 p-55 d-1 o-6 p-53 d-1 o-9 p-52 d-1 o-12 p-57 d-7 p-54 d-1 o-14 p-55 d-2 o-18 p-52 d-1 o-21 p-57 d-1 p-54 d-1 o-24 p-59 d-9 p-55 d-1 o-27 p-57 d-1 o-30 p-55 d-1 o-32 p-54 d-2 o-35 p-56 d-2 o-36 p-59 d-7 o-38 p-57 d-2 o-41 p-54 d-2 o-44 p-56 d-2 o-45 p-59 d-2 i-47 o-0 p-50 d-1 p-38 d-1 o-6 p-50 d-1 p-38 d-1 o-9 p-50 d-1 p-38 d-1 o-11 p-50 d-1 p-38 d-1 o-18 p-50 d-1 p-38 d-1 o-20 p-50 d-1 p-38 d-1 o-23 p-50 d-1 p-38 d-1 b-1 s-9 t-27 i-71 o-0 p-73 d-8 p-64 d-3 o-6 p-61 d-5 o-12 p-62 d-4 o-18 p-64 d-4 o-24 p-65 d-4 o-30 p-64 d-1 o-33 p-65 d-1 o-36 p-67 d-4 o-41 p-65 d-2 o-44 p-67 d-2 i-56 o-6 p-69 d-2 p-57 d-2 o-12 p-69 d-2 p-57 d-1 o-18 p-69 d-2 p-57 d-1 o-24 p-69 d-9 p-62 d-8 o-36 p-74 d-6 p-62 d-8 i-52 o-5 p-61 d-6 o-6 p-57 d-10 p-57 d-5 o-11 p-62 d-5 p-59 d-5 o-17 p-64 d-5 p-61 d-5 p-57 d-5 o-23 p-65 d-6 p-62 d-16 p-53 d-11 o-29 p-64 d-2 o-32 p-65 d-2 o-35 p-67 d-5 p-58 d-11 o-41 p-65 d-2 p-62 d-5 o-44 p-67 d-2 o-47 p-69 d-5 p-64 d-11 p-49 d-17 i-70 o-0 p-61 d-4 p-57 d-3 o-6 p-57 d-4 p-57 d-1 o-12 p-59 d-3 o-18 p-61 d-4 p-57 d-3 o-24 p-62 d-15 p-53 d-9 o-35 p-58 d-11 o-42 p-62 d-4 i-49 o-6 p-61 d-4 p-57 d-4 o-11 p-59 d-4 o-12 p-62 d-4 o-17 p-61 d-4 o-18 p-64 d-4 p-57 d-4 p-45 d-4 o-23 p-62 d-16 p-53 d-11 p-41 d-11 o-24 p-65 d-4 o-30 p-64 d-1 o-32 p-65 d-2 o-35 p-46 d-11 o-36 p-67 d-4 p-58 d-10 o-42 p-65 d-1 p-62 d-4 o-44 p-67 d-2 o-47 p-69 d-5 p-37 d-17 i-47 o-6 p-45 d-1 p-33 d-1 o-12 p-45 d-1 p-33 d-1 o-18 p-45 d-1 p-33 d-1 o-24 p-50 d-2 p-38 d-1 o-36 p-50 d-1 p-38 d-1 b-1 s-9 t-27 i-71 o-0 p-69 d-4 o-6 p-76 d-3 p-70 d-4 o-12 p-76 d-4 p-69 d-5 o-18 p-76 d-4 p-67 d-4 o-24 p-77 d-2 p-65 d-4 o-27 p-79 d-2 o-30 p-77 d-2 p-69 d-4 o-33 p-76 d-1 o-36 p-77 d-1 p-74 d-23 o-38 p-79 d-2 o-42 p-76 d-1 o-44 p-77 d-2 i-52 o-5 p-76 d-4 p-70 d-5 o-11 p-76 d-4 p-69 d-5 p-57 d-16 o-17 p-76 d-5 p-67 d-5 p-49 d-5 o-23 p-77 d-3 p-65 d-5 p-50 d-14 o-26 p-79 d-2 o-29 p-69 d-5 p-53 d-5 o-30 p-77 d-2 o-32 p-76 d-2 o-35 p-77 d-2 p-74 d-23 p-58 d-17 o-38 p-79 d-3 o-41 p-76 d-3 p-50 d-5 o-44 p-77 d-2 o-47 p-79 d-2 p-52 d-16 i-49 o-0 p-64 d-10 p-49 d-16 o-5 p-70 d-5 o-6 p-76 d-2 o-11 p-76 d-3 o-12 p-69 d-4 p-57 d-15 o-18 p-76 d-3 p-67 d-4 p-49 d-4 p-37 d-4 o-24 p-77 d-1 p-65 d-4 p-50 d-16 p-38 d-15 o-26 p-79 d-2 o-29 p-77 d-2 p-69 d-4 p-53 d-6 o-32 p-76 d-2 o-35 p-77 d-2 p-74 d-23 o-36 p-58 d-14 o-38 p-79 d-2 o-41 p-76 d-2 p-50 d-5 o-42 p-38 d-4 o-44 p-77 d-2 o-47 p-79 d-2 i-56 o-0 p-69 d-8 p-57 d-8 i-70 o-0 p-64 d-10 p-49 d-13 o-12 p-57 d-15 o-18 p-49 d-3 o-24 p-50 d-14 o-29 p-53 d-5 o-36 p-58 d-14 o-42 p-50 d-4 i-47 o-0 p-45 d-1 p-33 d-1 b-1 s-9 t-27 i-71 o-0 p-79 d-15 o-12 p-73 d-10 o-18 p-77 d-1 o-20 p-76 d-3 o-24 p-74 d-9 o-36 p-79 d-1 o-38 p-77 d-2 o-42 p-76 d-1 o-44 p-74 d-2 i-52 o-2 p-81 d-2 o-5 p-79 d-2 p-55 d-5 o-8 p-77 d-2 o-11 p-79 d-2 p-73 d-11 p-64 d-5 o-14 p-81 d-2 o-17 p-77 d-2 p-64 d-5 p-50 d-2 o-20 p-79 d-2 p-52 d-1 o-23 p-81 d-5 p-62 d-5 p-53 d-5 o-29 p-82 d-2 p-61 d-2 p-52 d-2 o-32 p-81 d-2 p-62 d-2 p-53 d-1 o-35 p-79 d-2 p-64 d-2 p-55 d-5 o-38 p-77 d-2 p-65 d-2 o-41 p-76 d-2 p-67 d-2 p-53 d-2 o-44 p-74 d-2 p-65 d-2 p-55 d-2 o-47 p-73 d-5 p-64 d-5 p-57 d-5 i-49 o-0 p-52 d-15 p-40 d-15 o-2 p-81 d-2 o-5 p-79 d-2 p-55 d-5 o-8 p-77 d-2 o-11 p-79 d-2 p-73 d-10 p-64 d-5 o-14 p-81 d-2 o-17 p-77 d-1 p-64 d-5 p-50 d-2 p-38 d-2 o-20 p-79 d-1 p-52 d-1 p-40 d-1 o-23 p-81 d-5 p-62 d-5 p-53 d-5 p-41 d-5 o-29 p-82 d-2 p-61 d-2 p-52 d-1 p-40 d-2 o-32 p-81 d-2 p-62 d-2 p-53 d-1 p-41 d-1 o-35 p-79 d-2 p-64 d-2 p-55 d-4 p-43 d-5 o-38 p-77 d-1 p-65 d-2 o-41 p-76 d-1 p-67 d-2 p-53 d-1 p-41 d-1 o-43 p-74 d-2 o-44 p-65 d-2 p-55 d-1 p-43 d-1 o-47 p-73 d-4 p-64 d-5 p-57 d-5 p-45 d-5 i-70 o-0 p-52 d-15 o-6 p-55 d-4 o-12 p-64 d-4 o-18 p-64 d-4 p-50 d-1 o-21 p-52 d-1 o-23 p-53 d-5 o-24 p-62 d-4 o-30 p-61 d-2 p-52 d-1 o-32 p-62 d-2 p-53 d-2 o-36 p-64 d-1 p-55 d-4 o-38 p-65 d-2 o-41 p-67 d-2 p-53 d-2 o-44 p-65 d-2 p-55 d-1 o-47 p-57 d-4 b-1 s-9 t-27 i-71 o-0 p-73 d-4 o-6 p-74 d-3 o-11 p-76 d-17 o-12 p-70 d-14 o-29 p-70 d-5 o-30 p-79 d-5 o-36 p-77 d-5 p-69 d-4 o-42 p-76 d-5 p-69 d-4 i-56 o-30 p-69 d-2 p-57 d-1 o-36 p-69 d-1 p-57 d-1 o-42 p-69 d-1 p-57 d-1 o-47 p-74 d-24 p-62 d-24 i-52 o-5 p-74 d-4 p-62 d-5 p-58 d-2 o-8 p-57 d-2 o-11 p-76 d-17 p-61 d-7 p-55 d-1 o-12 p-70 d-15 o-14 p-53 d-1 o-16 p-52 d-2 o-19 p-50 d-2 o-20 p-62 d-2 o-23 p-64 d-11 p-49 d-11 o-29 p-70 d-5 o-30 p-79 d-4 o-35 p-69 d-5 p-57 d-6 p-50 d-6 o-36 p-77 d-4 o-41 p-76 d-5 p-69 d-5 p-61 d-5 o-42 p-57 d-4 o-47 p-74 d-16 p-69 d-12 p-62 d-6 p-58 d-17 i-49 o-5 p-74 d-4 p-62 d-4 p-58 d-1 p-46 d-1 o-8 p-57 d-1 p-45 d-1 o-11 p-76 d-16 p-61 d-7 p-55 d-1 p-43 d-1 o-12 p-70 d-15 o-14 p-53 d-1 p-41 d-1 o-16 p-40 d-2 o-17 p-52 d-1 o-19 p-50 d-2 p-38 d-2 o-20 p-62 d-2 o-23 p-64 d-11 p-49 d-11 p-37 d-11 o-29 p-79 d-5 p-70 d-5 o-35 p-77 d-5 p-57 d-6 o-36 p-69 d-4 p-50 d-4 p-38 d-4 o-41 p-76 d-5 p-61 d-6 p-57 d-5 p-45 d-4 o-42 p-69 d-4 o-47 p-74 d-17 p-62 d-5 p-58 d-11 p-46 d-11 i-70 o-0 p-64 d-4 o-5 p-58 d-2 o-6 p-62 d-4 o-8 p-57 d-1 o-11 p-55 d-2 o-12 p-61 d-7 o-14 p-53 d-1 o-17 p-52 d-2 o-20 p-50 d-2 o-21 p-62 d-1 o-23 p-49 d-11 o-24 p-64 d-9 o-35 p-57 d-5 o-36 p-50 d-4 o-42 p-61 d-4 p-57 d-4 i-47 o-30 p-45 d-1 p-33 d-1 o-36 p-50 d-1 p-38 d-1 o-42 p-45 d-1 p-33 d-1 b-1 s-9 t-27 i-71 o-0 p-74 d-15 p-69 d-11 o-12 p-68 d-11 o-18 p-74 d-5 o-24 p-73 d-4 p-69 d-2 o-30 p-73 d-5 p-69 d-10 o-36 p-74 d-4 o-41 p-76 d-5 o-42 p-69 d-4 o-47 p-69 d-11 i-52 o-5 p-65 d-5 o-11 p-68 d-12 p-64 d-5 o-17 p-74 d-5 p-62 d-5 p-58 d-6 o-23 p-73 d-5 p-69 d-5 p-64 d-4 p-57 d-6 o-29 p-73 d-6 p-69 d-11 p-57 d-5 o-35 p-74 d-5 p-59 d-5 o-41 p-76 d-5 p-69 d-6 p-61 d-5 o-47 p-69 d-10 p-65 d-11 p-62 d-4 i-56 o-24 p-69 d-4 p-57 d-5 i-70 o-0 p-62 d-4 p-58 d-15 o-6 p-65 d-4 o-12 p-64 d-4 o-17 p-62 d-5 o-18 p-58 d-4 o-24 p-64 d-4 p-57 d-6 o-30 p-57 d-1 o-36 p-59 d-4 o-42 p-61 d-4 i-49 o-0 p-69 d-11 o-5 p-65 d-7 o-11 p-64 d-5 o-12 p-68 d-12 p-46 d-10 p-34 d-10 o-17 p-62 d-6 o-18 p-74 d-5 o-23 p-64 d-5 p-45 d-5 o-24 p-73 d-4 p-69 d-4 p-33 d-4 o-29 p-73 d-6 o-30 p-69 d-8 p-57 d-4 p-57 d-3 p-45 d-4 o-35 p-74 d-6 p-59 d-5 p-59 d-5 p-47 d-5 o-41 p-76 d-6 p-69 d-5 p-61 d-5 p-61 d-5 p-49 d-5 o-47 p-69 d-11 p-65 d-11 p-62 d-5 p-50 d-4 i-47 o-0 p-50 d-1 p-38 d-1 o-6 p-50 d-1 p-38 d-1 o-8 p-50 d-1 p-38 d-1 o-11 p-50 d-1 p-38 d-1 o-17 p-50 d-1 p-38 d-1 o-24 p-45 d-1 p-33 d-1 b-1 s-9 t-27 i-71 o-0 p-65 d-10 o-12 p-70 d-7 p-70 d-1 o-24 p-61 d-15 o-42 p-61 d-4 i-52 o-5 p-50 d-6 o-11 p-70 d-11 p-55 d-5 o-17 p-52 d-6 o-23 p-57 d-6 o-24 p-61 d-16 o-29 p-58 d-5 o-30 p-45 d-3 o-35 p-57 d-5 p-45 d-4 o-41 p-61 d-6 p-55 d-6 p-45 d-5 o-47 p-62 d-14 p-53 d-5 p-46 d-2 i-70 o-0 p-62 d-4 o-6 p-50 d-4 o-12 p-55 d-4 o-17 p-52 d-5 o-24 p-57 d-4 o-30 p-58 d-4 p-45 d-4 o-36 p-57 d-4 p-45 d-4 o-42 p-55 d-5 p-45 d-4 i-49 o-0 p-62 d-4 o-5 p-50 d-6 p-50 d-5 p-38 d-6 o-11 p-55 d-5 p-55 d-5 p-46 d-5 o-12 p-70 d-10 o-17 p-52 d-5 p-52 d-5 p-43 d-5 o-23 p-57 d-5 p-57 d-3 o-24 p-61 d-15 o-29 p-58 d-5 p-33 d-4 o-30 p-45 d-2 o-35 p-57 d-5 p-45 d-3 p-33 d-4 o-41 p-55 d-5 p-45 d-2 p-33 d-4 o-42 p-61 d-4 o-47 p-62 d-14 p-53 d-5 p-46 d-2 p-34 d-2 b-1 s-9 t-27 i-71 o-0 p-62 d-13 o-18 p-62 d-4 o-24 p-64 d-15 o-30 p-69 d-1 o-35 p-69 d-2 o-42 p-69 d-1 p-62 d-1 o-44 p-64 d-2 o-47 p-70 d-2 i-52 o-2 p-48 d-2 o-5 p-50 d-5 p-46 d-1 o-8 p-45 d-1 o-11 p-55 d-6 p-47 d-2 o-14 p-48 d-2 o-17 p-62 d-5 p-53 d-6 p-45 d-2 o-20 p-47 d-2 o-23 p-52 d-5 p-48 d-2 o-24 p-64 d-14 o-26 p-50 d-2 o-29 p-69 d-3 p-48 d-5 p-48 d-1 o-32 p-47 d-1 o-35 p-69 d-3 p-57 d-4 p-49 d-1 o-38 p-50 d-2 o-41 p-69 d-4 p-62 d-2 p-57 d-4 p-47 d-2 o-44 p-64 d-1 p-49 d-1 o-47 p-70 d-2 p-65 d-11 p-53 d-11 p-50 d-3 i-70 o-0 p-53 d-4 p-46 d-1 o-2 p-48 d-2 o-5 p-46 d-2 o-6 p-50 d-4 o-8 p-45 d-2 o-11 p-47 d-2 o-12 p-55 d-4 o-14 p-48 d-2 o-18 p-53 d-4 p-45 d-1 o-20 p-47 d-2 o-24 p-52 d-4 p-48 d-1 o-26 p-50 d-2 o-29 p-48 d-1 o-30 p-48 d-1 o-32 p-47 d-1 o-35 p-49 d-2 o-36 p-57 d-4 o-38 p-50 d-1 o-41 p-47 d-2 o-42 p-57 d-4 o-44 p-49 d-2 o-47 p-50 d-4 i-49 o-2 p-48 d-1 p-36 d-2 o-5 p-50 d-5 p-46 d-1 p-34 d-1 o-8 p-45 d-1 p-33 d-1 o-11 p-55 d-5 p-47 d-2 p-35 d-2 o-14 p-48 d-2 p-36 d-1 o-17 p-62 d-5 p-53 d-5 p-45 d-2 p-33 d-2 o-20 p-47 d-2 p-35 d-1 o-23 p-52 d-4 p-36 d-2 o-24 p-64 d-15 p-48 d-1 o-26 p-50 d-2 p-38 d-2 o-29 p-69 d-3 p-48 d-5 p-48 d-2 p-36 d-1 o-32 p-47 d-1 p-35 d-1 o-35 p-69 d-4 p-57 d-5 p-49 d-2 p-37 d-2 o-38 p-50 d-2 p-38 d-1 o-41 p-69 d-4 p-62 d-2 p-57 d-3 p-47 d-1 p-35 d-1 o-44 p-64 d-1 p-49 d-1 p-37 d-1 o-47 p-70 d-2 p-65 d-9 p-53 d-10 p-50 d-4 p-38 d-3 b-1 s-9 t-27 i-71 o-0 p-65 d-8 o-2 p-72 d-2 o-6 p-70 d-1 o-8 p-69 d-2 o-12 p-71 d-1 o-14 p-72 d-2 o-17 p-69 d-2 o-20 p-71 d-2 o-23 p-72 d-2 o-26 p-74 d-2 o-30 p-72 d-1 p-64 d-2 o-32 p-71 d-2 o-35 p-73 d-2 o-36 p-64 d-2 o-39 p-74 d-1 o-42 p-71 d-1 p-64 d-3 o-44 p-73 d-2 i-52 o-2 p-72 d-2 o-5 p-70 d-2 o-6 p-50 d-3 o-8 p-69 d-2 o-11 p-71 d-2 p-62 d-11 p-55 d-4 o-14 p-72 d-2 o-17 p-69 d-2 p-53 d-4 o-20 p-71 d-2 o-23 p-72 d-2 p-55 d-7 p-52 d-4 o-26 p-74 d-2 o-29 p-72 d-2 p-64 d-4 p-52 d-4 o-32 p-71 d-2 o-35 p-73 d-2 p-64 d-5 p-57 d-4 o-38 p-74 d-2 o-41 p-71 d-2 p-64 d-5 p-55 d-5 o-44 p-73 d-2 o-47 p-74 d-8 p-65 d-2 p-53 d-7 i-49 o-2 p-72 d-2 o-5 p-70 d-2 p-50 d-5 p-38 d-4 o-8 p-69 d-2 o-11 p-71 d-2 p-55 d-4 p-43 d-4 o-12 p-62 d-9 o-14 p-72 d-3 o-17 p-53 d-4 p-41 d-4 o-18 p-69 d-1 o-20 p-71 d-2 o-23 p-72 d-2 p-52 d-4 p-40 d-4 o-24 p-55 d-7 o-26 p-74 d-2 o-29 p-72 d-2 p-64 d-3 p-52 d-4 p-40 d-4 o-32 p-71 d-2 o-35 p-73 d-2 p-64 d-3 p-57 d-4 p-45 d-4 o-38 p-74 d-2 o-41 p-71 d-2 p-64 d-3 p-55 d-5 p-43 d-4 o-44 p-73 d-2 o-47 p-74 d-7 p-65 d-2 p-53 d-4 p-41 d-5 i-70 o-0 p-53 d-9 o-6 p-50 d-4 o-12 p-62 d-9 p-55 d-3 o-18 p-53 d-3 o-24 p-55 d-9 p-52 d-3 o-30 p-52 d-4 o-36 p-57 d-4 o-42 p-55 d-3 o-47 p-53 d-7 b-1 s-9 t-27 i-71 o-0 p-74 d-12 p-65 d-2 o-3 p-67 d-1 o-6 p-65 d-1 o-8 p-64 d-2 o-11 p-66 d-2 o-15 p-67 d-1 o-18 p-64 d-1 o-20 p-66 d-2 o-24 p-67 d-1 o-27 p-69 d-1 o-30 p-76 d-2 p-67 d-1 o-32 p-66 d-2 o-35 p-68 d-2 o-36 p-76 d-3 o-38 p-69 d-2 o-42 p-76 d-2 p-66 d-1 o-44 p-68 d-2 o-47 p-69 d-10 i-52 o-2 p-67 d-2 o-5 p-65 d-2 p-57 d-5 o-8 p-64 d-2 o-11 p-66 d-2 p-62 d-5 o-14 p-67 d-2 o-17 p-64 d-2 p-60 d-5 o-20 p-66 d-2 o-23 p-67 d-2 p-59 d-5 o-26 p-69 d-2 o-29 p-76 d-4 p-67 d-2 o-30 p-59 d-4 o-32 p-66 d-2 o-35 p-76 d-4 p-68 d-2 p-64 d-5 o-38 p-69 d-2 o-41 p-76 d-4 p-66 d-1 p-62 d-5 p-52 d-5 o-44 p-68 d-2 o-47 p-77 d-3 p-69 d-11 p-60 d-11 i-49 o-2 p-67 d-2 o-5 p-57 d-4 p-45 d-4 o-6 p-65 d-1 p-57 d-5 o-8 p-64 d-2 o-11 p-66 d-2 p-50 d-5 o-12 p-62 d-5 p-62 d-3 o-14 p-67 d-2 o-17 p-64 d-2 p-60 d-5 p-60 d-4 p-48 d-4 o-20 p-66 d-2 o-23 p-67 d-2 p-59 d-5 p-59 d-4 p-47 d-4 o-26 p-69 d-2 o-29 p-76 d-3 p-67 d-2 p-59 d-5 p-59 d-5 p-47 d-5 o-32 p-66 d-2 o-35 p-76 d-4 p-68 d-1 p-64 d-5 p-64 d-4 o-36 p-52 d-3 o-38 p-69 d-1 o-41 p-76 d-4 p-66 d-1 p-50 d-4 o-42 p-62 d-4 p-52 d-3 o-44 p-68 d-1 o-47 p-77 d-2 p-69 d-9 p-60 d-11 p-57 d-4 i-70 o-6 p-57 d-4 o-12 p-62 d-4 o-18 p-60 d-4 o-24 p-59 d-5 o-30 p-59 d-4 o-36 p-64 d-4 o-42 p-62 d-4 p-52 d-4 b-1 s-9 t-24 i-71 o-0 p-77 d-1 o-2 p-79 d-2 o-6 p-77 d-1 o-9 p-76 d-1 o-12 p-78 d-2 p-69 d-6 o-15 p-79 d-1 o-18 p-76 d-1 o-20 p-78 d-2 o-21 p-69 d-1 o-24 p-79 d-4 p-67 d-10 o-30 p-74 d-3 o-36 p-76 d-7 p-71 d-7 o-45 p-76 d-1 p-71 d-1 i-52 o-0 p-57 d-4 o-2 p-79 d-2 o-5 p-45 d-5 o-6 p-77 d-1 o-8 p-76 d-2 o-11 p-78 d-2 p-69 d-7 p-62 d-7 p-50 d-5 o-14 p-79 d-2 o-17 p-76 d-2 p-48 d-4 o-19 p-69 d-2 o-20 p-78 d-2 p-62 d-2 o-23 p-79 d-2 p-67 d-11 p-62 d-11 p-47 d-5 o-26 p-81 d-2 o-29 p-79 d-2 p-47 d-4 o-32 p-78 d-2 o-35 p-80 d-2 p-71 d-7 p-64 d-7 p-52 d-4 o-38 p-81 d-2 o-41 p-78 d-2 p-50 d-5 o-44 p-80 d-2 p-71 d-2 p-64 d-2 o-47 p-81 d-4 p-69 d-5 p-64 d-12 p-49 d-5 i-49 o-2 p-79 d-2 o-5 p-45 d-4 p-33 d-4 o-6 p-77 d-1 o-8 p-76 d-2 o-11 p-78 d-2 p-69 d-7 p-50 d-4 p-38 d-4 o-12 p-62 d-6 o-14 p-79 d-2 o-17 p-76 d-2 p-48 d-4 p-36 d-5 o-20 p-78 d-2 p-69 d-1 p-62 d-2 o-23 p-79 d-2 p-67 d-10 p-62 d-11 p-47 d-3 p-35 d-4 o-26 p-81 d-2 o-29 p-79 d-2 p-47 d-4 p-35 d-5 o-32 p-78 d-2 o-35 p-80 d-2 p-52 d-4 p-40 d-5 o-36 p-71 d-7 p-64 d-6 o-38 p-81 d-2 o-41 p-78 d-2 p-50 d-5 p-38 d-4 o-44 p-80 d-2 o-45 p-71 d-2 p-64 d-1 o-47 p-81 d-6 p-64 d-11 p-49 d-5 p-37 d-4 i-70 o-0 p-60 d-9 p-57 d-4 o-6 p-45 d-4 o-12 p-62 d-6 p-50 d-4 o-18 p-48 d-4 o-21 p-62 d-1 o-24 p-62 d-9 p-47 d-4 o-29 p-47 d-5 o-36 p-64 d-7 p-52 d-4 o-42 p-50 d-4 o-45 p-64 d-1 b-1 s-9 t-24 i-71 o-0 p-76 d-10 p-69 d-4 o-6 p-67 d-4 o-12 p-74 d-4 p-65 d-4 o-18 p-74 d-4 p-70 d-4 o-24 p-74 d-11 p-69 d-15 o-36 p-73 d-10 o-42 p-69 d-4 i-52 o-5 p-73 d-5 p-67 d-6 o-6 p-57 d-4 o-11 p-74 d-4 p-65 d-5 p-58 d-4 o-12 p-62 d-4 o-17 p-70 d-5 p-55 d-4 o-18 p-74 d-3 p-65 d-3 o-23 p-69 d-17 p-57 d-17 o-24 p-74 d-11 p-64 d-16 o-36 p-73 d-11 o-41 p-69 d-5 p-57 d-5 o-42 p-64 d-4 o-47 p-71 d-26 p-56 d-26 i-56 o-0 p-69 d-11 p-57 d-10 o-12 p-62 d-3 o-18 p-62 d-4 o-24 p-69 d-4 p-57 d-3 o-30 p-69 d-1 p-57 d-1 o-33 p-69 d-1 p-57 d-1 o-36 p-69 d-1 p-57 d-1 o-42 p-69 d-1 p-57 d-1 i-49 o-0 p-69 d-4 o-5 p-73 d-5 p-45 d-5 o-6 p-67 d-4 p-57 d-4 o-11 p-74 d-5 p-65 d-5 p-58 d-4 p-46 d-5 o-12 p-62 d-4 o-17 p-74 d-5 p-70 d-5 p-55 d-4 p-43 d-4 o-18 p-65 d-4 o-23 p-74 d-12 o-24 p-69 d-15 p-64 d-16 p-57 d-10 p-45 d-11 o-36 p-73 d-10 p-45 d-10 p-33 d-10 o-42 p-69 d-4 p-64 d-5 o-47 p-65 d-26 p-32 d-26 i-70 o-0 p-64 d-10 p-49 d-4 o-6 p-57 d-4 o-12 p-62 d-5 p-58 d-4 o-18 p-65 d-4 p-55 d-3 o-24 p-64 d-22 p-57 d-22 i-47 o-0 p-45 d-4 p-33 d-2 o-12 p-50 d-1 p-38 d-1 o-18 p-50 d-1 p-38 d-1 o-24 p-45 d-1 p-33 d-1 o-30 p-45 d-1 p-33 d-1 o-33 p-45 d-1 p-33 d-1 o-35 p-45 d-1 p-33 d-1 o-42 p-45 d-1 p-33 d-1 b-1 s-9 t-13 i-71 o-0 p-74 d-25 p-71 d-24 i-56 o-0 p-74 d-27 p-62 d-27 i-52 o-0 p-74 d-25 p-65 d-25 o-47 p-56 d-8 i-70 o-0 p-65 d-22 p-56 d-24 o-47 p-56 d-8 i-49 o-0 p-74 d-26 p-71 d-24 p-44 d-24 o-47 p-44 d-12 i-47 o-0 p-50 d-16 p-48 d-1 p-38 d-16 b-1 s-9 t-11 i-71 o-0 p-74 d-8 p-65 d-7 o-9 p-74 d-2 p-65 d-2 o-12 p-73 d-11 p-64 d-10 o-24 p-74 d-22 p-65 d-22 i-52 o-0 p-74 d-7 p-71 d-7 p-65 d-7 o-9 p-74 d-2 p-71 d-2 p-65 d-2 p-56 d-3 o-12 p-73 d-11 p-69 d-10 p-64 d-11 p-57 d-11 o-24 p-74 d-10 p-69 d-10 p-65 d-10 p-53 d-5 o-30 p-50 d-4 o-35 p-57 d-17 o-36 p-74 d-11 p-69 d-16 p-65 d-11 i-56 o-12 p-69 d-10 p-57 d-10 o-24 p-69 d-3 p-62 d-3 o-30 p-69 d-3 p-62 d-2 o-36 p-69 d-10 p-57 d-10 i-49 o-0 p-74 d-7 p-71 d-8 p-65 d-8 p-56 d-11 o-9 p-74 d-2 p-71 d-2 p-65 d-2 o-12 p-73 d-11 p-69 d-10 p-64 d-11 p-57 d-10 p-45 d-10 o-24 p-74 d-23 p-69 d-10 p-65 d-23 p-53 d-4 p-41 d-5 o-29 p-50 d-5 o-30 p-38 d-4 o-35 p-45 d-11 p-33 d-11 o-36 p-69 d-15 i-70 o-0 p-65 d-7 p-65 d-1 o-9 p-65 d-1 p-56 d-1 o-12 p-64 d-10 p-57 d-9 o-24 p-65 d-22 p-53 d-4 o-29 p-50 d-4 o-35 p-57 d-11 i-47 o-12 p-45 d-7 p-33 d-6 o-24 p-50 d-1 p-38 d-1 o-30 p-50 d-1 p-38 d-1 o-36 p-45 d-1 p-33 d-1 o-42 p-45 d-1 p-33 d-1 o-45 p-45 d-1 p-33 d-1 b-1 s-9 t-11 i-71 o-0 p-73 d-10 p-64 d-10 o-12 p-74 d-36 p-62 d-36 i-52 o-0 p-73 d-11 p-64 d-10 o-5 p-69 d-5 o-6 p-57 d-4 o-12 p-74 d-36 p-69 d-36 p-62 d-37 p-50 d-36 i-56 o-0 p-69 d-1 p-57 d-1 o-6 p-69 d-2 p-57 d-1 o-12 p-69 d-37 p-62 d-36 i-49 o-0 p-73 d-11 p-64 d-11 p-45 d-11 p-33 d-10 o-5 p-69 d-5 o-12 p-74 d-37 p-69 d-36 p-62 d-36 p-50 d-36 p-38 d-36 i-70 o-0 p-64 d-10 p-45 d-9 o-12 p-62 d-36 p-50 d-36 i-47 o-0 p-45 d-1 p-33 d-1 o-3 p-45 d-1 p-33 d-1 o-6 p-45 d-1 p-33 d-1 o-9 p-45 d-1 p-33 d-1 o-12 p-50 d-30 p-38 d-30 b-1\",\n          \"s-9 t-35 i-83 o-6 p-107 d-3 o-18 p-107 d-3 o-30 p-107 d-3 o-42 p-107 d-3 i-81 o-0 p-61 d-6 p-54 d-6 o-9 p-62 d-6 p-55 d-6 o-18 p-62 d-6 p-55 d-6 o-27 p-62 d-6 p-55 d-6 o-36 p-62 d-6 p-55 d-6 o-45 p-62 d-6 p-55 d-6 i-87 o-0 p-61 d-6 p-54 d-6 o-9 p-62 d-6 p-55 d-6 o-18 p-62 d-6 p-55 d-6 o-27 p-62 d-6 p-55 d-6 o-36 p-62 d-6 p-55 d-6 o-45 p-62 d-6 p-55 d-6 b-1 s-9 t-35 i-83 o-6 p-107 d-3 o-18 p-107 d-3 o-30 p-107 d-3 o-42 p-107 d-3 i-81 o-6 p-62 d-6 p-55 d-6 o-15 p-62 d-6 p-55 d-6 o-24 p-62 d-6 p-55 d-6 o-33 p-61 d-6 p-54 d-6 o-42 p-61 d-6 p-54 d-6 i-87 o-6 p-62 d-6 p-55 d-6 o-15 p-62 d-6 p-55 d-6 o-24 p-62 d-6 p-55 d-6 o-33 p-61 d-6 p-54 d-6 o-42 p-61 d-6 p-54 d-6 b-1 s-9 t-35 i-83 o-6 p-107 d-3 o-18 p-107 d-3 o-30 p-107 d-3 o-42 p-107 d-3 i-81 o-3 p-66 d-6 p-59 d-6 o-12 p-66 d-6 p-59 d-6 o-21 p-66 d-6 p-59 d-6 o-30 p-66 d-6 p-59 d-6 o-39 p-66 d-6 p-59 d-6 i-87 o-3 p-66 d-6 p-59 d-6 o-12 p-66 d-6 p-59 d-6 o-21 p-66 d-6 p-59 d-6 o-30 p-66 d-6 p-59 d-6 o-39 p-66 d-6 p-59 d-6 b-1 s-9 t-35 i-83 o-6 p-107 d-3 o-18 p-107 d-3 o-30 p-107 d-3 o-42 p-107 d-3 i-81 o-0 p-66 d-6 p-59 d-6 o-9 p-66 d-6 p-59 d-6 o-15 p-69 d-6 p-62 d-6 o-24 p-69 d-6 p-62 d-6 o-33 p-61 d-6 p-54 d-6 o-42 p-61 d-6 p-54 d-6 i-87 o-0 p-66 d-6 p-59 d-6 o-9 p-66 d-6 p-59 d-6 o-15 p-69 d-6 p-62 d-6 o-24 p-69 d-6 p-62 d-6 o-33 p-61 d-6 p-54 d-6 o-42 p-61 d-6 p-54 d-6 b-1 s-9 t-35 i-83 o-6 p-107 d-3 o-18 p-107 d-3 o-30 p-107 d-3 o-42 p-107 d-3 i-81 o-0 p-61 d-6 p-54 d-6 o-9 p-62 d-6 p-55 d-6 o-18 p-62 d-6 p-55 d-6 o-27 p-62 d-6 p-55 d-6 o-36 p-62 d-6 p-55 d-6 o-45 p-62 d-6 p-55 d-6 i-87 o-0 p-61 d-6 p-54 d-6 o-9 p-62 d-6 p-55 d-6 o-18 p-62 d-6 p-55 d-6 o-27 p-62 d-6 p-55 d-6 o-36 p-62 d-6 p-55 d-6 o-45 p-62 d-6 p-55 d-6 b-1 s-9 t-35 i-83 o-6 p-107 d-3 o-18 p-107 d-3 o-30 p-107 d-3 o-42 p-107 d-3 i-81 o-6 p-62 d-6 p-55 d-6 o-15 p-62 d-6 p-55 d-6 o-24 p-62 d-6 p-55 d-6 o-33 p-61 d-6 p-54 d-6 o-42 p-61 d-6 p-54 d-6 i-87 o-6 p-62 d-6 p-55 d-6 o-15 p-62 d-6 p-55 d-6 o-24 p-62 d-6 p-55 d-6 o-33 p-61 d-6 p-54 d-6 o-42 p-61 d-6 p-54 d-6 b-1 s-9 t-35 i-83 o-6 p-107 d-3 o-18 p-107 d-3 o-30 p-107 d-3 o-42 p-107 d-3 i-81 o-3 p-66 d-6 p-59 d-6 o-12 p-66 d-6 p-59 d-6 o-21 p-66 d-6 p-59 d-6 o-30 p-66 d-6 p-59 d-6 o-39 p-66 d-6 p-59 d-6 i-87 o-3 p-66 d-6 p-59 d-6 o-12 p-66 d-6 p-59 d-6 o-21 p-66 d-6 p-59 d-6 o-30 p-66 d-6 p-59 d-6 o-39 p-66 d-6 p-59 d-6 b-1 s-9 t-35 i-83 o-6 p-107 d-3 o-18 p-107 d-3 o-30 p-107 d-3 o-42 p-107 d-3 i-81 o-0 p-66 d-6 p-59 d-6 o-9 p-66 d-6 p-59 d-6 o-15 p-69 d-6 p-62 d-6 o-24 p-69 d-6 p-62 d-6 o-33 p-61 d-6 p-54 d-6 o-42 p-61 d-6 p-54 d-6 i-87 o-0 p-66 d-6 p-59 d-6 o-9 p-66 d-6 p-59 d-6 o-15 p-69 d-6 p-62 d-6 o-24 p-69 d-6 p-62 d-6 o-33 p-61 d-6 p-54 d-6 o-42 p-61 d-6 p-54 d-6 b-1\",\n          \"s-9 t-35 i-0 o-0 p-67 d-16 o-15 p-69 d-11 o-16 p-66 d-5 o-26 p-71 d-7 p-55 d-6 o-27 p-65 d-6 o-28 p-76 d-11 o-38 p-72 d-13 p-64 d-13 p-57 d-12 b-1 s-9 t-35 i-0 o-0 p-76 d-8 o-11 p-83 d-11 p-75 d-15 p-66 d-17 o-12 p-72 d-14 o-22 p-81 d-4 o-32 p-78 d-14 o-33 p-74 d-13 p-71 d-14 p-66 d-14 p-65 d-22 o-45 p-79 d-8 p-67 d-10 b-1 s-9 t-35 i-0 o-7 p-80 d-11 p-79 d-8 p-68 d-10 o-8 p-73 d-7 p-64 d-17 o-16 p-81 d-3 p-69 d-23 o-21 p-81 d-22 o-28 p-89 d-41 p-77 d-44 o-29 p-62 d-12 o-43 p-82 d-6 p-70 d-3 b-1 s-9 t-35 i-0 o-5 p-55 d-49 o-12 p-83 d-24 o-13 p-71 d-33 o-19 p-88 d-9 o-28 p-91 d-9 o-35 p-89 d-7 o-41 p-86 d-6 o-47 p-83 d-4 b-1 s-9 t-35 i-0 o-4 p-79 d-3 o-8 p-78 d-3 o-16 p-77 d-35 p-69 d-12 p-65 d-39 p-57 d-9 p-50 d-10 o-28 p-70 d-6 p-58 d-4 o-36 p-43 d-52 o-42 p-71 d-17 o-44 p-59 d-36 b-1 s-9 t-35 i-0 o-1 p-76 d-11 o-10 p-79 d-10 o-18 p-77 d-6 o-23 p-74 d-6 o-29 p-71 d-5 o-35 p-67 d-6 o-43 p-66 d-3 b-1 s-9 t-35 i-0 o-6 p-65 d-86 p-57 d-28 o-7 p-53 d-82 p-50 d-44 p-45 d-23 p-38 d-45 o-33 p-58 d-27 p-46 d-19 b-1 s-9 t-35 i-0 o-24 p-47 d-22 p-31 d-28 o-25 p-59 d-28 b-1 s-9 t-35 i-0 o-18 p-64 d-12 o-19 p-52 d-5 o-27 p-36 d-49 o-31 p-43 d-35 o-34 p-48 d-33 o-37 p-52 d-19 o-41 p-55 d-16 o-44 p-60 d-14 b-1 s-9 t-35 i-0 o-3 p-64 d-7 o-20 p-64 d-2 p-60 d-3 o-33 p-64 d-3 p-60 d-4 o-47 p-60 d-6 p-55 d-16 b-1 s-9 t-35 i-0 o-0 p-64 d-5 o-12 p-64 d-7 p-60 d-8 p-56 d-14 o-23 p-59 d-11 o-24 p-64 d-8 p-60 d-8 o-38 p-64 d-7 p-59 d-15 o-39 p-60 d-6 b-1 s-9 t-35 i-0 o-4 p-64 d-7 p-60 d-8 p-57 d-14 o-16 p-64 d-6 p-60 d-7 p-52 d-14 o-26 p-64 d-12 p-54 d-13 o-27 p-60 d-8 o-37 p-55 d-15 o-38 p-62 d-10 p-59 d-9 b-1 s-9 t-35 i-0 o-1 p-64 d-13 p-57 d-15 o-2 p-58 d-12 p-49 d-14 o-17 p-55 d-29 p-50 d-74 o-30 p-57 d-7 o-31 p-62 d-5 o-45 p-62 d-5 p-57 d-3 o-46 p-53 d-70 b-1 s-9 t-35 i-0 o-10 p-62 d-3 p-57 d-3 o-20 p-56 d-6 o-21 p-59 d-6 o-32 p-59 d-5 p-56 d-4 o-42 p-45 d-61 b-1 s-9 t-35 i-0 o-5 p-61 d-6 o-6 p-55 d-5 o-19 p-61 d-7 p-55 d-7 o-20 p-52 d-24 o-32 p-61 d-4 p-55 d-2 o-43 p-61 d-4 o-44 p-55 d-2 p-53 d-7 b-1 s-9 t-35 i-0 o-6 p-61 d-8 p-55 d-4 o-13 p-45 d-44 o-17 p-57 d-12 o-28 p-64 d-6 p-54 d-4 p-52 d-15 o-29 p-60 d-5 o-42 p-60 d-27 b-1 s-9 t-35 i-0 o-5 p-64 d-2 p-54 d-2 o-16 p-64 d-2 p-54 d-1 o-27 p-57 d-3 o-28 p-64 d-2 o-43 p-38 d-7 o-44 p-64 d-6 b-1 s-9 t-35 i-0 o-16 p-81 d-6 p-72 d-4 p-67 d-5 o-18 p-76 d-2 o-23 p-57 d-5 o-31 p-81 d-4 o-32 p-76 d-4 p-72 d-3 p-67 d-3 p-57 d-2 o-40 p-50 d-4 o-44 p-72 d-12 p-67 d-4 p-64 d-6 p-60 d-4 b-1 s-9 t-35 i-0 o-6 p-74 d-12 o-7 p-67 d-6 p-62 d-4 p-59 d-4 p-50 d-4 o-17 p-76 d-9 o-18 p-67 d-16 p-60 d-2 p-57 d-2 o-19 p-50 d-2 o-32 p-76 d-23 p-43 d-6 p-31 d-5 o-47 p-65 d-9 p-60 d-44 b-1 s-9 t-35 i-0 o-0 p-55 d-9 p-50 d-63 o-6 p-74 d-4 o-14 p-74 d-46 o-15 p-70 d-14 p-65 d-30 p-56 d-8 o-27 p-69 d-9 p-57 d-11 o-38 p-68 d-8 o-39 p-58 d-6 b-1 s-9 t-35 i-0 o-6 p-67 d-18 o-7 p-65 d-18 p-59 d-7 o-8 p-55 d-7 o-26 p-43 d-24 p-36 d-24 o-40 p-60 d-8 o-41 p-64 d-6 b-1 s-9 t-35 i-0 o-6 p-64 d-3 p-60 d-4 o-21 p-67 d-13 o-22 p-64 d-2 p-60 d-5 p-55 d-14 o-34 p-68 d-13 o-35 p-56 d-13 o-36 p-64 d-5 p-60 d-5 o-46 p-71 d-10 o-47 p-64 d-7 p-60 d-8 p-59 d-9 b-1 s-9 t-35 i-0 o-12 p-71 d-14 o-13 p-60 d-6 p-59 d-12 o-26 p-69 d-12 p-60 d-8 o-27 p-64 d-5 p-57 d-14 o-38 p-64 d-8 p-60 d-7 o-39 p-52 d-12 b-1 s-9 t-35 i-0 o-2 p-66 d-13 p-64 d-2 p-60 d-6 p-54 d-12 o-14 p-67 d-9 p-59 d-5 p-55 d-12 o-15 p-62 d-6 o-26 p-69 d-12 p-58 d-16 p-57 d-11 o-27 p-49 d-12 o-28 p-64 d-14 o-42 p-55 d-27 p-50 d-68 b-1 s-9 t-35 i-0 o-8 p-67 d-12 p-57 d-7 o-9 p-62 d-5 o-21 p-65 d-5 p-57 d-5 o-22 p-62 d-3 o-23 p-53 d-31 o-34 p-65 d-3 p-62 d-2 p-57 d-3 o-46 p-65 d-6 p-59 d-5 p-56 d-7 b-1 s-9 t-35 i-0 o-14 p-65 d-10 p-59 d-3 p-56 d-3 p-53 d-5 o-23 p-45 d-73 o-32 p-57 d-19 o-46 p-65 d-9 o-47 p-61 d-5 p-55 d-5 b-1 s-9 t-35 i-0 o-8 p-52 d-3 o-15 p-52 d-31 o-26 p-64 d-5 o-27 p-61 d-5 p-55 d-3 o-38 p-64 d-3 p-61 d-4 p-55 d-2 b-1 s-9 t-35 i-0 o-1 p-64 d-5 p-57 d-5 o-2 p-61 d-2 o-8 p-45 d-16 o-14 p-60 d-15 o-31 p-64 d-3 p-54 d-2 o-32 p-60 d-2 o-37 p-57 d-3 o-42 p-57 d-21 b-1 s-9 t-35 i-0 o-5 p-64 d-2 p-60 d-3 p-54 d-3 o-16 p-64 d-3 p-60 d-4 p-54 d-2 o-27 p-60 d-8 o-28 p-64 d-1 p-54 d-4 o-43 p-64 d-5 p-38 d-7 b-1 s-9 t-35 i-0 o-12 p-81 d-5 p-76 d-4 p-72 d-4 p-67 d-4 o-18 p-57 d-4 o-24 p-72 d-3 p-67 d-2 p-57 d-4 o-25 p-76 d-1 o-36 p-72 d-12 p-67 d-5 p-64 d-6 p-57 d-12 o-37 p-50 d-5 o-47 p-74 d-7 p-67 d-5 p-62 d-5 p-59 d-7 b-1 s-9 t-35 i-0 o-0 p-50 d-5 o-9 p-50 d-5 o-10 p-76 d-7 p-67 d-7 p-60 d-4 o-22 p-43 d-12 o-24 p-64 d-10 o-39 p-77 d-6 p-72 d-7 p-69 d-6 p-65 d-7 o-45 p-62 d-4 b-1 s-9 t-35 i-0 o-2 p-77 d-6 p-69 d-6 p-65 d-7 o-3 p-72 d-5 p-62 d-27 o-14 p-77 d-5 p-72 d-5 p-69 d-5 p-65 d-6 o-26 p-77 d-6 p-72 d-6 p-69 d-6 p-65 d-6 o-38 p-77 d-2 p-72 d-2 p-69 d-3 p-65 d-2 p-62 d-2 o-46 p-31 d-4 b-1 s-9 t-35 i-0 o-1 p-43 d-1 o-3 p-50 d-9 o-6 p-53 d-7 o-10 p-60 d-7 o-14 p-65 d-14 o-32 p-77 d-7 p-72 d-6 p-68 d-6 p-65 d-7 o-38 p-56 d-8 b-1 s-9 t-35 i-0 o-0 p-77 d-7 p-72 d-6 p-68 d-7 p-65 d-8 o-1 p-56 d-16 o-15 p-77 d-7 p-72 d-13 p-67 d-8 p-65 d-8 p-55 d-20 o-27 p-77 d-8 p-71 d-8 p-67 d-9 p-65 d-9 p-59 d-14 o-42 p-77 d-4 p-64 d-2 o-43 p-71 d-2 b-1 s-9 t-35 i-0 o-3 p-36 d-21 o-5 p-43 d-21 o-7 p-48 d-19 o-9 p-52 d-14 o-12 p-55 d-12 o-17 p-62 d-8 o-34 p-76 d-13 o-35 p-67 d-9 p-64 d-12 o-46 p-60 d-6 b-1 s-9 t-35 i-0 o-8 p-76 d-28 o-9 p-67 d-25 p-64 d-28 p-60 d-8 o-28 p-55 d-8 p-52 d-7 p-48 d-6 p-43 d-6 o-42 p-56 d-7 o-43 p-48 d-4 p-44 d-11 o-44 p-52 d-2 b-1 s-9 t-35 i-0 o-6 p-59 d-9 p-52 d-8 o-7 p-48 d-7 p-47 d-7 o-17 p-59 d-14 o-18 p-52 d-6 p-47 d-11 o-19 p-48 d-5 o-29 p-57 d-16 p-52 d-6 p-48 d-7 p-45 d-9 o-42 p-52 d-9 o-43 p-48 d-5 p-40 d-12 b-1 s-9 t-35 i-0 o-7 p-54 d-13 p-42 d-13 o-8 p-52 d-2 p-48 d-6 o-18 p-55 d-16 o-19 p-50 d-11 p-47 d-8 o-20 p-43 d-14 o-33 p-57 d-29 o-34 p-52 d-13 p-46 d-15 p-37 d-16 b-1 s-9 t-35 i-0 o-6 p-55 d-31 p-50 d-29 p-45 d-31 o-7 p-38 d-29 b-1 s-9 t-35 i-0 o-11 p-53 d-37 o-12 p-47 d-27 p-43 d-19 p-31 d-26 b-1 s-9 t-35 i-0 o-5 p-36 d-11 p-24 d-21 o-16 p-43 d-10 o-25 p-48 d-9 o-33 p-52 d-4 o-40 p-55 d-4 o-45 p-60 d-3 b-1 s-9 t-35 i-0 o-2 p-64 d-2 o-8 p-67 d-18 p-55 d-13 o-13 p-60 d-3 o-18 p-64 d-2 o-22 p-68 d-14 p-56 d-13 o-27 p-60 d-3 o-30 p-64 d-2 o-33 p-71 d-8 o-34 p-59 d-6 o-38 p-60 d-2 o-41 p-64 d-2 o-44 p-71 d-14 o-45 p-59 d-11 b-1 s-9 t-35 i-0 o-1 p-60 d-2 o-4 p-64 d-2 o-8 p-69 d-14 p-57 d-7 o-12 p-60 d-3 o-16 p-64 d-2 o-20 p-64 d-4 p-52 d-4 o-25 p-60 d-2 o-28 p-64 d-2 o-31 p-66 d-13 p-54 d-10 o-35 p-60 d-3 o-37 p-64 d-2 o-42 p-67 d-14 p-55 d-5 o-45 p-59 d-2 b-1 s-9 t-35 i-0 o-0 p-62 d-2 o-6 p-69 d-22 o-7 p-57 d-5 p-49 d-8 o-12 p-58 d-2 o-17 p-64 d-2 o-22 p-67 d-33 o-23 p-38 d-7 o-27 p-45 d-4 o-32 p-50 d-2 o-37 p-55 d-4 o-41 p-57 d-2 o-46 p-62 d-2 b-1 s-9 t-35 i-0 o-4 p-65 d-62 o-5 p-53 d-7 o-9 p-57 d-4 o-14 p-62 d-2 o-18 p-53 d-2 o-21 p-57 d-2 o-24 p-62 d-3 o-28 p-56 d-6 o-29 p-53 d-4 o-33 p-59 d-1 o-36 p-62 d-2 o-39 p-53 d-2 o-40 p-56 d-2 o-43 p-59 d-2 o-46 p-62 d-1 b-1 s-9 t-35 i-0 o-2 p-45 d-12 o-6 p-53 d-8 o-12 p-55 d-3 o-16 p-61 d-2 o-20 p-53 d-4 o-24 p-55 d-2 o-27 p-61 d-3 o-31 p-64 d-21 o-32 p-52 d-5 o-35 p-55 d-4 o-38 p-61 d-2 o-42 p-52 d-2 o-45 p-55 d-2 b-1 s-9 t-35 i-0 o-0 p-61 d-2 o-4 p-65 d-12 p-53 d-10 o-8 p-61 d-3 o-11 p-64 d-1 o-14 p-67 d-13 o-15 p-55 d-3 o-18 p-61 d-2 o-21 p-64 d-2 o-25 p-69 d-15 p-45 d-8 o-31 p-52 d-4 o-34 p-54 d-4 o-38 p-64 d-4 p-60 d-3 o-44 p-64 d-4 o-47 p-66 d-5 b-1 s-9 t-35 i-0 o-6 p-72 d-35 o-11 p-66 d-2 o-15 p-64 d-1 o-18 p-60 d-3 o-22 p-54 d-3 o-25 p-52 d-2 o-28 p-45 d-4 o-32 p-52 d-3 o-35 p-54 d-2 o-38 p-60 d-2 o-40 p-69 d-21 o-44 p-64 d-1 o-47 p-66 d-2 b-1 s-9 t-35 i-0 o-8 p-38 d-11 o-11 p-76 d-34 o-18 p-45 d-7 o-24 p-48 d-2 o-28 p-55 d-4 o-33 p-57 d-5 o-36 p-69 d-4 o-39 p-60 d-4 o-44 p-69 d-2 o-45 p-67 d-1 b-1 s-9 t-35 i-0 o-1 p-60 d-2 o-5 p-57 d-1 o-10 p-57 d-13 p-55 d-1 o-14 p-48 d-3 o-17 p-45 d-4 o-21 p-59 d-14 p-38 d-4 o-25 p-45 d-5 o-29 p-48 d-3 o-33 p-60 d-16 p-55 d-3 o-37 p-48 d-5 o-41 p-45 d-2 o-47 p-64 d-24 b-1 s-9 t-35 i-0 o-3 p-31 d-18 o-7 p-43 d-15 o-12 p-53 d-6 o-17 p-59 d-7 o-22 p-62 d-3 o-26 p-32 d-11 o-27 p-62 d-61 o-31 p-44 d-6 o-32 p-53 d-4 o-35 p-58 d-5 o-38 p-33 d-10 o-43 p-53 d-4 p-45 d-3 o-47 p-57 d-7 b-1 s-9 t-35 i-0 o-2 p-34 d-12 o-6 p-46 d-8 o-7 p-53 d-5 o-11 p-56 d-13 o-16 p-35 d-12 o-22 p-47 d-9 o-23 p-53 d-8 o-30 p-55 d-8 o-32 p-36 d-8 o-39 p-48 d-3 b-1 s-9 t-35 i-0 o-0 p-64 d-2 p-60 d-2 p-55 d-3 o-6 p-64 d-2 p-60 d-2 p-55 d-2 o-12 p-64 d-1 p-60 d-2 p-55 d-2 o-16 p-64 d-2 p-60 d-2 p-55 d-2 o-20 p-64 d-2 p-60 d-2 p-55 d-2 o-24 p-64 d-2 p-60 d-2 p-55 d-2 o-28 p-64 d-2 p-55 d-2 o-29 p-60 d-1 o-32 p-64 d-3 p-60 d-4 o-33 p-55 d-2 o-36 p-79 d-12 p-67 d-5 o-40 p-64 d-1 p-60 d-2 p-55 d-2 o-43 p-64 d-3 p-55 d-3 o-44 p-60 d-1 o-47 p-80 d-13 p-68 d-8 b-1 s-9 t-35 i-0 o-2 p-56 d-3 o-3 p-64 d-1 p-60 d-1 o-6 p-64 d-3 o-7 p-60 d-2 p-56 d-3 o-10 p-83 d-10 p-71 d-9 o-14 p-64 d-2 p-59 d-2 o-15 p-60 d-1 o-19 p-64 d-2 p-60 d-3 p-59 d-3 o-24 p-83 d-11 p-71 d-11 o-29 p-64 d-2 p-60 d-2 p-59 d-2 o-34 p-64 d-2 p-60 d-2 p-59 d-2 o-37 p-81 d-5 p-69 d-7 o-41 p-64 d-1 p-60 d-2 p-57 d-2 o-45 p-64 d-1 p-60 d-2 p-57 d-2 b-1 s-9 t-35 i-0 o-0 p-76 d-8 o-1 p-64 d-1 o-4 p-60 d-2 p-52 d-1 o-5 p-64 d-1 o-8 p-64 d-2 p-60 d-4 p-52 d-2 o-11 p-78 d-9 p-66 d-8 o-14 p-64 d-2 p-60 d-3 p-54 d-3 o-18 p-64 d-2 o-19 p-60 d-1 p-54 d-2 o-22 p-79 d-10 p-67 d-9 o-25 p-62 d-2 p-59 d-2 p-55 d-2 o-29 p-62 d-3 p-59 d-3 o-30 p-55 d-2 o-34 p-81 d-7 p-69 d-8 o-37 p-49 d-3 o-41 p-64 d-1 p-58 d-1 o-45 p-67 d-14 p-58 d-1 o-47 p-69 d-3 b-1 s-9 t-35 i-0 o-2 p-74 d-4 o-4 p-50 d-5 p-38 d-4 o-8 p-79 d-26 o-16 p-67 d-2 p-62 d-2 p-57 d-2 o-21 p-67 d-2 p-62 d-2 p-57 d-2 o-26 p-67 d-2 p-62 d-2 o-27 p-57 d-2 o-31 p-57 d-6 o-32 p-67 d-1 p-62 d-1 o-35 p-67 d-1 p-62 d-2 o-37 p-65 d-10 o-43 p-77 d-39 b-1 s-9 t-35 i-0 o-1 p-62 d-2 o-2 p-65 d-2 p-57 d-1 o-5 p-65 d-2 p-57 d-2 o-6 p-62 d-1 o-10 p-65 d-2 p-62 d-2 p-57 d-2 o-14 p-65 d-2 p-62 d-2 p-57 d-2 o-19 p-65 d-2 o-20 p-62 d-1 p-57 d-2 o-29 p-62 d-2 p-59 d-2 o-30 p-56 d-1 o-34 p-62 d-1 p-59 d-2 p-56 d-2 o-39 p-77 d-11 p-62 d-1 p-59 d-1 p-56 d-2 o-40 p-65 d-1 o-44 p-59 d-2 o-45 p-62 d-1 p-56 d-1 b-1 s-9 t-35 i-0 o-0 p-62 d-2 o-1 p-59 d-1 p-56 d-1 o-8 p-33 d-4 o-9 p-45 d-3 o-10 p-81 d-13 p-77 d-15 p-73 d-17 p-69 d-5 o-19 p-65 d-2 o-20 p-61 d-1 p-55 d-1 o-25 p-65 d-1 o-26 p-61 d-1 p-55 d-1 o-30 p-65 d-2 p-61 d-2 p-55 d-2 o-34 p-65 d-3 p-61 d-2 p-55 d-2 o-36 p-76 d-4 o-37 p-64 d-1 o-43 p-76 d-26 p-64 d-3 b-1 s-9 t-35 i-0 o-0 p-64 d-1 p-61 d-2 p-55 d-2 o-4 p-64 d-2 p-61 d-2 p-55 d-2 o-8 p-64 d-2 p-61 d-2 p-55 d-2 o-12 p-64 d-2 p-61 d-2 p-55 d-2 o-17 p-64 d-2 o-18 p-61 d-1 p-55 d-1 o-26 p-64 d-1 p-61 d-1 p-55 d-1 o-29 p-64 d-3 o-30 p-61 d-1 p-55 d-2 o-34 p-81 d-8 p-69 d-4 o-37 p-64 d-1 p-61 d-2 p-55 d-1 o-42 p-64 d-1 p-61 d-1 p-55 d-1 b-1 s-9 t-35 i-0 o-0 p-84 d-17 p-78 d-23 p-76 d-24 p-72 d-19 p-45 d-3 p-33 d-2 o-8 p-64 d-1 p-60 d-2 p-54 d-1 o-13 p-64 d-1 p-54 d-1 o-14 p-60 d-1 o-18 p-64 d-1 p-60 d-1 p-54 d-1 o-21 p-64 d-3 p-60 d-2 p-54 d-2 o-23 p-81 d-6 p-69 d-6 o-27 p-64 d-5 o-28 p-60 d-4 p-54 d-4 o-31 p-81 d-29 p-69 d-27 o-36 p-64 d-2 p-54 d-1 o-37 p-60 d-1 o-40 p-64 d-2 p-60 d-2 p-54 d-2 o-44 p-64 d-2 p-60 d-2 p-54 d-2 b-1 s-9 t-35 i-0 o-0 p-64 d-2 p-60 d-2 p-54 d-2 o-4 p-64 d-3 o-5 p-60 d-3 p-54 d-3 o-12 p-64 d-1 p-60 d-2 p-54 d-1 o-16 p-64 d-3 p-60 d-3 p-54 d-2 o-20 p-84 d-14 p-72 d-3 o-23 p-64 d-2 p-54 d-2 o-24 p-60 d-1 o-27 p-64 d-1 p-60 d-1 o-28 p-54 d-2 o-29 p-76 d-15 o-34 p-50 d-7 p-38 d-5 o-38 p-88 d-15 o-45 p-67 d-2 o-46 p-64 d-2 p-60 d-1 b-1 s-9 t-35 i-0 o-2 p-67 d-2 p-64 d-2 p-60 d-2 o-6 p-67 d-2 o-7 p-64 d-1 p-60 d-2 o-10 p-67 d-2 p-64 d-2 p-60 d-2 o-11 p-81 d-5 p-69 d-4 o-16 p-67 d-2 p-64 d-2 p-60 d-2 o-18 p-81 d-9 p-69 d-8 o-22 p-79 d-1 p-76 d-2 p-67 d-2 p-64 d-2 p-60 d-2 o-25 p-79 d-3 o-26 p-76 d-1 p-67 d-3 p-64 d-2 p-60 d-2 o-29 p-81 d-10 p-69 d-10 o-33 p-79 d-2 p-67 d-2 o-34 p-76 d-1 p-64 d-1 p-60 d-1 o-37 p-79 d-3 p-76 d-3 p-67 d-3 p-64 d-3 o-38 p-60 d-3 o-41 p-83 d-10 p-71 d-10 o-45 p-74 d-3 p-67 d-3 p-59 d-3 o-46 p-64 d-2 p-62 d-1 b-1 s-9 t-35 i-0 o-1 p-74 d-3 p-62 d-4 p-59 d-3 o-2 p-67 d-3 o-6 p-84 d-4 p-72 d-4 o-9 p-67 d-1 p-60 d-1 p-57 d-1 o-10 p-76 d-1 o-12 p-60 d-2 p-57 d-2 o-13 p-76 d-1 o-16 p-76 d-10 o-18 p-49 d-2 o-19 p-43 d-5 o-20 p-55 d-5 o-23 p-88 d-2 o-30 p-77 d-3 p-72 d-3 p-69 d-4 p-65 d-4 p-60 d-2 p-57 d-2 o-31 p-50 d-1 o-36 p-77 d-2 p-72 d-3 p-69 d-3 p-65 d-2 p-60 d-1 p-57 d-2 p-50 d-1 o-40 p-77 d-2 p-72 d-3 p-69 d-2 p-65 d-2 p-60 d-2 p-57 d-2 o-41 p-50 d-1 o-44 p-77 d-2 p-72 d-2 p-69 d-2 p-65 d-2 p-60 d-5 o-45 p-57 d-4 p-50 d-6 b-1 s-9 t-35 i-0 o-1 p-86 d-2 p-74 d-1 o-5 p-86 d-2 o-6 p-74 d-1 o-12 p-65 d-3 p-60 d-2 p-57 d-2 p-50 d-2 o-13 p-77 d-2 p-72 d-2 p-69 d-3 o-17 p-72 d-3 p-60 d-3 o-18 p-77 d-2 p-69 d-2 p-65 d-2 p-57 d-1 p-50 d-1 o-22 p-77 d-2 p-72 d-3 p-69 d-2 p-65 d-2 p-60 d-2 p-57 d-2 p-50 d-1 o-26 p-77 d-2 p-72 d-2 p-69 d-2 p-65 d-2 p-60 d-2 p-57 d-2 p-50 d-2 o-30 p-77 d-3 p-72 d-4 p-69 d-4 p-65 d-6 p-60 d-4 o-31 p-57 d-4 p-50 d-3 o-38 p-77 d-2 p-65 d-2 p-60 d-2 p-57 d-2 o-39 p-72 d-1 p-69 d-1 p-50 d-1 o-42 p-72 d-2 p-65 d-2 o-43 p-77 d-1 p-60 d-4 p-57 d-2 o-44 p-50 d-2 b-1 s-9 t-35 i-0 o-2 p-86 d-2 p-74 d-2 p-62 d-3 o-8 p-77 d-2 p-65 d-2 p-60 d-3 p-50 d-1 o-9 p-69 d-2 p-57 d-1 o-10 p-72 d-2 o-12 p-65 d-1 p-60 d-1 p-57 d-1 o-13 p-77 d-2 p-72 d-1 p-50 d-1 o-20 p-43 d-2 p-31 d-1 o-30 p-89 d-3 p-77 d-4 p-65 d-3 o-41 p-77 d-3 p-72 d-3 p-68 d-3 p-65 d-3 p-60 d-3 p-56 d-3 p-53 d-2 p-50 d-2 b-1 s-9 t-35 i-0 o-0 p-77 d-2 p-72 d-3 p-68 d-2 p-65 d-2 p-60 d-2 p-56 d-2 p-53 d-2 p-50 d-1 o-5 p-77 d-2 p-72 d-3 p-68 d-3 p-65 d-3 p-60 d-3 p-56 d-3 p-50 d-2 o-6 p-53 d-1 o-10 p-77 d-2 p-72 d-1 p-68 d-1 p-65 d-1 p-60 d-2 p-53 d-1 o-11 p-50 d-1 o-15 p-80 d-3 p-68 d-3 p-56 d-3 o-23 p-80 d-2 p-68 d-3 p-56 d-3 o-28 p-77 d-2 p-65 d-3 p-60 d-2 p-56 d-3 o-29 p-72 d-2 p-68 d-2 p-53 d-1 p-50 d-1 o-33 p-77 d-2 p-68 d-1 p-65 d-2 p-60 d-2 p-56 d-2 p-53 d-3 p-50 d-2 o-34 p-72 d-1 o-38 p-79 d-3 p-67 d-3 p-55 d-3 o-43 p-77 d-3 p-65 d-3 p-60 d-3 p-55 d-3 p-53 d-2 o-44 p-72 d-1 p-50 d-1 b-1 s-9 t-35 i-0 o-0 p-77 d-2 p-72 d-1 p-65 d-1 p-60 d-3 p-55 d-5 p-53 d-6 p-50 d-11 o-7 p-83 d-3 p-80 d-2 p-71 d-4 p-59 d-4 o-13 p-77 d-3 p-71 d-2 p-59 d-3 o-14 p-67 d-1 p-65 d-1 p-55 d-1 p-53 d-1 p-50 d-2 o-19 p-77 d-2 p-71 d-1 p-65 d-1 p-59 d-2 p-55 d-1 p-53 d-1 p-50 d-2 o-20 p-67 d-1 o-26 p-88 d-3 o-27 p-76 d-1 p-64 d-2 o-35 p-77 d-3 p-71 d-2 p-67 d-3 p-65 d-3 p-59 d-3 p-53 d-2 p-50 d-2 o-36 p-55 d-1 o-40 p-59 d-1 o-41 p-77 d-1 p-71 d-1 p-65 d-2 p-53 d-2 p-50 d-1 o-47 p-36 d-5 b-1 s-9 t-35 i-0 o-0 p-62 d-4 o-2 p-48 d-3 o-3 p-64 d-2 o-5 p-70 d-2 o-8 p-74 d-14 o-15 p-62 d-10 o-16 p-86 d-4 o-28 p-76 d-4 o-29 p-70 d-2 p-64 d-3 p-62 d-1 p-60 d-3 p-58 d-3 p-52 d-2 p-48 d-2 o-36 p-76 d-3 p-70 d-2 p-64 d-2 p-60 d-2 p-58 d-2 p-52 d-2 p-48 d-2 o-42 p-76 d-3 p-70 d-2 p-64 d-2 p-60 d-2 p-58 d-2 p-48 d-2 o-43 p-52 d-1 b-1 s-9 t-35 i-0 o-0 p-76 d-2 p-64 d-2 p-60 d-3 p-58 d-4 p-48 d-2 o-1 p-70 d-1 o-2 p-52 d-1 o-8 p-84 d-6 p-72 d-5 o-10 p-60 d-3 o-16 p-84 d-1 p-72 d-2 p-60 d-4 o-24 p-76 d-3 p-70 d-3 p-64 d-2 p-60 d-2 p-58 d-2 p-48 d-3 o-25 p-52 d-1 o-30 p-76 d-2 p-70 d-2 p-64 d-2 p-60 d-2 o-31 p-58 d-1 p-52 d-2 o-35 p-60 d-8 p-48 d-5 o-40 p-76 d-2 p-70 d-2 p-64 d-2 o-45 p-76 d-3 p-70 d-2 p-64 d-2 b-1 s-9 t-35 i-0 o-2 p-64 d-2 p-52 d-1 o-7 p-76 d-1 p-70 d-1 p-64 d-1 o-11 p-76 d-3 p-70 d-2 o-16 p-69 d-2 p-57 d-2 o-21 p-76 d-1 p-70 d-2 p-64 d-2 o-26 p-76 d-1 p-70 d-1 p-64 d-4 o-28 p-36 d-2 o-35 p-67 d-23 o-36 p-55 d-14 o-43 p-72 d-2 p-69 d-3 p-60 d-3 b-1 s-9 t-35 i-0 o-0 p-69 d-3 o-1 p-72 d-1 p-60 d-2 o-6 p-69 d-2 o-7 p-72 d-2 p-60 d-3 o-12 p-72 d-2 p-69 d-2 o-13 p-60 d-1 o-18 p-69 d-2 p-65 d-2 p-53 d-1 o-23 p-65 d-3 o-24 p-53 d-4 o-28 p-72 d-2 p-60 d-1 o-32 p-69 d-2 p-60 d-2 o-33 p-72 d-1 o-39 p-65 d-9 o-40 p-53 d-1 o-45 p-60 d-2 p-57 d-1 p-48 d-2 b-1 s-9 t-35 i-0 o-1 p-60 d-1 p-57 d-2 p-48 d-4 o-6 p-69 d-5 p-57 d-1 o-11 p-65 d-1 p-60 d-1 p-53 d-1 p-48 d-1 o-15 p-65 d-1 p-60 d-2 o-16 p-53 d-4 p-48 d-2 o-22 p-74 d-5 p-62 d-3 o-26 p-48 d-2 o-27 p-69 d-2 p-57 d-1 o-30 p-57 d-2 o-31 p-69 d-8 p-65 d-3 p-48 d-2 o-34 p-60 d-11 o-37 p-36 d-5 o-41 p-72 d-19 p-48 d-2 b-1 s-9 t-35 i-0 o-0 p-68 d-4 o-1 p-65 d-1 p-62 d-2 p-56 d-3 p-53 d-1 p-50 d-2 o-6 p-68 d-2 p-65 d-2 p-62 d-2 p-56 d-2 p-53 d-2 p-50 d-2 o-11 p-68 d-3 p-50 d-2 o-12 p-65 d-2 p-62 d-1 p-56 d-2 p-53 d-2 o-16 p-68 d-4 o-17 p-65 d-1 o-18 p-62 d-2 p-56 d-2 o-19 p-50 d-2 o-20 p-53 d-1 o-22 p-71 d-2 p-59 d-2 o-27 p-59 d-2 o-28 p-71 d-4 o-31 p-56 d-2 p-53 d-2 p-50 d-2 o-32 p-68 d-1 p-65 d-1 p-62 d-1 o-36 p-68 d-2 p-65 d-2 p-62 d-2 p-56 d-2 o-37 p-53 d-1 p-50 d-1 o-43 p-48 d-7 o-44 p-36 d-4 b-1 s-9 t-35 i-0 o-0 p-65 d-2 o-1 p-59 d-2 p-53 d-1 o-5 p-65 d-3 p-59 d-2 p-53 d-1 o-10 p-53 d-2 p-41 d-2 o-14 p-65 d-2 o-15 p-59 d-1 p-53 d-1 o-19 p-65 d-3 p-59 d-2 p-53 d-1 o-26 p-58 d-4 p-46 d-6 o-33 p-59 d-2 p-53 d-2 o-34 p-65 d-2 o-39 p-65 d-10 p-36 d-3 p-24 d-3 o-40 p-59 d-6 p-53 d-7 b-1 s-9 t-35 i-0 o-2 p-56 d-35 p-44 d-34 o-12 p-64 d-4 p-60 d-4 p-52 d-4 o-20 p-64 d-2 p-60 d-3 p-52 d-3 o-27 p-52 d-3 o-28 p-64 d-1 p-60 d-2 o-35 p-60 d-6 p-52 d-5 o-36 p-64 d-4 o-41 p-55 d-4 o-42 p-43 d-2 b-1 s-9 t-35 i-0 o-0 p-55 d-8 p-43 d-10 o-8 p-64 d-2 p-60 d-3 p-52 d-3 o-17 p-64 d-2 p-60 d-3 p-52 d-2 o-19 p-36 d-11 o-22 p-43 d-10 o-26 p-52 d-8 o-32 p-67 d-2 p-55 d-3 o-33 p-64 d-2 o-34 p-60 d-1 o-39 p-67 d-3 p-60 d-2 p-55 d-1 o-40 p-64 d-1 o-44 p-55 d-5 o-45 p-52 d-2 p-48 d-4 b-1 s-9 t-35 i-0 o-2 p-72 d-1 p-64 d-1 p-60 d-2 o-3 p-67 d-2 o-6 p-72 d-2 p-60 d-2 o-7 p-67 d-1 p-64 d-1 o-10 p-60 d-4 p-55 d-2 o-11 p-52 d-3 o-15 p-72 d-3 p-67 d-2 p-64 d-1 o-19 p-67 d-2 o-20 p-76 d-2 p-72 d-1 p-64 d-1 o-23 p-64 d-6 o-24 p-60 d-2 p-55 d-4 o-28 p-79 d-2 p-76 d-2 p-72 d-2 p-67 d-1 o-32 p-79 d-2 p-76 d-1 p-72 d-1 p-67 d-1 o-36 p-67 d-5 p-64 d-3 p-60 d-4 o-40 p-84 d-1 p-79 d-2 p-76 d-2 p-72 d-2 o-44 p-84 d-2 p-79 d-1 p-76 d-1 p-72 d-2 b-1 s-9 t-35 i-0 o-0 p-72 d-5 p-67 d-2 p-64 d-4 o-4 p-84 d-2 p-79 d-2 p-76 d-2 o-5 p-88 d-1 o-8 p-84 d-2 p-79 d-2 o-9 p-88 d-2 o-13 p-67 d-13 o-14 p-76 d-3 o-17 p-91 d-2 o-18 p-88 d-2 p-84 d-2 p-79 d-1 o-22 p-91 d-2 p-88 d-2 p-79 d-2 o-23 p-84 d-1 o-26 p-76 d-3 p-68 d-16 o-27 p-72 d-2 o-30 p-92 d-2 p-88 d-2 p-80 d-2 o-31 p-84 d-2 o-34 p-92 d-4 p-80 d-2 o-35 p-84 d-1 o-36 p-88 d-1 o-39 p-76 d-7 p-71 d-10 o-40 p-72 d-8 o-44 p-95 d-3 p-84 d-2 p-83 d-2 o-45 p-88 d-1 b-1 s-9 t-35 i-0 o-1 p-95 d-4 p-88 d-2 p-84 d-3 p-83 d-3 o-6 p-76 d-5 p-71 d-13 o-7 p-72 d-2 o-12 p-95 d-2 p-88 d-2 p-84 d-2 p-83 d-2 o-18 p-95 d-1 p-88 d-2 p-84 d-2 p-83 d-1 o-23 p-76 d-6 o-24 p-72 d-5 p-69 d-8 o-28 p-93 d-2 p-88 d-3 p-81 d-2 o-29 p-84 d-1 o-33 p-93 d-2 p-84 d-3 p-81 d-2 o-34 p-88 d-1 o-38 p-76 d-1 p-72 d-2 p-64 d-5 o-42 p-88 d-2 p-84 d-2 o-47 p-88 d-2 p-84 d-1 b-1 s-9 t-35 i-0 o-4 p-76 d-5 p-66 d-12 o-5 p-72 d-5 o-9 p-90 d-1 p-78 d-1 o-10 p-88 d-1 p-84 d-2 o-14 p-90 d-3 p-88 d-2 p-84 d-1 p-78 d-2 o-19 p-74 d-5 p-67 d-7 o-20 p-71 d-5 o-24 p-91 d-2 p-79 d-2 o-25 p-86 d-2 p-83 d-1 o-30 p-91 d-9 p-86 d-4 p-79 d-6 o-31 p-83 d-2 p-61 d-5 o-35 p-69 d-2 o-38 p-70 d-1 o-42 p-76 d-10 b-1 s-9 t-35 i-0 o-0 p-93 d-3 p-88 d-3 p-81 d-2 o-8 p-93 d-5 o-9 p-88 d-3 p-81 d-3 o-12 p-62 d-62 o-14 p-67 d-56 o-17 p-69 d-52 o-20 p-74 d-45 o-24 p-79 d-51 o-28 p-81 d-3 o-33 p-86 d-45 o-41 p-91 d-35 o-42 p-81 d-32 b-1 s-9 t-35 i-0 o-46 p-43 d-7 b-1 s-9 t-35 i-0 o-4 p-50 d-3 o-8 p-55 d-3 o-13 p-59 d-3 o-17 p-65 d-67 o-22 p-67 d-10 o-29 p-71 d-59 o-45 p-77 d-36 b-1 s-9 t-35 b-1 s-9 t-35 i-0 o-18 p-24 d-16 o-34 p-36 d-6 o-46 p-43 d-13 b-1 s-9 t-35 i-0 o-7 p-48 d-16 o-18 p-52 d-12 o-32 p-55 d-10 b-1 s-9 t-35 i-0 o-3 p-60 d-12 b-1 s-9 t-35 i-0 o-5 p-64 d-57 b-1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d577efca-e37d-4684-be81-9ea691c34dfe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>location</th>\n",
              "      <th>genre</th>\n",
              "      <th>remiz_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lmd_full/2/2a604c93ed4ee9d82d388da694e89e7c.mid</td>\n",
              "      <td>[reggae, pop]</td>\n",
              "      <td>s-9 t-33 b-1 s-9 t-33 i-58 o-0 p-73 d-25 o-24 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lmd_full/0/0fd51dae1d5ffc871de6b8bd8ff3e5ce.mid</td>\n",
              "      <td>[pop, popfolk]</td>\n",
              "      <td>s-9 t-33 b-1 s-9 t-33 i-28 o-30 p-48 d-3 o-36 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lmd_full/0/00bb4be2822c3828935498af7b90b98e.mid</td>\n",
              "      <td>[pop, jazz]</td>\n",
              "      <td>s-9 t-25 b-1 s-9 t-25 i-0 o-2 p-61 d-7 p-59 d-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lmd_full/e/e7394f75f6978369eb463abcb75a88da.mid</td>\n",
              "      <td>[electronic, pop]</td>\n",
              "      <td>s-9 t-42 b-1 s-9 t-42 i-33 o-0 p-35 d-4 o-12 p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lmd_full/f/f5ac97af893d6b5cec0324bc49ae10bb.mid</td>\n",
              "      <td>[electronic, experimental]</td>\n",
              "      <td>s-9 t-38 i-81 o-6 p-53 d-6 p-48 d-6 o-30 p-53 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d577efca-e37d-4684-be81-9ea691c34dfe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d577efca-e37d-4684-be81-9ea691c34dfe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d577efca-e37d-4684-be81-9ea691c34dfe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-89397f29-2251-4552-92d5-042142fcd9c1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-89397f29-2251-4552-92d5-042142fcd9c1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-89397f29-2251-4552-92d5-042142fcd9c1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                          location  \\\n",
              "0  lmd_full/2/2a604c93ed4ee9d82d388da694e89e7c.mid   \n",
              "1  lmd_full/0/0fd51dae1d5ffc871de6b8bd8ff3e5ce.mid   \n",
              "2  lmd_full/0/00bb4be2822c3828935498af7b90b98e.mid   \n",
              "3  lmd_full/e/e7394f75f6978369eb463abcb75a88da.mid   \n",
              "4  lmd_full/f/f5ac97af893d6b5cec0324bc49ae10bb.mid   \n",
              "\n",
              "                        genre  \\\n",
              "0               [reggae, pop]   \n",
              "1              [pop, popfolk]   \n",
              "2                 [pop, jazz]   \n",
              "3           [electronic, pop]   \n",
              "4  [electronic, experimental]   \n",
              "\n",
              "                                           remiz_str  \n",
              "0  s-9 t-33 b-1 s-9 t-33 i-58 o-0 p-73 d-25 o-24 ...  \n",
              "1  s-9 t-33 b-1 s-9 t-33 i-28 o-30 p-48 d-3 o-36 ...  \n",
              "2  s-9 t-25 b-1 s-9 t-25 i-0 o-2 p-61 d-7 p-59 d-...  \n",
              "3  s-9 t-42 b-1 s-9 t-42 i-33 o-0 p-35 d-4 o-12 p...  \n",
              "4  s-9 t-38 i-81 o-6 p-53 d-6 p-48 d-6 o-30 p-53 ...  "
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2eqkFosMDI4"
      },
      "outputs": [],
      "source": [
        "# df.to_csv('midi_to_remiz_str.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGzDuF8yOTOs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nxZYi-1uHiF"
      },
      "source": [
        "## Model Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "2a1b4036307943b3964881f03165fec8",
            "97bee1bfd448416eaf8b021813ab5ab9",
            "c15eff3220f7435890af4aaddd98f3cb",
            "e83ec1ddc8824f998229135628fab7ee",
            "28bc238ba4b94e7298d1395fd0cfc51c",
            "496f38da15ce46f491017635f1717bca",
            "47892ad649814b5faee72728f062d3e1",
            "b2e37a6a3ee344d5a161be3788943b47",
            "f92c66900a0c43ca9055b1cb29693c1e",
            "89dd8a7538294d01a77d5321b6a3163a",
            "d9ea2eda759a41fc8fe3e7ccd6cba530",
            "70fbdb57e4bf4eae8a977ad307b37eb0",
            "85f3d220ab34443e8c0fac5c63e7bcff",
            "981d4b45bf524bd5a64912b850c9d310",
            "4edfe0c86a3e40c487e5ee4c6c2c1423",
            "5d75c7861a1e44e18fd93a4b56d9d6a2",
            "18c6d7d86c4b41988a9a472f05542370",
            "d478ca79f3ff470a8b4412f6fbc15b36",
            "df1a24cef97b49c097ea4b67bd7ca44d",
            "3c09c3100d144816a2a1d3e7fd8265e7",
            "1e725a02050e4cea879941f3ebfc4faa",
            "e718e3db8f0141a285a639d45cde66d3",
            "35d39819d96b4b80b8cd881cffbf8cf8",
            "a238f1225ed04f05a278e222aef91b69",
            "dc36a6135c3f4cc2af1940d89ae81ced",
            "e0ab1c01be274ff09bdb089a96d46020",
            "e3babef5aa764e539ab024e23abb48c6",
            "83fcc4a284144217b87cc890207c23ed",
            "fc8277ad66e24c26889431fa7b3f3f38",
            "cf13a028c3ef4aea952648faf7808948",
            "9d168fbc8c9944668b6eee2863653cc5",
            "f8d39c6452ee44acb78f5d6c09884b07",
            "0989f2b384a34486899bcd8c98bc1be1",
            "d2e2f0a51a9041f3934dc3d0ecb44023",
            "349cf384cf6d47798d30f50b8f3facef",
            "23621cfcd50b4d4abbd3c63dd2cf2314",
            "ce9831eb7a324779856743010728e8f7",
            "534eb9f0131a48a58a0306e2a8a6c85b",
            "7b6a2d92f23b40aa90a38645f5da955e",
            "14f95cb68e7046328e88da6a1dfa4702",
            "b7397a5a085142bf9ab85ee487617e63",
            "55fea2b999614beb858c94ea3de551cb",
            "f8c47af85de2490f8d17c18f1bcf26cb",
            "cfd07bd1b0624d0392752d9f59004dae",
            "dcf169cbc14048b380e243ee2bd14a4a",
            "d24a292fd89c403c8598bfc4beea36fc",
            "f3927f9483a146138b4a8882f832b95b",
            "7f4f328f771e4ad4a6af756ec31e06c8",
            "fdd130428feb4cdd86d6a7480abb509c",
            "362b59c182064ab1b78c4480432c9761",
            "a2f2c6c5431641b8831433d5339d4104",
            "300b8de437944cfbbfe45e923ec0248e",
            "ea82cbed1d124e3aaaa4178510a2200b",
            "d6437fc8b86b426b8094976ff1a8e011",
            "2b2c9b60879849afb4ccbc981c2edcf4",
            "c0b428b4da304a1da9eb2c29184ad43a",
            "eed33007457946a698fa4ad91acf048d",
            "95837b59fa7b404f9590c015cefd2a84",
            "76f3005d96ec4bd5a8e349ab4a4254a9",
            "fda56091e23643bab2960a0edf072587",
            "c5d7d1e0f1424b3289cab78c43d6865c",
            "3357b1ce4fad4cfe9a1b788c7c21f32f",
            "952e2fc228684ee987e909d58035cc43",
            "bfadc6ec0fcf48e89339fb8ad27dbc85",
            "41ba21f88158449991f5e0ca3e0d4346",
            "c3624ec6061f4568876ad2ca7c754b94"
          ]
        },
        "id": "a6UkZNDX-6z2",
        "outputId": "ac86f176-fa36-4068-a3cd-3a3eed2ba1e9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a1b4036307943b3964881f03165fec8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70fbdb57e4bf4eae8a977ad307b37eb0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35d39819d96b4b80b8cd881cffbf8cf8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/857 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2e2f0a51a9041f3934dc3d0ecb44023",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/909 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dcf169cbc14048b380e243ee2bd14a4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/175M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0b428b4da304a1da9eb2c29184ad43a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load model\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"LongshenOu/m2m_pt\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"LongshenOu/m2m_pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGyfIaxg1vWe",
        "outputId": "8ed6bffc-a9df-4da0-88e4-6856c41ae33c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Special Tokens ---\n",
            "BOS Token (Start): [BOS] (ID: 2)\n",
            "EOS Token (End):   [EOS] (ID: 1)\n",
            "PAD Token (Padding): [EOS] (ID: 1)\n",
            "UNK Token (Unknown): [UNK] (ID: 0)\n"
          ]
        }
      ],
      "source": [
        "# Check the Special Tokens (BOS, EOS, PAD, UNK)\n",
        "print(\"--- Special Tokens ---\")\n",
        "print(f\"BOS Token (Start): {tokenizer.bos_token} (ID: {tokenizer.bos_token_id})\")\n",
        "print(f\"EOS Token (End):   {tokenizer.eos_token} (ID: {tokenizer.eos_token_id})\")\n",
        "print(f\"PAD Token (Padding): {tokenizer.pad_token} (ID: {tokenizer.pad_token_id})\")\n",
        "print(f\"UNK Token (Unknown): {tokenizer.unk_token} (ID: {tokenizer.unk_token_id})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLHvcV5p2xT7",
        "outputId": "7148d45a-07c6-4b18-eba6-87a0c39c1a71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Vocabulary Size ---\n",
            "Vocabulary Size: 989\n",
            "{'s-209': 895, 'i-34': 175, 'p-243': 513, 's-21': 707, 'o-96': 109, 'i-104': 245, 'o-2': 15, 'o-52': 65, 'p-66': 336, 'd-83': 609, 't-25': 965, 'o-56': 69, 'p-196': 466, 'v-13': 667, 't-21': 961, 'v-17': 671, 'd-51': 577, 'i-57': 198, 's-169': 855, 'd-96': 622, 'p-100': 370, 'd-76': 602, 'o-93': 106, 'p-79': 349, 'p-61': 331, 's-251': 937, 'p-129': 399, 'i-92': 233, 'p-162': 432, 's-26': 712, 'v-3': 657, 'p-72': 342, 'i-66': 207, 'd-4': 530, 's-110': 796, '[INST]': 9, 'p-244': 514, 's-190': 876, 'i-5': 146, 's-149': 835, 's-117': 803, 'p-215': 485, 'o-12': 25, 'p-12': 282, 'p-140': 410, 'o-45': 58, 's-225': 911, 'i-84': 225, 's-62': 748, 'p-21': 291, 's-81': 767, 'd-32': 558, 'd-117': 643, 'p-109': 379, 'i-85': 226, 'o-37': 50, 'p-173': 443, 's-207': 893, 's-42': 728, 'o-106': 119, 'v-4': 658, 's-230': 916, 'o-111': 124, 's-6': 692, 't-27': 967, 'i-110': 251, 'p-184': 454, 'd-14': 540, 'i-106': 247, 'p-154': 424, 'd-57': 583, 'p-144': 414, 't-37': 977, 'p-226': 496, 's-118': 804, 's-152': 838, 'p-187': 457, 'd-113': 639, 'd-60': 586, 'p-36': 306, 'p-37': 307, 'p-214': 484, 'i-14': 155, 's-128': 814, 'd-26': 552, 'p-52': 322, 'p-199': 469, 'p-57': 327, 'd-37': 563, 'd-81': 607, 'o-10': 23, 'p-50': 320, 's-99': 785, 'd-17': 543, 'p-39': 309, 'd-24': 550, 's-178': 864, 's-237': 923, 'p-71': 341, 'p-192': 462, 's-145': 831, 'i-89': 230, 'i-88': 229, 's-156': 842, 'o-8': 21, 'p-223': 493, '[CLS]': 3, 'p-224': 494, 's-85': 771, 'i-63': 204, 't-5': 945, 's-153': 839, 'i-103': 244, 'o-104': 117, 'p-51': 321, 's-2': 688, 'd-103': 629, 'p-168': 438, 's-146': 832, 's-83': 769, 's-106': 792, 't-47': 987, 'd-100': 626, 'd-108': 634, 'd-12': 538, 'p-44': 314, 's-167': 853, 'p-139': 409, 's-58': 744, 't-3': 943, 'd-106': 632, 's-187': 873, 'o-57': 70, 'p-101': 371, 's-252': 938, 'i-91': 232, 's-191': 877, 'o-86': 99, 'i-127': 268, 'p-216': 486, 's-253': 939, 'p-2': 272, 'd-59': 585, 's-161': 847, 'o-18': 31, 'o-83': 96, 'd-66': 592, 'd-88': 614, 's-180': 866, 'p-151': 421, 'v-19': 673, 's-208': 894, 'd-77': 603, 'p-182': 452, 't-2': 942, 'o-102': 115, 's-124': 810, 'i-55': 196, 'i-117': 258, 'd-104': 630, 's-46': 732, 't-28': 968, 'p-92': 362, 'o-99': 112, 'd-91': 617, 'i-95': 236, 'p-89': 359, 's-45': 731, 'p-167': 437, 'o-121': 134, 'i-56': 197, 's-111': 797, 's-229': 915, 'o-84': 97, 's-171': 857, 'i-3': 144, 'i-81': 222, 'p-81': 351, 's-41': 727, 'p-65': 335, 's-246': 932, 'd-28': 554, 'p-83': 353, 'p-97': 367, 's-57': 743, 'p-78': 348, 'i-39': 180, 'i-83': 224, 'o-71': 84, 's-50': 736, 's-247': 933, 'p-221': 491, 'p-229': 499, 's-64': 750, 's-159': 845, 'p-218': 488, 's-216': 902, 's-231': 917, 'i-93': 234, 'p-160': 430, 's-185': 871, 'o-100': 113, 'd-50': 576, 'd-75': 601, 's-197': 883, 'o-97': 110, 'i-82': 223, 's-108': 794, 'p-11': 281, 'i-2': 143, 's-212': 898, 's-104': 790, 's-186': 872, 's-96': 782, 's-228': 914, 's-34': 720, 'i-9': 150, 'p-209': 479, 'o-20': 33, 'd-15': 541, 'p-80': 350, 'o-7': 20, 'o-46': 59, 'v-28': 682, 's-59': 745, 'd-43': 569, 'd-84': 610, 's-82': 768, 'p-198': 468, 'd-46': 572, 's-65': 751, 's-5': 691, 'p-127': 397, 's-244': 930, 'i-128': 269, 'p-27': 297, '[CHORD]': 11, 't-46': 986, 's-55': 741, 't-44': 984, 'p-48': 318, 'p-7': 277, 's-198': 884, 'd-54': 580, 'p-133': 403, 'i-32': 173, 's-204': 890, 'i-50': 191, 's-33': 719, 'i-26': 167, 's-221': 907, 'p-67': 337, 'p-26': 296, 't-11': 951, 'o-53': 66, 'i-1': 142, 'd-102': 628, 'o-69': 82, 's-199': 885, 's-188': 874, 'd-62': 588, 'o-110': 123, 's-4': 690, 'p-110': 380, 'p-211': 481, 'o-38': 51, 'i-16': 157, 's-7': 693, 't-14': 954, 'i-43': 184, 'p-62': 332, 's-109': 795, 'o-116': 129, 'o-115': 128, 's-100': 786, 's-233': 919, 'p-207': 477, 's-32': 718, 'o-62': 75, 'o-24': 37, 'p-239': 509, 'p-114': 384, 'o-51': 64, 's-1': 687, 'p-1': 271, 's-203': 889, 'd-116': 642, 'o-113': 126, 's-196': 882, 'o-36': 49, 's-70': 756, 's-172': 858, 'i-20': 161, 's-227': 913, 't-41': 981, 's-121': 807, 'o-44': 57, 'd-0': 526, 'p-116': 386, 'd-61': 587, 'p-19': 289, 'p-16': 286, 's-12': 698, 'd-65': 591, 's-48': 734, 'p-204': 474, 'i-111': 252, 's-113': 799, 'i-40': 181, 'i-79': 220, 's-112': 798, 'p-115': 385, 'p-122': 392, 's-202': 888, 'p-77': 347, 'd-53': 579, 'd-19': 545, 't-22': 962, 'i-46': 187, 'p-230': 500, 'd-87': 613, 'i-53': 194, 's-73': 759, 's-13': 699, 'p-213': 483, 's-183': 869, 'p-102': 372, 'p-22': 292, 'o-92': 105, 'o-22': 35, 'p-20': 290, 's-224': 910, 's-86': 772, 'o-42': 55, 'o-77': 90, '[PAD]': 5, 'v-24': 678, 's-36': 722, 'o-15': 28, 's-103': 789, 'o-80': 93, 'i-126': 267, 'p-73': 343, 'p-8': 278, 's-176': 862, 'p-161': 431, 'd-18': 544, 'p-159': 429, 'v-0': 654, 'i-25': 166, 'd-63': 589, 'v-2': 656, 's-134': 820, 's-130': 816, 'o-81': 94, 'p-91': 361, 'p-135': 405, 'v-22': 676, 's-10': 696, 'p-13': 283, 'p-0': 270, 's-120': 806, 'd-118': 644, 's-29': 715, 's-88': 774, 'v-7': 661, 'p-205': 475, 'i-45': 186, 'p-225': 495, 'o-0': 13, 'p-5': 275, 'p-194': 464, 'o-108': 121, 'd-127': 653, 's-31': 717, 'd-23': 549, 's-136': 822, 's-192': 878, 's-114': 800, 'p-250': 520, 't-43': 983, 'p-108': 378, 's-162': 848, 'p-47': 317, 'p-31': 301, 'd-89': 615, 'p-153': 423, 'd-123': 649, 'o-66': 79, 'p-206': 476, 's-173': 859, 'd-13': 539, 's-15': 701, 'p-98': 368, 's-155': 841, 'd-41': 567, 's-54': 740, 'p-156': 426, 'p-121': 391, 'd-126': 652, 'p-220': 490, 'p-141': 411, 'i-64': 205, 'p-43': 313, 'i-94': 235, 's-71': 757, 'p-189': 459, 's-220': 906, 'd-92': 618, 'd-39': 565, 'v-5': 659, 'p-147': 417, 'p-4': 274, 'v-25': 679, 'p-181': 451, 'p-186': 456, 's-102': 788, 's-170': 856, 'd-79': 605, 't-35': 975, 'p-3': 273, 'p-180': 450, 'p-149': 419, 'o-43': 56, 'o-11': 24, 'o-59': 72, 'd-10': 536, 's-101': 787, 's-148': 834, 'd-122': 648, 's-166': 852, 's-248': 934, 's-89': 775, 's-16': 702, 'p-155': 425, 'd-119': 645, 'v-26': 680, 'p-201': 471, 'p-212': 482, 'p-200': 470, 's-66': 752, 't-12': 952, 'p-166': 436, 's-92': 778, 's-14': 700, 's-236': 922, 's-181': 867, 'p-70': 340, 'o-82': 95, 'd-71': 597, 'p-94': 364, 't-32': 972, 'p-246': 516, 's-177': 863, 's-43': 729, 's-125': 811, 'o-112': 125, 'i-87': 228, 't-19': 959, 's-137': 823, 'o-27': 40, 's-27': 713, 's-38': 724, 'o-50': 63, 'p-172': 442, 'o-13': 26, 'p-45': 315, 's-168': 854, 'd-101': 627, 'p-132': 402, 's-49': 735, 'i-36': 177, 'o-98': 111, 'p-165': 435, 'p-237': 507, 's-20': 706, 'i-30': 171, 'd-58': 584, '[SEP]': 4, 'o-47': 60, 's-193': 879, 'p-179': 449, 'p-126': 396, 'i-101': 242, 'p-251': 521, 'o-120': 133, 'o-90': 103, 'i-123': 264, 'p-125': 395, 'i-77': 218, 'o-17': 30, 'p-34': 304, 'p-58': 328, 's-250': 936, 'd-8': 534, 's-138': 824, 'd-114': 640, 's-79': 765, 'p-197': 467, 'v-16': 670, 's-163': 849, 'i-41': 182, 'i-100': 241, 'p-235': 505, 'i-11': 152, 'd-95': 621, 'p-193': 463, 'o-30': 43, 's-23': 709, 'o-103': 116, 'i-31': 172, 'p-17': 287, 'p-15': 285, 'o-31': 44, 'i-70': 211, 'p-171': 441, 'i-114': 255, 'p-164': 434, 'i-112': 253, 'i-22': 163, 's-142': 828, 'p-99': 369, 's-77': 763, '[PITCH]': 8, 's-75': 761, 'd-105': 631, 'o-65': 78, 'o-28': 41, 'p-146': 416, 'p-112': 382, 'd-97': 623, 'p-255': 525, 's-78': 764, 'd-35': 561, 'i-98': 239, 's-210': 896, 'p-150': 420, 'i-61': 202, 'p-176': 446, 'p-68': 338, 's-158': 844, 'p-23': 293, 'p-123': 393, 'p-69': 339, 's-24': 710, 's-91': 777, 'p-177': 447, 'i-19': 160, 'i-74': 215, 'v-9': 663, 's-135': 821, 'p-49': 319, 'p-113': 383, 's-95': 781, 'p-42': 312, 's-151': 837, 's-93': 779, 'v-15': 669, 's-234': 920, 'p-195': 465, 'd-38': 564, 'o-14': 27, 'p-131': 401, 's-11': 697, 'i-119': 260, 's-150': 836, 'i-68': 209, 't-34': 974, 's-98': 784, 'o-9': 22, 'd-5': 531, 't-39': 979, 'p-9': 279, 'i-8': 149, 'i-121': 262, 'o-48': 61, 'i-24': 165, 'd-124': 650, 'i-52': 193, 'o-114': 127, 'i-97': 238, 'p-231': 501, 'o-64': 77, 'i-33': 174, 'o-35': 48, 'd-70': 596, 't-42': 982, 's-37': 723, 's-97': 783, 'd-25': 551, 't-8': 948, 's-144': 830, 'd-16': 542, 's-218': 904, 'd-33': 559, 'v-14': 668, 'p-145': 415, 'p-54': 324, 'o-119': 132, 'i-86': 227, 'd-110': 636, 'b-1': 12, 'p-240': 510, 't-29': 969, 's-19': 705, 'd-112': 638, 'p-241': 511, 'o-124': 137, 'p-46': 316, 't-38': 978, 'p-82': 352, 'i-60': 201, 'i-80': 221, 'i-118': 259, 's-154': 840, 'd-29': 555, 'p-59': 329, 'v-6': 660, 's-22': 708, 'd-22': 548, 'v-1': 655, 'i-4': 145, 'd-55': 581, 's-74': 760, 'o-54': 67, 'o-4': 17, 's-164': 850, 'v-31': 685, 'i-59': 200, 'o-19': 32, 'd-44': 570, 'd-80': 606, 'd-85': 611, 'i-102': 243, 's-165': 851, 's-122': 808, 'p-120': 390, 'o-122': 135, 'p-217': 487, 'o-117': 130, 't-7': 947, 'o-126': 139, 's-242': 928, 'd-30': 556, 'o-55': 68, 'd-120': 646, 'd-72': 598, 'p-183': 453, 's-8': 694, 'o-41': 54, 'd-47': 573, 'o-123': 136, 'p-74': 344, 't-24': 964, 'd-74': 600, 'o-1': 14, 'p-245': 515, 's-205': 891, 'd-115': 641, '[UNK]': 0, 'p-138': 408, '[MELODY]': 10, 'p-163': 433, 'p-18': 288, 'o-49': 62, 'o-67': 80, 'i-67': 208, 'v-11': 665, 'p-174': 444, 's-76': 762, 't-40': 980, 'p-33': 303, 'p-30': 300, 's-174': 860, 's-194': 880, 'd-3': 529, 's-133': 819, 'p-87': 357, 'p-253': 523, 's-40': 726, 'p-238': 508, 'o-74': 87, 'p-136': 406, 'o-61': 74, 'o-78': 91, 'p-90': 360, 's-39': 725, 'd-93': 619, 'p-60': 330, 'p-95': 365, 's-132': 818, 'd-9': 535, 'p-14': 284, 'v-21': 675, 'd-90': 616, 'p-117': 387, 's-35': 721, 'p-254': 524, 'd-107': 633, 't-23': 963, 'i-12': 153, 'i-76': 217, 'o-107': 120, 's-67': 753, 'p-29': 299, 's-0': 686, 's-147': 833, 's-127': 813, 'p-6': 276, 'd-31': 557, 's-119': 805, 's-94': 780, 'p-152': 422, 'o-26': 39, 's-56': 742, 'd-27': 553, 'p-169': 439, 'i-35': 176, 'i-99': 240, 'p-203': 473, 'i-72': 213, 'i-23': 164, 'p-248': 518, 'o-23': 36, 'p-105': 375, 'd-109': 635, 'p-188': 458, 's-68': 754, 't-9': 949, 'i-108': 249, 'p-88': 358, 'p-10': 280, 'd-68': 594, 'p-28': 298, 'd-20': 546, 't-45': 985, 'i-28': 169, 't-6': 946, 't-36': 976, 't-4': 944, 'o-68': 81, 'o-58': 71, 'p-41': 311, 'p-55': 325, 'o-70': 83, 's-200': 886, 'i-18': 159, 's-141': 827, 'o-33': 46, '[MASK]': 6, 'p-35': 305, 'd-52': 578, 't-15': 955, 'p-119': 389, 'p-232': 502, 'o-16': 29, 'd-40': 566, 'p-63': 333, 's-232': 918, 'p-75': 345, 'i-29': 170, 't-13': 953, 't-16': 956, 'i-73': 214, 'd-99': 625, 'p-234': 504, 'o-40': 53, 'd-67': 593, 'v-10': 664, 'd-7': 533, 't-20': 960, 'o-88': 101, 'o-25': 38, 'p-142': 412, 's-3': 689, 'd-1': 527, 'p-236': 506, 's-9': 695, 'p-252': 522, 's-60': 746, 's-90': 776, 's-157': 843, 'o-94': 107, 'i-122': 263, 's-63': 749, 's-189': 875, 'd-82': 608, 's-240': 926, 's-241': 927, 'p-104': 374, 's-245': 931, 's-25': 711, 'd-94': 620, 'i-51': 192, 't-30': 970, 't-0': 940, 'p-249': 519, 'o-29': 42, 't-31': 971, 'p-219': 489, 'p-228': 498, 's-235': 921, 'v-27': 681, 'd-86': 612, 'i-54': 195, 'p-53': 323, 'p-175': 445, 's-18': 704, 's-28': 714, 'p-96': 366, 'd-2': 528, 'i-96': 237, 'p-233': 503, 'o-89': 102, 's-243': 929, 'd-36': 562, 'o-105': 118, 's-87': 773, 'd-69': 595, 'i-69': 210, 'o-127': 140, 's-123': 809, 's-72': 758, 'p-103': 373, 's-52': 738, 'i-21': 162, 'p-24': 294, 'i-115': 256, 'o-73': 86, 'i-120': 261, 's-249': 935, 'p-190': 460, 's-69': 755, 'd-73': 599, 'i-48': 189, 'p-124': 394, '[EOS]': 1, 'i-113': 254, 'p-208': 478, 'i-47': 188, 's-44': 730, 'o-125': 138, 'o-72': 85, 'i-105': 246, 'i-10': 151, 's-217': 903, 'p-148': 418, 'i-62': 203, 'o-79': 92, '[HIST]': 7, 's-195': 881, 'd-21': 547, 'd-56': 582, 'o-87': 100, 'p-32': 302, 's-201': 887, 'o-95': 108, 's-214': 900, 'i-37': 178, 'p-170': 440, 'd-121': 647, 'i-90': 231, 'p-84': 354, 't-48': 988, 's-131': 817, 'i-17': 158, 'p-247': 517, 's-238': 924, 'o-32': 45, 's-17': 703, 'o-6': 19, 's-53': 739, 'v-8': 662, 'i-107': 248, 's-129': 815, 'o-118': 131, 'p-143': 413, 'd-49': 575, 'p-111': 381, 'o-109': 122, 's-61': 747, 's-126': 812, 'p-210': 480, 'o-21': 34, 'p-128': 398, 'o-3': 16, 's-47': 733, 'i-75': 216, 's-116': 802, 's-143': 829, 's-105': 791, 'p-157': 427, 'p-222': 492, 't-17': 957, 'i-0': 141, 'p-202': 472, 'p-227': 497, 'i-7': 148, 's-107': 793, 'v-23': 677, 'i-71': 212, 'd-42': 568, 's-30': 716, 'o-101': 114, 'o-63': 76, 's-140': 826, 'p-25': 295, 'd-11': 537, 'p-85': 355, 't-18': 958, 'i-65': 206, 't-26': 966, 'd-48': 574, 's-226': 912, 'p-118': 388, 's-211': 897, 'v-30': 684, 'p-40': 310, 'i-13': 154, 't-1': 941, 'p-185': 455, 'p-191': 461, 'p-93': 363, 's-175': 861, 'p-130': 400, 'o-5': 18, 'p-158': 428, 'i-78': 219, 's-80': 766, 'd-111': 637, 'o-39': 52, 's-215': 901, 'i-125': 266, 'p-86': 356, 'p-106': 376, 'i-109': 250, 'd-6': 532, 's-223': 909, '[BOS]': 2, 'p-56': 326, 'i-116': 257, 'i-49': 190, 's-51': 737, 'p-64': 334, 'p-38': 308, 's-213': 899, 'i-42': 183, 's-206': 892, 'i-6': 147, 'p-76': 346, 's-160': 846, 'i-27': 168, 'p-137': 407, 'i-124': 265, 'p-134': 404, 'v-20': 674, 's-239': 925, 's-219': 905, 's-184': 870, 'o-91': 104, 'o-75': 88, 'p-242': 512, 'i-44': 185, 'v-29': 683, 'p-178': 448, 'd-78': 604, 's-115': 801, 'v-12': 666, 'o-76': 89, 'p-107': 377, 's-222': 908, 's-139': 825, 's-84': 770, 'i-58': 199, 'd-98': 624, 'i-38': 179, 'o-34': 47, 's-179': 865, 's-182': 868, 'o-60': 73, 't-10': 950, 'v-18': 672, 'd-34': 560, 't-33': 973, 'o-85': 98, 'i-15': 156, 'd-125': 651, 'd-64': 590, 'd-45': 571}\n"
          ]
        }
      ],
      "source": [
        "# Check the Vocabulary Size\n",
        "print(\"\\n--- Vocabulary Size ---\")\n",
        "print(f\"Vocabulary Size: {len(tokenizer.vocab)}\")\n",
        "print(tokenizer.vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3A11uhx28Fp",
        "outputId": "5f1ba1b0-f71a-46ac-93cf-abfbb44cf20a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Vocabulary (First 20 tokens) ---\n",
            "ID 0: [UNK]\n",
            "ID 1: [EOS]\n",
            "ID 2: [BOS]\n",
            "ID 3: [CLS]\n",
            "ID 4: [SEP]\n",
            "ID 5: [PAD]\n",
            "ID 6: [MASK]\n",
            "ID 7: [HIST]\n",
            "ID 8: [PITCH]\n",
            "ID 9: [INST]\n",
            "ID 10: [MELODY]\n",
            "ID 11: [CHORD]\n",
            "ID 12: b-1\n",
            "ID 13: o-0\n",
            "ID 14: o-1\n",
            "ID 15: o-2\n",
            "ID 16: o-3\n",
            "ID 17: o-4\n",
            "ID 18: o-5\n",
            "ID 19: o-6\n"
          ]
        }
      ],
      "source": [
        "# Get a Sample of the Vocabulary\n",
        "print(\"\\n--- Sample Vocabulary (First 20 tokens) ---\")\n",
        "# The tokenizer's vocab is a dictionary mapping token strings to IDs.\n",
        "id_to_token = {v: k for k, v in tokenizer.vocab.items()}\n",
        "for i in range(20):\n",
        "    print(f\"ID {i}: {id_to_token.get(i, '[Token not found]')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_clVxxYc_Mz",
        "outputId": "cd74bb81-2bd5-40ff-d241-adbb25026494"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': [2, 689, 976, 214, 13, 349, 534, 22, 349, 529, 25, 348, 531, 31, 349, 531, 37, 351, 531, 43, 353, 531, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ],
      "source": [
        "sample_remiz_input = \"s-3 t-36 i-73 o-0 p-79 d-8 o-9 p-79 d-3 o-12 p-78 d-5 o-18 p-79 d-5 o-24 p-81 d-5 o-30 p-83 d-5\"\n",
        "tokenized_input = tokenizer(sample_remiz_input)\n",
        "print(tokenized_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQtriCTBl5S_",
        "outputId": "c30af6de-c06c-417e-8a5d-788878a056a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[BOS]', 's-3', 't-36', 'i-73', 'o-0', 'p-79', 'd-8', 'o-9', 'p-79', 'd-3', 'o-12', 'p-78', 'd-5', 'o-18', 'p-79', 'd-5', 'o-24', 'p-81', 'd-5', 'o-30', 'p-83', 'd-5', '[EOS]']\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.convert_ids_to_tokens(tokenized_input['input_ids']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWjlgsLTmBYU",
        "outputId": "ed086b9b-0166-4b3c-ef56-47400ee3be8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(989, 768)\n",
            "    (wpe): Embedding(2048, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=768)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=989, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-I6XRHgmBVb",
        "outputId": "4314072d-6d16-4922-cbdb-e6bc887d89b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Model Configuration ---\n",
            "GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"dtype\": \"float32\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 2048,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 16,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 2048,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.57.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 989\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Model Configuration ---\")\n",
        "print(model.config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIXmcv_mmBS3",
        "outputId": "9234551c-4353-431a-8c20-2e339e1aee10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max sequence length of the model (n_positions): 2048\n"
          ]
        }
      ],
      "source": [
        "print(f\"Max sequence length of the model (n_positions): {model.config.n_positions}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cp6lbkCrl5Fm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xvf8oHhias_r",
        "outputId": "caeebe03-2cf9-4d1d-babd-b8a4eda9367f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42\n"
          ]
        }
      ],
      "source": [
        "print(NUM_CLASSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T58A4LpawUj",
        "outputId": "f9eb146e-ca7c-48f6-c603-5d7c9d4629a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'80s': 0, '90s': 1, 'alternative': 2, 'ambient': 3, 'blues': 4, 'celtic': 5, 'chillout': 6, 'classical': 7, 'country': 8, 'dance': 9, 'drumnbass': 10, 'easylistening': 11, 'electronic': 12, 'electropop': 13, 'experimental': 14, 'folk': 15, 'funk': 16, 'hiphop': 17, 'house': 18, 'indie': 19, 'instrumentalpop': 20, 'instrumentalrock': 21, 'jazz': 22, 'jazzfusion': 23, 'latin': 24, 'lounge': 25, 'metal': 26, 'newage': 27, 'orchestral': 28, 'pop': 29, 'popfolk': 30, 'poprock': 31, 'punkrock': 32, 'reggae': 33, 'rock': 34, 'soundtrack': 35, 'swing': 36, 'symphonic': 37, 'synthpop': 38, 'techno': 39, 'trance': 40, 'world': 41}\n"
          ]
        }
      ],
      "source": [
        "print(CLASS_TO_INDEX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_27HoVomQke"
      },
      "outputs": [],
      "source": [
        "# --- Configuration Constants ---\n",
        "MODEL_NAME = 'gpt2'\n",
        "MAX_CHUNK_LENGTH = 256 # Reduced for memory\n",
        "EMBEDDING_DIM = 768\n",
        "BATCH_SIZE = 4\n",
        "# NUM_CLASSES = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nfM-moCmhjj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4eO3D9VmQND"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46d1d4e7",
        "outputId": "833576c6-e81d-4242-86bd-dff2f6bc7084"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Text: s-3 t-36 i-73 o-0 p-79 d-8\n",
            "Input IDs: tensor([  2, 689, 976, 214,  13, 349, 534,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1])\n",
            "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Input IDs Shape: torch.Size([1, 512])\n",
            "Attention Mask Shape: torch.Size([1, 512])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Sample input sequence\n",
        "input_text = \"s-3 t-36 i-73 o-0 p-79 d-8\"\n",
        "\n",
        "# Tokenize the input text, also returning the attention mask\n",
        "encoded_inputs = tokenizer.encode_plus(\n",
        "    input_text,\n",
        "    add_special_tokens=True,\n",
        "    max_length=MAX_CHUNK_LENGTH,\n",
        "    return_token_type_ids=False,\n",
        "    padding=\"max_length\",\n",
        "    return_tensors=\"pt\",\n",
        "    return_attention_mask=True\n",
        ")\n",
        "input_ids = encoded_inputs[\"input_ids\"]\n",
        "attention_mask = encoded_inputs[\"attention_mask\"]\n",
        "\n",
        "print(f\"Input Text: {input_text}\")\n",
        "print(f\"Input IDs: {input_ids.squeeze()[:20]}\")\n",
        "print(f\"Attention Mask: {attention_mask.squeeze()[:20]}\")\n",
        "print(f\"Input IDs Shape: {input_ids.shape}\")\n",
        "print(f\"Attention Mask Shape: {attention_mask.shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BC0S2EgY0R6",
        "outputId": "f7eb1b13-4c8a-4816-cef4-30fe0f9d4b87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[BOS]', 's-3', 't-36', 'i-73', 'o-0', 'p-79', 'd-8', '[EOS]', '[EOS]', '[EOS]', '[EOS]', '[EOS]', '[EOS]', '[EOS]', '[EOS]', '[EOS]', '[EOS]', '[EOS]', '[EOS]', '[EOS]']\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.convert_ids_to_tokens(input_ids.squeeze())[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV6GJfoA3yVH",
        "outputId": "7fb66729-a140-44ca-fa12-1e8e085d8871"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generated Output: s-3 t-36 i-73 o-0 p-79 d-8 p-45 d-12 o-8 p-81 d-1 o-9 p-79 d-1 o-10 p-81 d-2 o-12 p-79 d-2 o-14 p-81 d-4 o-18 p-79 d-6 p-45 d-6 o-24 p-77 d-6 p-47 d-12 o-30 p-76 d-6 o-36 p-77 d-2 o-38 p-79 d-4 o-42 p-77 d-3 p-47 d-6 o-45 p-76 d-3 b-1 s-3 t-35 i-73\n"
          ]
        }
      ],
      "source": [
        "# Generate a sequence using the model\n",
        "output_sequences = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    attention_mask=attention_mask,\n",
        "\n",
        "    max_new_tokens=50,  # Max length of the generated sequence\n",
        "    num_return_sequences=1, # Number of sequences to generate\n",
        "    no_repeat_ngram_size=2, # Avoid repeating n-grams\n",
        "    do_sample=True, # Use sampling instead of greedy decoding\n",
        "    top_k=50, # Consider only the top_k most likely tokens\n",
        "    top_p=0.95, # Nucleus sampling\n",
        "    temperature=0.7, # Control randomness\n",
        "    pad_token_id=tokenizer.eos_token_id # Use EOS token for padding\n",
        ")\n",
        "\n",
        "# Decode the generated sequence\n",
        "generated_text = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
        "\n",
        "print(f\"\\nGenerated Output: {generated_text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "841306ae",
        "outputId": "c29127bc-9ca2-46f0-c94c-32585f07b32b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Sorted Vocabulary (First 20 entries by ID) ---\n",
            "ID: 0, Token: [UNK]\n",
            "ID: 1, Token: [EOS]\n",
            "ID: 2, Token: [BOS]\n",
            "ID: 3, Token: [CLS]\n",
            "ID: 4, Token: [SEP]\n",
            "ID: 5, Token: [PAD]\n",
            "ID: 6, Token: [MASK]\n",
            "ID: 7, Token: [HIST]\n",
            "ID: 8, Token: [PITCH]\n",
            "ID: 9, Token: [INST]\n",
            "ID: 10, Token: [MELODY]\n",
            "ID: 11, Token: [CHORD]\n",
            "ID: 12, Token: b-1\n",
            "ID: 13, Token: o-0\n",
            "ID: 14, Token: o-1\n",
            "ID: 15, Token: o-2\n",
            "ID: 16, Token: o-3\n",
            "ID: 17, Token: o-4\n",
            "ID: 18, Token: o-5\n",
            "ID: 19, Token: o-6\n"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "\n",
        "# Get the tokenizer's vocabulary\n",
        "vocabulary = tokenizer.vocab\n",
        "\n",
        "# Sort the vocabulary by value (ID) and create an OrderedDict\n",
        "sorted_vocab_items = collections.OrderedDict(sorted(vocabulary.items(), key=lambda item: item[1]))\n",
        "\n",
        "print(\"--- Sorted Vocabulary (First 20 entries by ID) ---\")\n",
        "# Iterate and print the first 20 items from the OrderedDict\n",
        "for i, (token, token_id) in enumerate(sorted_vocab_items.items()):\n",
        "    if i >= 20:\n",
        "        break\n",
        "    print(f\"ID: {token_id}, Token: {token}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72628bce",
        "outputId": "595e9631-7959-45bc-a488-7e3101ae7b5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizer vocabulary successfully saved to vocab.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "output_file = \"vocab.json\"\n",
        "\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(sorted_vocab_items, f, indent=4)\n",
        "\n",
        "print(f\"Tokenizer vocabulary successfully saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57866225",
        "outputId": "43b77e81-9897-419f-9e66-59d0c19cf306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lmd_full  lmd_full.tar.gz  lmd_full.tar.gz.1  REMI-z  sample_data  vocab.json\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJx17umbcrLS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07773b0f"
      },
      "source": [
        "# Finetuning\n",
        "Fine-tune the pre-trained `GPT2LMHeadModel` from `LongshenOu/m2m_pt` for a classification task by extracting the base model as a feature extractor, defining a custom PyTorch classifier head, integrating the classifier with the feature extractor, and setting up a training loop with an optimizer and loss function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f43f30e0"
      },
      "source": [
        "## Load Base Model for Feature Extraction\n",
        "\n",
        "Extract the base GPT2Model from the loaded GPT2LMHeadModel. This will remove the language modeling head, allowing us to use the model's hidden states as features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87cacf0d",
        "outputId": "46f33d83-b390-4785-ed5e-7601087a4aca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature extractor model type: <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>\n",
            "GPT2Model(\n",
            "  (wte): Embedding(989, 768)\n",
            "  (wpe): Embedding(2048, 768)\n",
            "  (drop): Dropout(p=0.1, inplace=False)\n",
            "  (h): ModuleList(\n",
            "    (0-11): 12 x GPT2Block(\n",
            "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): GPT2Attention(\n",
            "        (c_attn): Conv1D(nf=2304, nx=768)\n",
            "        (c_proj): Conv1D(nf=768, nx=768)\n",
            "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (mlp): GPT2MLP(\n",
            "        (c_fc): Conv1D(nf=3072, nx=768)\n",
            "        (c_proj): Conv1D(nf=768, nx=3072)\n",
            "        (act): NewGELUActivation()\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "feature_extractor = model.transformer\n",
        "print(f\"Feature extractor model type: {type(feature_extractor)}\")\n",
        "print(feature_extractor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkxkaPC3gDRv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYtY2LcKg0ww"
      },
      "source": [
        "### Freeze the parameters of `feature_extractor`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUIp3zDwgDJN"
      },
      "outputs": [],
      "source": [
        "for param in feature_extractor.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acdb8cff",
        "outputId": "ac116859-d9a7-4e5f-96e2-b380dd322589"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Checking feature_extractor parameters' requires_grad status ---\n",
            "wte.weight: requires_grad = False\n",
            "wpe.weight: requires_grad = False\n",
            "h.0.ln_1.weight: requires_grad = False\n",
            "h.0.ln_1.bias: requires_grad = False\n",
            "h.0.attn.c_attn.weight: requires_grad = False\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Checking feature_extractor parameters' requires_grad status ---\")\n",
        "for name, param in feature_extractor.named_parameters():\n",
        "    if 'weight' in name or 'bias' in name:\n",
        "        print(f\"{name}: requires_grad = {param.requires_grad}\")\n",
        "        # Print only a few to avoid too much output\n",
        "        if 'h.0.attn.c_attn.weight' in name:\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "decd4680"
      },
      "source": [
        "## Define Custom Classifier Head\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d636d2c0",
        "outputId": "b559a1ba-aba0-45e3-c302-665ad86984f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instantiated Classification Head:\n",
            "ChunkAggregationHead(\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (chunk_attention): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=768, out_features=1, bias=True)\n",
            "    (3): Softmax(dim=1)\n",
            "  )\n",
            "  (classifier): Linear(in_features=768, out_features=42, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class ChunkAggregationHead(nn.Module):\n",
        "    \"\"\"\n",
        "    Handles aggregation of multiple chunk embeddings into a single document embedding\n",
        "    and performs the final multi-label classification.\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_size, num_labels, dropout_prob=0.1):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "        # Hierarchical Attention Mechanism (to weight the chunks)\n",
        "        self.chunk_attention = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_size, 1),\n",
        "            nn.Softmax(dim=1)  # Softmax over the 'num_chunks' dimension\n",
        "        )\n",
        "\n",
        "        # Final Multi-Label Classification Layer\n",
        "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, chunk_embeddings):\n",
        "        # chunk_embeddings shape: (batch_size, num_chunks, hidden_size)\n",
        "\n",
        "        # 1. Apply Attention Mechanism\n",
        "        # Weights shape: (batch_size, num_chunks, 1)\n",
        "        attention_weights = self.chunk_attention(chunk_embeddings)\n",
        "\n",
        "        # 2. Weighted Sum (Aggregation)\n",
        "        # weighted_embeddings shape: (batch_size, num_chunks, hidden_size)\n",
        "        weighted_embeddings = chunk_embeddings * attention_weights\n",
        "\n",
        "        # document_embedding shape: (batch_size, hidden_size)\n",
        "        document_embedding = torch.sum(weighted_embeddings, dim=1)\n",
        "\n",
        "        # 3. Final Classification\n",
        "        pooled_output = self.dropout(document_embedding)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "# Instantiate the classification head\n",
        "classifier_head = ChunkAggregationHead(EMBEDDING_DIM, NUM_CLASSES)\n",
        "\n",
        "print(f\"Instantiated Classification Head:\\n{classifier_head}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cO6KPoONR-1n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2db4b683"
      },
      "source": [
        "### Integrate Classifier with Feature Extractor\n",
        "\n",
        "Combine the feature extractor (base model) and the custom classifier head into a single model for fine-tuning. This setup will allow gradients to flow back to the classifier head, training it on the extracted features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e93410ed",
        "outputId": "cafdf6bc-5fe6-461f-dac6-f40073dd1d8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instantiated Combined Model:\n",
            "GPT2ForHierarchicalClassification(\n",
            "  (feature_extractor): GPT2Model(\n",
            "    (wte): Embedding(989, 768)\n",
            "    (wpe): Embedding(2048, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=768)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (aggregation_head): ChunkAggregationHead(\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (chunk_attention): Sequential(\n",
            "      (0): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (1): Tanh()\n",
            "      (2): Linear(in_features=768, out_features=1, bias=True)\n",
            "      (3): Softmax(dim=1)\n",
            "    )\n",
            "    (classifier): Linear(in_features=768, out_features=42, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class GPT2ForHierarchicalClassification(nn.Module):\n",
        "    def __init__(self, feature_extractor, aggregation_head):\n",
        "        super().__init__()\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.aggregation_head = aggregation_head\n",
        "\n",
        "        # ----------------------------------------------------\n",
        "        # 🔥 Freeze the feature extractor parameters here 🔥\n",
        "        # ----------------------------------------------------\n",
        "        for param in self.feature_extractor.parameters():\n",
        "             param.requires_grad = False\n",
        "\n",
        "        # Ensure the tokenizer's padding side is set to 'left' for GPT-2 if it's used\n",
        "        # self.feature_extractor.config.tokenizer_padding_side = \"left\"\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        # 1. Reshape Input: Flatten chunks and batch\n",
        "        # input_ids shape: (batch_size, num_chunks, sequence_length)\n",
        "        batch_size, num_chunks, sequence_length = input_ids.shape\n",
        "\n",
        "        flat_input_ids = input_ids.view(-1, sequence_length)             # (B * N, L)\n",
        "        flat_attention_mask = attention_mask.view(-1, sequence_length)   # (B * N, L)\n",
        "\n",
        "        # 2. Pass flat inputs through the feature extractor (Frozen GPT-2)\n",
        "        # Gradient calculation is skipped for the feature extractor\n",
        "        with torch.no_grad():\n",
        "            outputs = self.feature_extractor(\n",
        "                input_ids=flat_input_ids,\n",
        "                attention_mask=flat_attention_mask\n",
        "            )\n",
        "\n",
        "        # 3. Extract Chunk Embeddings\n",
        "        # use the embedding of the last token (index -1) as the chunk representation\n",
        "        # flat_hidden_state shape: (B * N, hidden_size)\n",
        "        flat_hidden_state = outputs.last_hidden_state[:, -1, :]\n",
        "\n",
        "        # 4. Reshape Output: Restore batch and chunk dimensions\n",
        "        # chunk_embeddings shape: (batch_size, num_chunks, hidden_size)\n",
        "        chunk_embeddings = flat_hidden_state.view(batch_size, num_chunks, -1)\n",
        "\n",
        "        # 5. Pass chunk embeddings to the Aggregation Head\n",
        "        logits = self.aggregation_head(chunk_embeddings)\n",
        "\n",
        "        return logits\n",
        "\n",
        "# Instantiate the combined model\n",
        "model = GPT2ForHierarchicalClassification(feature_extractor, classifier_head)\n",
        "\n",
        "# # Freeze the feature extractor parameters\n",
        "# for param in model.feature_extractor.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "print(f\"Instantiated Combined Model:\\n{model}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmFrtoGTkPve",
        "outputId": "071fd00a-c892-4dfa-aed0-4765c60a662a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Checking combined_model parameters' requires_grad status ---\n",
            "feature_extractor.wte.weight: requires_grad = False\n",
            "feature_extractor.wpe.weight: requires_grad = False\n",
            "feature_extractor.h.0.ln_1.weight: requires_grad = False\n",
            "feature_extractor.h.0.ln_1.bias: requires_grad = False\n",
            "feature_extractor.h.0.attn.c_attn.weight: requires_grad = False\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Checking combined_model parameters' requires_grad status ---\")\n",
        "for name, param in model.named_parameters():\n",
        "    if 'feature_extractor' in name and 'weight' in name or 'bias' in name:\n",
        "        print(f\"{name}: requires_grad = {param.requires_grad}\")\n",
        "        # Print only a few to avoid too much output\n",
        "        if 'h.0.attn.c_attn.weight' in name: # Example of a specific parameter\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssJfHGveSByb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8de5b33e"
      },
      "source": [
        "## Prepare Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avvIF8TcchRD",
        "outputId": "b33aefa0-5e0d-4fbc-c991-1204058f9ef2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42\n"
          ]
        }
      ],
      "source": [
        "print(NUM_CLASSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoWXDQFEikSr"
      },
      "outputs": [],
      "source": [
        "BARS_PER_SEGMENT = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OLTrAuwAhcRT",
        "outputId": "7dff2eae-d5ff-4c0c-9a38-d69a37424e00"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2842,\n  \"fields\": [\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2842,\n        \"samples\": [\n          \"lmd_full/0/05fbec1fc6c901ddb61d713b4e9af591.mid\",\n          \"lmd_full/7/725a15c9f572f3fe21abd5b7effd1f2a.mid\",\n          \"lmd_full/3/36b93c462d21e3045bf4af6f2753e25b.mid\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genre\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-747de4e2-d952-4718-8734-674e6aacef28\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>location</th>\n",
              "      <th>genre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lmd_full/2/2a604c93ed4ee9d82d388da694e89e7c.mid</td>\n",
              "      <td>[reggae, pop]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lmd_full/0/0fd51dae1d5ffc871de6b8bd8ff3e5ce.mid</td>\n",
              "      <td>[pop, popfolk]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lmd_full/0/00bb4be2822c3828935498af7b90b98e.mid</td>\n",
              "      <td>[pop, jazz]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lmd_full/e/e7394f75f6978369eb463abcb75a88da.mid</td>\n",
              "      <td>[electronic, pop]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lmd_full/f/f5ac97af893d6b5cec0324bc49ae10bb.mid</td>\n",
              "      <td>[electronic, experimental]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-747de4e2-d952-4718-8734-674e6aacef28')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-747de4e2-d952-4718-8734-674e6aacef28 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-747de4e2-d952-4718-8734-674e6aacef28');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-844d922c-abf4-479e-8d24-13b918cc4b3c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-844d922c-abf4-479e-8d24-13b918cc4b3c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-844d922c-abf4-479e-8d24-13b918cc4b3c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                          location                       genre\n",
              "0  lmd_full/2/2a604c93ed4ee9d82d388da694e89e7c.mid               [reggae, pop]\n",
              "1  lmd_full/0/0fd51dae1d5ffc871de6b8bd8ff3e5ce.mid              [pop, popfolk]\n",
              "2  lmd_full/0/00bb4be2822c3828935498af7b90b98e.mid                 [pop, jazz]\n",
              "3  lmd_full/e/e7394f75f6978369eb463abcb75a88da.mid           [electronic, pop]\n",
              "4  lmd_full/f/f5ac97af893d6b5cec0324bc49ae10bb.mid  [electronic, experimental]"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVWes0R-hmWI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8FMFzIjhsVX"
      },
      "outputs": [],
      "source": [
        "def process_midi_to_segments(midi_fp, bars_per_segment, tokenizer, max_token_length):\n",
        "    \"\"\"\n",
        "    Loads a MIDI file, filters empty bars, segments into n-bar chunks,\n",
        "    converts each chunk to a ReMiZ string, and tokenizes it.\n",
        "    \"\"\"\n",
        "    # print(midi_fp)\n",
        "    try:\n",
        "        # 1. Load the MIDI\n",
        "        mt = MultiTrack.from_midi(midi_fp)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading MIDI {midi_fp}: {e}\")\n",
        "        return []\n",
        "\n",
        "    # 2. Filter Empty Bars\n",
        "    non_empty_bars = []\n",
        "    for bar_index in range(len(mt)):\n",
        "        bar = mt[bar_index]\n",
        "        if len(bar) > 0: # Check if the bar contains any instruments/notes\n",
        "            non_empty_bars.append(bar)\n",
        "    filtered_mt = MultiTrack(non_empty_bars)\n",
        "\n",
        "    # 3. Segment into N-Bar Chunks\n",
        "    segmented_tracks = []\n",
        "    num_bars = len(filtered_mt)\n",
        "    for i in range(0, num_bars, bars_per_segment):\n",
        "        # Extract the bar objects for the segment\n",
        "        segment_multi_track = filtered_mt[i : i + bars_per_segment]\n",
        "        segment_bars = segment_multi_track.bars\n",
        "\n",
        "        # Create a new MultiTrack object for this segment\n",
        "        segmented_track = MultiTrack(segment_bars)\n",
        "\n",
        "        # 4. Convert segment to ReMiZ string\n",
        "        remiz_str = segmented_track.to_remiz_str(\n",
        "            with_ts=True, with_tempo=True, with_velocity=False\n",
        "        )\n",
        "\n",
        "        # 5. Tokenize the ReMiZ string\n",
        "        tokens = tokenizer.encode(remiz_str, add_special_tokens=True, max_length=max_token_length, truncation=True)\n",
        "        segmented_tracks.append(tokens)\n",
        "\n",
        "    return segmented_tracks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8C9l6UWhsNI",
        "outputId": "b1622fb5-d245-4850-ba89-b2c79ecb5750"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2, 695, 973, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 141, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 176, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 535, 34, 302, 528, 37, 307, 532, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 141, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 532, 34, 307, 528, 37, 312, 532, 49, 312, 535, 12, 695, 973, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 141, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 176, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 533, 34, 302, 528, 37, 307, 533, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 141, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 535, 34, 312, 527, 37, 312, 529, 40, 312, 527, 43, 312, 532, 49, 311, 531, 55, 309, 530, 12, 695, 973, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 141, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 176, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 535, 34, 302, 528, 37, 307, 532, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 141, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 532, 34, 307, 528, 37, 312, 532, 49, 312, 535, 12, 695, 973, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 141, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 176, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 533, 28, 302, 528, 31, 304, 528, 34, 302, 528, 302, 527, 37, 307, 533, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 141, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 535, 34, 307, 529, 37, 312, 535, 49, 312, 531, 52, 313, 529, 55, 314, 531, 12, 1], [2, 695, 973, 214, 13, 347, 531, 19, 347, 527, 22, 347, 527, 25, 347, 528, 28, 345, 527, 31, 345, 530, 37, 345, 531, 43, 343, 535, 141, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 176, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 243, 13, 331, 527, 326, 528, 323, 527, 180, 13, 307, 533, 12, 695, 973, 214, 25, 345, 532, 31, 343, 527, 34, 343, 533, 40, 340, 537, 55, 340, 527, 58, 340, 529, 141, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 243, 13, 336, 527, 331, 527, 328, 527, 180, 13, 312, 535, 12, 695, 973, 214, 13, 347, 531, 19, 347, 529, 25, 347, 531, 31, 345, 527, 34, 345, 534, 43, 343, 528, 49, 343, 535, 141, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 176, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 243, 13, 331, 527, 326, 527, 323, 527, 180, 13, 307, 534, 34, 302, 528, 37, 307, 533, 12, 695, 973, 214, 25, 345, 532, 31, 343, 528, 34, 343, 535, 43, 340, 537, 141, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 243, 13, 336, 528, 331, 527, 328, 527, 180, 13, 312, 534, 34, 307, 528, 37, 312, 532, 49, 307, 533, 12, 695, 973, 214, 25, 345, 531, 31, 345, 528, 34, 345, 532, 43, 345, 531, 49, 347, 532, 55, 348, 534, 160, 13, 338, 573, 333, 572, 330, 573, 141, 19, 338, 528, 333, 528, 330, 527, 31, 338, 528, 333, 528, 330, 527, 43, 338, 528, 333, 528, 330, 527, 55, 338, 528, 333, 528, 330, 527, 176, 19, 338, 528, 333, 528, 330, 527, 31, 338, 528, 333, 528, 330, 527, 43, 338, 528, 333, 528, 330, 527, 55, 338, 528, 333, 528, 330, 527, 243, 13, 333, 528, 330, 527, 326, 528, 180, 13, 314, 533, 34, 309, 528, 37, 314, 532, 12, 695, 973, 214, 13, 347, 536, 25, 342, 539, 49, 347, 532, 55, 345, 529, 58, 343, 533, 160, 13, 338, 572, 335, 572, 330, 571, 141, 19, 338, 528, 335, 528, 330, 527, 31, 338, 528, 335, 528, 330, 528, 43, 338, 528, 335, 527, 330, 527, 55, 338, 527, 335, 527, 330, 527, 176, 19, 338, 528, 335, 528, 330, 527, 31, 338, 528, 335, 528, 330, 528, 43, 338, 528, 335, 527, 330, 527, 55, 338, 527, 335, 527, 330, 527, 243, 13, 335, 529, 330, 529, 326, 529, 180, 13, 311, 532, 34, 307, 529, 37, 311, 534, 49, 302, 532, 12, 695, 973, 214, 19, 340, 535, 43, 340, 532, 49, 348, 532, 55, 347, 531, 160, 13, 340, 573, 336, 573, 331, 573, 141, 19, 340, 528, 336, 528, 331, 527, 31, 340, 528, 336, 528, 331, 527, 43, 340, 528, 336, 527, 331, 527, 55, 340, 527, 336, 527, 331, 527, 176, 19, 340, 528, 336, 528, 331, 527, 31, 340, 528, 336, 528, 331, 527, 43, 340, 528, 336, 527, 331, 527, 55, 340, 527, 336, 527, 331, 527, 243, 13, 336, 528, 331, 528, 328, 528, 180, 13, 312, 532, 34, 307, 528, 37, 312, 533, 12, 695, 973, 214, 13, 345, 542, 160, 13, 338, 570, 333, 570, 330, 570, 141, 19, 338, 528, 333, 527, 330, 527, 31, 338, 527, 333, 527, 330, 527, 43, 338, 527, 333, 527, 330, 527, 55, 338, 527, 333, 527, 330, 527, 176, 19, 338, 528, 333, 527, 330, 527, 31, 338, 527, 333, 527, 330, 527, 43, 338, 527, 333, 527, 330, 527, 55, 338, 527, 333, 527, 330, 527, 243, 13, 333, 528, 330, 527, 326, 528, 180, 13, 314, 533, 34, 309, 528, 37, 314, 535, 49, 302, 533, 12, 1], [2, 695, 973, 199, 13, 350, 562, 49, 347, 533, 55, 350, 533, 214, 13, 347, 531, 19, 347, 527, 22, 347, 527, 25, 347, 528, 28, 345, 527, 31, 345, 530, 37, 345, 531, 43, 343, 535, 141, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 176, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 535, 34, 302, 528, 37, 307, 532, 12, 695, 973, 199, 13, 352, 538, 25, 355, 550, 49, 359, 530, 52, 357, 530, 55, 355, 530, 58, 352, 529, 214, 25, 345, 532, 31, 343, 527, 34, 343, 533, 40, 340, 537, 55, 340, 527, 58, 340, 529, 141, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 532, 34, 307, 528, 37, 312, 532, 49, 312, 535, 12, 695, 973, 199, 13, 350, 562, 49, 347, 533, 55, 350, 533, 214, 13, 347, 531, 19, 347, 529, 25, 347, 531, 31, 345, 527, 34, 345, 534, 43, 343, 528, 49, 343, 535, 141, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 176, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 534, 34, 302, 528, 37, 307, 533, 12, 695, 973, 199, 13, 352, 538, 25, 355, 550, 49, 359, 530, 52, 357, 530, 55, 355, 530, 58, 352, 529, 214, 25, 345, 532, 31, 343, 528, 34, 343, 535, 43, 340, 537, 141, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 534, 34, 307, 528, 37, 312, 532, 49, 307, 533, 12, 695, 973, 199, 13, 354, 562, 49, 352, 532, 55, 354, 532, 214, 25, 345, 531, 31, 345, 528, 34, 345, 532, 43, 345, 531, 49, 347, 532, 55, 348, 534, 141, 19, 338, 528, 333, 528, 330, 527, 31, 338, 528, 333, 528, 330, 527, 43, 338, 528, 333, 528, 330, 527, 55, 338, 528, 333, 528, 330, 527, 176, 19, 338, 528, 333, 528, 330, 527, 31, 338, 528, 333, 528, 330, 527, 43, 338, 528, 333, 528, 330, 527, 55, 338, 528, 333, 528, 330, 527, 180, 13, 314, 533, 34, 309, 528, 37, 314, 532, 12, 695, 973, 199, 13, 350, 538, 25, 347, 560, 214, 13, 347, 536, 25, 342, 539, 49, 347, 532, 55, 345, 529, 58, 343, 533, 141, 19, 338, 528, 335, 528, 330, 527, 31, 338, 528, 335, 528, 330, 528, 43, 338, 528, 335, 527, 330, 527, 55, 338, 527, 335, 527, 330, 527, 176, 19, 338, 528, 335, 528, 330, 527, 31, 338, 528, 335, 528, 330, 528, 43, 338, 528, 335, 527, 330, 527, 55, 338, 527, 335, 527, 330, 527, 180, 13, 311, 532, 34, 307, 529, 37, 311, 534, 49, 302, 532, 12, 695, 973, 199, 13, 345, 539, 25, 347, 539, 37, 348, 538, 49, 352, 537, 214, 19, 340, 535, 43, 340, 532, 49, 348, 532, 55, 347, 531, 141, 19, 340, 528, 336, 528, 331, 527, 31, 340, 528, 336, 528, 331, 527, 43, 340, 528, 336, 527, 331, 527, 55, 340, 527, 336, 527, 331, 527, 176, 19, 340, 528, 336, 528, 331, 527, 31, 340, 528, 336, 528, 331, 527, 43, 340, 528, 336, 527, 331, 527, 55, 340, 527, 336, 527, 331, 527, 180, 13, 312, 532, 34, 307, 528, 37, 312, 533, 12, 695, 973, 199, 13, 350, 538, 25, 352, 539, 37, 354, 537, 49, 357, 537, 214, 13, 345, 542, 141, 19, 338, 528, 333, 527, 330, 527, 31, 338, 527, 333, 527, 330, 527, 43, 338, 527, 333, 527, 330, 527, 55, 338, 527, 333, 527, 330, 527, 176, 19, 338, 528, 333, 527, 330, 527, 31, 338, 527, 333, 527, 330, 527, 43, 338, 527, 333, 527, 330, 527, 55, 338, 527, 333, 527, 330, 527, 180, 13, 314, 533, 34, 309, 528, 37, 314, 535, 49, 302, 533, 12, 1], [2, 695, 973, 213, 31, 350, 528, 37, 350, 528, 43, 350, 528, 49, 352, 528, 55, 352, 527, 58, 352, 534, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 214, 31, 343, 528, 37, 343, 528, 43, 343, 528, 49, 345, 528, 55, 345, 527, 58, 345, 534, 216, 13, 347, 531, 335, 532, 19, 343, 533, 331, 533, 141, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 160, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 528, 331, 528, 43, 338, 528, 335, 528, 331, 528, 55, 338, 529, 335, 529, 331, 528, 176, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 535, 34, 302, 528, 37, 307, 532, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 213, 19, 350, 538, 214, 19, 343, 538, 141, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 160, 19, 340, 529, 336, 529, 331, 528, 31, 340, 528, 336, 528, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 532, 34, 307, 528, 37, 312, 532, 49, 312, 535, 12, 695, 973, 213, 49, 352, 528, 55, 352, 527, 58, 352, 527, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 214, 49, 345, 528, 55, 345, 527, 58, 345, 527, 216, 13, 347, 531, 335, 532, 19, 343, 533, 331, 533, 141, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 160, 19, 338, 528, 335, 528, 331, 528, 31, 338, 528, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 52, 338, 529, 335, 528, 331, 528, 176, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 533, 34, 302, 528, 37, 307, 533, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 213, 13, 352, 532, 19, 350, 537, 214, 13, 345, 532, 19, 343, 537, 141, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 160, 19, 340, 528, 336, 528, 331, 528, 31, 340, 529, 336, 528, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 535, 34, 312, 527, 37, 312, 529, 40, 312, 527, 43, 312, 532, 49, 311, 531, 55, 309, 530, 12, 695, 973, 213, 31, 350, 528, 37, 350, 528, 43, 350, 528, 49, 352, 529, 55, 352, 528, 58, 352, 534, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 214, 31, 343, 528, 37, 343, 528, 43, 343, 528, 49, 345, 529, 55, 345, 528, 58, 345, 534, 216, 13, 347, 531, 335, 532, 19, 343, 536, 331, 536, 141, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 160, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 528, 331, 528, 43, 338, 528, 335, 528, 331, 528, 55, 338, 529, 335, 529, 331, 528, 176, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 535, 34, 302, 528, 37, 307, 532, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 213, 19, 350, 539, 214, 19, 343, 539, 141, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 160, 19, 340, 529, 336, 529, 331, 528, 31, 340, 528, 336, 528, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 532, 34, 307, 528, 37, 312, 532, 49, 312, 535, 12, 695, 973, 213, 31, 350, 527, 34, 350, 528, 37, 350, 528, 40, 350, 527, 43, 350, 528, 46, 350, 527, 49, 352, 528, 55, 352, 528, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 214, 31, 343, 527, 34, 343, 528, 37, 343, 528, 40, 343, 527, 43, 343, 528, 46, 343, 527, 49, 345, 528, 55, 345, 528, 216, 13, 347, 531, 335, 532, 19, 343, 536, 331, 536, 141, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 160, 19, 338, 528, 335, 528, 331, 528, 31, 338, 528, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 52, 338, 529, 335, 528, 331, 528, 176, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 533, 28, 302, 528, 31, 304, 528, 34, 302, 528, 302, 527, 37, 307, 533, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 213, 13, 352, 532, 19, 350, 538, 214, 13, 345, 532, 19, 343, 538, 141, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 160, 19, 340, 528, 336, 528, 331, 528, 31, 340, 529, 336, 528, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 535, 34, 307, 529, 37, 312, 531, 43, 316, 533, 49, 314, 532, 55, 311, 531, 12, 1], [2, 695, 973, 199, 13, 355, 574, 214, 13, 347, 531, 19, 347, 527, 22, 347, 527, 25, 347, 528, 28, 345, 527, 31, 345, 530, 37, 345, 531, 43, 343, 535, 141, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 176, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 535, 12, 695, 973, 199, 13, 348, 574, 214, 25, 345, 532, 31, 343, 527, 34, 343, 533, 40, 340, 537, 55, 340, 527, 58, 340, 529, 141, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 58, 302, 529, 12, 695, 973, 214, 13, 347, 531, 19, 347, 529, 25, 347, 531, 31, 345, 527, 34, 345, 534, 43, 343, 528, 49, 343, 535, 199, 13, 343, 574, 141, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 176, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 534, 12, 695, 973, 199, 13, 367, 574, 214, 25, 345, 532, 31, 343, 528, 34, 343, 535, 43, 340, 537, 141, 55, 340, 528, 336, 528, 331, 528, 176, 55, 340, 528, 336, 528, 331, 528, 12, 695, 973, 214, 25, 345, 531, 31, 345, 528, 34, 345, 532, 43, 345, 531, 49, 347, 532, 55, 348, 534, 160, 13, 338, 573, 333, 572, 330, 573, 141, 19, 338, 528, 333, 528, 330, 527, 31, 338, 528, 333, 528, 330, 527, 43, 338, 528, 333, 528, 330, 527, 55, 338, 528, 333, 528, 330, 527, 176, 19, 338, 528, 333, 528, 330, 527, 31, 338, 528, 333, 528, 330, 527, 43, 338, 528, 333, 528, 330, 527, 55, 338, 528, 333, 528, 330, 527, 180, 13, 314, 533, 34, 309, 528, 37, 314, 532, 12, 695, 973, 214, 13, 347, 536, 25, 342, 539, 49, 347, 532, 55, 345, 529, 58, 343, 533, 160, 13, 338, 572, 335, 572, 330, 571, 141, 19, 338, 528, 335, 528, 330, 527, 31, 338, 528, 335, 528, 330, 528, 43, 338, 528, 335, 527, 330, 527, 55, 338, 527, 335, 527, 330, 527, 176, 19, 338, 528, 335, 528, 330, 527, 31, 338, 528, 335, 528, 330, 528, 43, 338, 528, 335, 527, 330, 527, 55, 338, 527, 335, 527, 330, 527, 180, 13, 311, 532, 34, 307, 529, 37, 311, 534, 49, 302, 532, 12, 695, 973, 214, 19, 340, 535, 43, 340, 532, 49, 348, 532, 55, 347, 531, 160, 13, 340, 573, 336, 573, 331, 573, 141, 19, 340, 528, 336, 528, 331, 527, 31, 340, 528, 336, 528, 331, 527, 43, 340, 528, 336, 527, 331, 527, 55, 340, 527, 336, 527, 331, 527, 176, 19, 340, 528, 336, 528, 331, 527, 31, 340, 528, 336, 528, 331, 527, 43, 340, 528, 336, 527, 331, 527, 55, 340, 527, 336, 527, 331, 527, 180, 13, 312, 532, 34, 307, 528, 37, 312, 533, 12, 695, 973, 214, 13, 345, 542, 160, 13, 338, 570, 333, 570, 330, 570, 141, 19, 338, 528, 333, 527, 330, 527, 31, 338, 527, 333, 527, 330, 527, 43, 338, 527, 333, 527, 330, 527, 55, 338, 527, 333, 527, 330, 527, 176, 19, 338, 528, 333, 527, 330, 527, 31, 338, 527, 333, 527, 330, 527, 43, 338, 527, 333, 527, 330, 527, 55, 338, 527, 333, 527, 330, 527, 180, 13, 314, 533, 34, 309, 528, 37, 314, 535, 49, 302, 533, 12, 1], [2, 695, 973, 213, 31, 350, 528, 37, 350, 528, 43, 350, 528, 49, 352, 528, 55, 352, 527, 58, 352, 534, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 214, 31, 343, 528, 37, 343, 528, 43, 343, 528, 49, 345, 528, 55, 345, 527, 58, 345, 534, 216, 13, 347, 531, 335, 532, 19, 343, 533, 331, 533, 141, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 160, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 528, 331, 528, 43, 338, 528, 335, 528, 331, 528, 55, 338, 529, 335, 529, 331, 528, 176, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 535, 34, 302, 528, 37, 307, 532, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 213, 19, 350, 538, 214, 19, 343, 538, 141, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 160, 19, 340, 529, 336, 529, 331, 528, 31, 340, 528, 336, 528, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 532, 34, 307, 528, 37, 312, 532, 49, 312, 535, 12, 695, 973, 213, 49, 352, 528, 55, 352, 527, 58, 352, 527, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 214, 49, 345, 528, 55, 345, 527, 58, 345, 527, 216, 13, 347, 531, 335, 532, 19, 343, 533, 331, 533, 141, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 160, 19, 338, 528, 335, 528, 331, 528, 31, 338, 528, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 52, 338, 529, 335, 528, 331, 528, 176, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 533, 34, 302, 528, 37, 307, 533, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 213, 13, 352, 532, 19, 350, 537, 214, 13, 345, 532, 19, 343, 537, 141, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 160, 19, 340, 528, 336, 528, 331, 528, 31, 340, 529, 336, 528, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 535, 34, 312, 527, 37, 312, 529, 40, 312, 527, 43, 312, 532, 49, 311, 531, 55, 309, 530, 12, 695, 973, 213, 31, 350, 528, 37, 350, 528, 43, 350, 528, 49, 352, 529, 55, 352, 528, 58, 352, 534, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 214, 31, 343, 528, 37, 343, 528, 43, 343, 528, 49, 345, 529, 55, 345, 528, 58, 345, 534, 216, 13, 347, 531, 335, 532, 19, 343, 536, 331, 536, 141, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 160, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 528, 331, 528, 43, 338, 528, 335, 528, 331, 528, 55, 338, 529, 335, 529, 331, 528, 176, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 535, 34, 302, 528, 37, 307, 532, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 213, 19, 350, 539, 214, 19, 343, 539, 141, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 160, 19, 340, 529, 336, 529, 331, 528, 31, 340, 528, 336, 528, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 532, 34, 307, 528, 37, 312, 532, 49, 312, 535, 12, 695, 973, 213, 31, 350, 527, 34, 350, 528, 37, 350, 528, 40, 350, 527, 43, 350, 528, 46, 350, 527, 49, 352, 528, 55, 352, 528, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 214, 31, 343, 527, 34, 343, 528, 37, 343, 528, 40, 343, 527, 43, 343, 528, 46, 343, 527, 49, 345, 528, 55, 345, 528, 216, 13, 347, 531, 335, 532, 19, 343, 536, 331, 536, 141, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 160, 19, 338, 528, 335, 528, 331, 528, 31, 338, 528, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 52, 338, 529, 335, 528, 331, 528, 176, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 533, 28, 302, 528, 31, 304, 528, 34, 302, 528, 302, 527, 37, 307, 533, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 213, 13, 352, 532, 19, 350, 538, 214, 13, 345, 532, 19, 343, 538, 141, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 160, 19, 340, 528, 336, 528, 331, 528, 31, 340, 529, 336, 528, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 535, 34, 307, 529, 37, 312, 531, 43, 316, 533, 49, 314, 532, 55, 311, 531, 12, 1], [2, 695, 973, 213, 31, 350, 528, 37, 350, 528, 43, 350, 528, 49, 352, 528, 55, 352, 527, 58, 352, 534, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 214, 31, 343, 528, 37, 343, 528, 43, 343, 528, 49, 345, 528, 55, 345, 527, 58, 345, 534, 216, 13, 347, 531, 335, 532, 19, 343, 533, 331, 533, 141, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 160, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 528, 331, 528, 43, 338, 528, 335, 528, 331, 528, 55, 338, 529, 335, 529, 331, 528, 176, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 535, 34, 302, 528, 37, 307, 532, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 213, 19, 350, 538, 214, 19, 343, 538, 141, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 160, 19, 340, 529, 336, 529, 331, 528, 31, 340, 528, 336, 528, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 532, 34, 307, 528, 37, 312, 532, 49, 312, 535, 12, 695, 973, 213, 49, 352, 528, 55, 352, 527, 58, 352, 527, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 214, 49, 345, 528, 55, 345, 527, 58, 345, 527, 216, 13, 347, 531, 335, 532, 19, 343, 533, 331, 533, 141, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 160, 19, 338, 528, 335, 528, 331, 528, 31, 338, 528, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 52, 338, 529, 335, 528, 331, 528, 176, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 533, 34, 302, 528, 37, 307, 533, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 213, 13, 352, 532, 19, 350, 537, 214, 13, 345, 532, 19, 343, 537, 141, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 160, 19, 340, 528, 336, 528, 331, 528, 31, 340, 529, 336, 528, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 535, 34, 312, 527, 37, 312, 529, 40, 312, 527, 43, 312, 532, 49, 311, 531, 55, 309, 530, 12, 695, 973, 213, 31, 350, 528, 37, 350, 528, 43, 350, 528, 49, 352, 529, 55, 352, 528, 58, 352, 534, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 214, 31, 343, 528, 37, 343, 528, 43, 343, 528, 49, 345, 529, 55, 345, 528, 58, 345, 534, 216, 13, 347, 531, 335, 532, 19, 343, 536, 331, 536, 141, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 160, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 528, 331, 528, 43, 338, 528, 335, 528, 331, 528, 55, 338, 529, 335, 529, 331, 528, 176, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 535, 34, 302, 528, 37, 307, 532, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 213, 19, 350, 539, 214, 19, 343, 539, 141, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 160, 19, 340, 529, 336, 529, 331, 528, 31, 340, 528, 336, 528, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 532, 34, 307, 528, 37, 312, 532, 49, 312, 535, 12, 695, 973, 213, 31, 350, 527, 34, 350, 528, 37, 350, 528, 40, 350, 527, 43, 350, 528, 46, 350, 527, 49, 352, 528, 55, 352, 528, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 214, 31, 343, 527, 34, 343, 528, 37, 343, 528, 40, 343, 527, 43, 343, 528, 46, 343, 527, 49, 345, 528, 55, 345, 528, 216, 13, 347, 531, 335, 532, 19, 343, 536, 331, 536, 141, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 160, 19, 338, 528, 335, 528, 331, 528, 31, 338, 528, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 52, 338, 529, 335, 528, 331, 528, 176, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 533, 28, 302, 528, 31, 304, 528, 34, 302, 528, 302, 527, 37, 307, 533, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 213, 13, 352, 532, 19, 350, 538, 214, 13, 345, 532, 19, 343, 538, 141, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 160, 19, 340, 528, 336, 528, 331, 528, 31, 340, 529, 336, 528, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 535, 34, 307, 529, 37, 312, 531, 43, 316, 533, 49, 314, 532, 55, 311, 531, 12, 1], [2, 695, 973, 213, 31, 350, 528, 37, 350, 528, 43, 350, 528, 49, 352, 528, 55, 352, 527, 58, 352, 534, 214, 31, 343, 528, 37, 343, 528, 43, 343, 528, 49, 345, 528, 55, 345, 527, 58, 345, 534, 216, 13, 347, 531, 335, 532, 19, 343, 533, 331, 533, 180, 13, 307, 537, 12, 695, 973, 213, 19, 350, 538, 214, 19, 343, 538, 12, 695, 973, 213, 49, 352, 528, 55, 352, 527, 58, 352, 527, 214, 49, 345, 528, 55, 345, 527, 58, 345, 527, 216, 13, 347, 531, 335, 532, 19, 343, 533, 331, 533, 12, 695, 973, 213, 13, 352, 532, 19, 350, 537, 214, 13, 345, 532, 19, 343, 537, 12, 695, 973, 213, 31, 350, 528, 37, 350, 528, 43, 350, 528, 49, 352, 529, 55, 352, 528, 58, 352, 534, 214, 31, 343, 528, 37, 343, 528, 43, 343, 528, 49, 345, 529, 55, 345, 528, 58, 345, 534, 216, 13, 347, 531, 335, 532, 19, 343, 536, 331, 536, 12, 695, 973, 213, 19, 350, 539, 214, 19, 343, 539, 12, 695, 973, 213, 31, 350, 527, 34, 350, 528, 37, 350, 528, 40, 350, 527, 43, 350, 528, 46, 350, 527, 49, 352, 528, 55, 352, 528, 214, 31, 343, 527, 34, 343, 528, 37, 343, 528, 40, 343, 527, 43, 343, 528, 46, 343, 527, 49, 345, 528, 55, 345, 528, 216, 13, 347, 531, 335, 532, 19, 343, 536, 331, 536, 12, 695, 973, 213, 13, 352, 532, 19, 350, 538, 214, 13, 345, 532, 19, 343, 538, 12, 1], [2, 695, 973, 213, 31, 350, 528, 37, 350, 528, 43, 350, 528, 49, 352, 528, 55, 352, 527, 58, 352, 534, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 214, 31, 343, 528, 37, 343, 528, 43, 343, 528, 49, 345, 528, 55, 345, 527, 58, 345, 534, 216, 13, 347, 531, 335, 532, 19, 343, 533, 331, 533, 141, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 160, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 528, 331, 528, 43, 338, 528, 335, 528, 331, 528, 55, 338, 529, 335, 529, 331, 528, 176, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 535, 34, 302, 528, 37, 307, 532, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 213, 19, 350, 538, 214, 19, 343, 538, 141, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 160, 19, 340, 529, 336, 529, 331, 528, 31, 340, 528, 336, 528, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 532, 34, 307, 528, 37, 312, 532, 49, 312, 535, 12, 695, 973, 213, 49, 352, 528, 55, 352, 527, 58, 352, 527, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 214, 49, 345, 528, 55, 345, 527, 58, 345, 527, 216, 13, 347, 531, 335, 532, 19, 343, 533, 331, 533, 141, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 160, 19, 338, 528, 335, 528, 331, 528, 31, 338, 528, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 52, 338, 529, 335, 528, 331, 528, 176, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 533, 34, 302, 528, 37, 307, 533, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 213, 13, 352, 532, 19, 350, 537, 214, 13, 345, 532, 19, 343, 537, 141, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 160, 19, 340, 528, 336, 528, 331, 528, 31, 340, 529, 336, 528, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 535, 34, 312, 527, 37, 312, 529, 40, 312, 527, 43, 312, 532, 49, 311, 531, 55, 309, 530, 12, 695, 973, 213, 31, 350, 528, 37, 350, 528, 43, 350, 528, 49, 352, 529, 55, 352, 528, 58, 352, 534, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 214, 31, 343, 528, 37, 343, 528, 43, 343, 528, 49, 345, 529, 55, 345, 528, 58, 345, 534, 216, 13, 347, 531, 335, 532, 19, 343, 536, 331, 536, 141, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 160, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 528, 331, 528, 43, 338, 528, 335, 528, 331, 528, 55, 338, 529, 335, 529, 331, 528, 176, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 535, 34, 302, 528, 37, 307, 532, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 213, 19, 350, 539, 214, 19, 343, 539, 141, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 160, 19, 340, 529, 336, 529, 331, 528, 31, 340, 528, 336, 528, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 532, 34, 307, 528, 37, 312, 532, 49, 312, 535, 12, 695, 973, 213, 31, 350, 527, 34, 350, 528, 37, 350, 528, 40, 350, 527, 43, 350, 528, 46, 350, 527, 49, 352, 528, 55, 352, 528, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 214, 31, 343, 527, 34, 343, 528, 37, 343, 528, 40, 343, 527, 43, 343, 528, 46, 343, 527, 49, 345, 528, 55, 345, 528, 216, 13, 347, 531, 335, 532, 19, 343, 536, 331, 536, 141, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 160, 19, 338, 528, 335, 528, 331, 528, 31, 338, 528, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 52, 338, 529, 335, 528, 331, 528, 176, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 533, 28, 302, 528, 31, 304, 528, 34, 302, 528, 302, 527, 37, 307, 533, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 213, 13, 352, 532, 19, 350, 538, 214, 13, 345, 532, 19, 343, 538, 141, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 160, 19, 340, 528, 336, 528, 331, 528, 31, 340, 529, 336, 528, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 535, 34, 307, 529, 37, 312, 531, 43, 316, 533, 49, 314, 532, 55, 311, 531, 12, 1], [2, 695, 973, 213, 31, 350, 528, 37, 350, 528, 43, 350, 528, 49, 352, 528, 55, 352, 527, 58, 352, 534, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 214, 31, 343, 528, 37, 343, 528, 43, 343, 528, 49, 345, 528, 55, 345, 527, 58, 345, 534, 216, 13, 347, 531, 335, 532, 19, 343, 533, 331, 533, 141, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 160, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 528, 331, 528, 43, 338, 528, 335, 528, 331, 528, 55, 338, 529, 335, 529, 331, 528, 176, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 535, 34, 302, 528, 37, 307, 532, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 213, 19, 350, 538, 214, 19, 343, 538, 141, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 160, 19, 340, 529, 336, 529, 331, 528, 31, 340, 528, 336, 528, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 532, 34, 307, 528, 37, 312, 532, 49, 312, 535, 12, 695, 973, 213, 49, 352, 528, 55, 352, 527, 58, 352, 527, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 214, 49, 345, 528, 55, 345, 527, 58, 345, 527, 216, 13, 347, 531, 335, 532, 19, 343, 533, 331, 533, 141, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 160, 19, 338, 528, 335, 528, 331, 528, 31, 338, 528, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 52, 338, 529, 335, 528, 331, 528, 176, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 533, 34, 302, 528, 37, 307, 533, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 213, 13, 352, 532, 19, 350, 537, 214, 13, 345, 532, 19, 343, 537, 141, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 160, 19, 340, 528, 336, 528, 331, 528, 31, 340, 529, 336, 528, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 535, 34, 312, 527, 37, 312, 529, 40, 312, 527, 43, 312, 532, 49, 311, 531, 55, 309, 530, 12, 695, 973, 213, 31, 350, 528, 37, 350, 528, 43, 350, 528, 49, 352, 529, 55, 352, 528, 58, 352, 534, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 214, 31, 343, 528, 37, 343, 528, 43, 343, 528, 49, 345, 529, 55, 345, 528, 58, 345, 534, 216, 13, 347, 531, 335, 532, 19, 343, 536, 331, 536, 141, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 160, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 528, 331, 528, 43, 338, 528, 335, 528, 331, 528, 55, 338, 529, 335, 529, 331, 528, 176, 19, 338, 529, 335, 529, 331, 529, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 535, 34, 302, 528, 37, 307, 532, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 213, 19, 350, 539, 214, 19, 343, 539, 141, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 160, 19, 340, 529, 336, 529, 331, 528, 31, 340, 528, 336, 528, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 529, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 532, 34, 307, 528, 37, 312, 532, 49, 312, 535, 12, 695, 973, 213, 31, 350, 527, 34, 350, 528, 37, 350, 528, 40, 350, 527, 43, 350, 528, 46, 350, 527, 49, 352, 528, 55, 352, 528, 199, 13, 343, 551, 37, 347, 534, 43, 348, 533, 49, 350, 532, 55, 343, 532, 214, 31, 343, 527, 34, 343, 528, 37, 343, 528, 40, 343, 527, 43, 343, 528, 46, 343, 527, 49, 345, 528, 55, 345, 528, 216, 13, 347, 531, 335, 532, 19, 343, 536, 331, 536, 141, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 160, 19, 338, 528, 335, 528, 331, 528, 31, 338, 528, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 52, 338, 529, 335, 528, 331, 528, 176, 19, 338, 529, 335, 529, 331, 528, 31, 338, 529, 335, 529, 331, 528, 43, 338, 529, 335, 529, 331, 528, 55, 338, 529, 335, 528, 331, 528, 180, 13, 307, 533, 28, 302, 528, 31, 304, 528, 34, 302, 528, 302, 527, 37, 307, 533, 12, 695, 973, 199, 13, 348, 548, 37, 359, 529, 40, 355, 528, 43, 359, 530, 46, 355, 528, 49, 359, 529, 52, 355, 528, 55, 359, 530, 58, 355, 528, 213, 13, 352, 532, 19, 350, 538, 214, 13, 345, 532, 19, 343, 538, 141, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 160, 19, 340, 528, 336, 528, 331, 528, 31, 340, 529, 336, 528, 331, 528, 43, 340, 528, 336, 528, 331, 528, 55, 340, 528, 336, 528, 331, 528, 176, 19, 340, 528, 336, 528, 331, 528, 31, 340, 528, 336, 529, 331, 528, 43, 340, 528, 336, 529, 331, 528, 55, 340, 528, 336, 528, 331, 528, 180, 13, 312, 535, 34, 307, 529, 37, 312, 531, 43, 316, 533, 49, 314, 532, 55, 311, 531, 12, 1], [2, 695, 973, 213, 31, 350, 528, 37, 350, 528, 43, 350, 528, 49, 352, 528, 55, 352, 527, 58, 352, 534, 214, 31, 343, 528, 37, 343, 528, 43, 343, 528, 49, 345, 528, 55, 345, 527, 58, 345, 534, 216, 13, 347, 531, 335, 532, 19, 343, 533, 331, 533, 180, 13, 307, 535, 12, 695, 973, 213, 19, 350, 538, 214, 19, 343, 538, 12, 1]]\n"
          ]
        }
      ],
      "source": [
        "print(process_midi_to_segments(df['location'][0], BARS_PER_SEGMENT, tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjbMfBs1N-GJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "class MIDIMultiLabelDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, bars_per_segment, class_to_idx, num_classes, max_token_length):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.bars_per_segment = bars_per_segment\n",
        "        self.class_to_idx = class_to_idx\n",
        "        self.num_classes = num_classes\n",
        "        self.max_token_length = max_token_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        midi_fp = \"/content/\" + row['location']\n",
        "        labels_list = row['genre']\n",
        "\n",
        "        # --- 1. MIDI Processing to Tokenized Chunks ---\n",
        "        # Get a list of tokenized segments (chunks)\n",
        "        tokenized_segments = process_midi_to_segments(midi_fp, self.bars_per_segment, self.tokenizer, self.max_token_length)\n",
        "\n",
        "        if not tokenized_segments:\n",
        "            # Handle empty/corrupted MIDI files by returning a placeholder or raising an error.\n",
        "            raise ValueError(f\"No valid segments found for MIDI at {midi_fp}\")\n",
        "\n",
        "        # --- 2. Token Padding (Required for Collation) ---\n",
        "        # Find the max token length (L) across all segments in this *one* document\n",
        "        max_segment_len = max(len(seg) for seg in tokenized_segments)\n",
        "\n",
        "        padded_segments = []\n",
        "        for segment in tokenized_segments:\n",
        "            # Pad each segment to the max length L found in this document\n",
        "            padding_needed = max_segment_len - len(segment)\n",
        "            padded_segment = segment + [self.tokenizer.pad_token_id] * padding_needed\n",
        "            padded_segments.append(padded_segment)\n",
        "\n",
        "        # 3. Create Multi-Hot Vector\n",
        "        multi_hot_vector = np.zeros(self.num_classes, dtype=np.float32)\n",
        "        for class_name in labels_list:\n",
        "            if class_name in self.class_to_idx:\n",
        "                class_index = self.class_to_idx[class_name]\n",
        "                multi_hot_vector[class_index] = 1.0\n",
        "\n",
        "        # Output Tensors (Shape: [N, L] where L is max_segment_len for THIS document)\n",
        "        input_ids = torch.tensor(padded_segments, dtype=torch.long)\n",
        "        attention_mask = (input_ids != self.tokenizer.pad_token_id).int()\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,          # Shape: [N, L] (N and L are variable)\n",
        "            'attention_mask': attention_mask, # Shape: [N, L]\n",
        "            'labels': torch.tensor(multi_hot_vector, dtype=torch.float)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdPeC9jCN94G"
      },
      "outputs": [],
      "source": [
        "def midi_custom_collate_fn(batch):\n",
        "    \"\"\"\n",
        "    Pads the variable number of chunks (N) AND the variable chunk length (L)\n",
        "    across all documents in a batch.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Determine Max Dimensions (N_max and L_max) in the current batch\n",
        "    max_num_chunks = max(item['input_ids'].shape[0] for item in batch)\n",
        "    max_chunk_length = max(item['input_ids'].shape[1] for item in batch)\n",
        "\n",
        "    # Assume the pad token ID is consistent across all documents\n",
        "    pad_token_id = batch[0]['input_ids'].unique()[-1].item()\n",
        "\n",
        "    batch_input_ids = []\n",
        "    batch_attention_mask = []\n",
        "    batch_labels = []\n",
        "\n",
        "    for item in batch:\n",
        "        current_input_ids = item['input_ids']\n",
        "        current_attention_mask = item['attention_mask']\n",
        "        num_chunks = current_input_ids.shape[0]\n",
        "\n",
        "        # A. Inner Padding (Padding L): Pad all current segments to L_max\n",
        "        # Pad columns (token length)\n",
        "        col_padding_needed = max_chunk_length - current_input_ids.shape[1]\n",
        "\n",
        "        # Pad tensor for columns (for each row/chunk)\n",
        "        col_pad_tensor = torch.full((num_chunks, col_padding_needed), pad_token_id, dtype=torch.long)\n",
        "        l_padded_input_ids = torch.cat([current_input_ids, col_pad_tensor], dim=1)\n",
        "\n",
        "        # Pad attention mask columns with 0s\n",
        "        col_pad_mask = torch.zeros((num_chunks, col_padding_needed), dtype=torch.int)\n",
        "        l_padded_attention_mask = torch.cat([current_attention_mask, col_pad_mask], dim=1)\n",
        "\n",
        "\n",
        "        # B. Outer Padding (Padding N): Pad the number of rows/chunks to N_max\n",
        "        row_padding_needed = max_num_chunks - num_chunks\n",
        "\n",
        "        # Pad rows (chunks) with L_max length pad tokens\n",
        "        row_pad_tensor = torch.full((row_padding_needed, max_chunk_length), pad_token_id, dtype=torch.long)\n",
        "        final_input_ids = torch.cat([l_padded_input_ids, row_pad_tensor], dim=0)\n",
        "\n",
        "        # Pad rows (chunks) of mask with 0s\n",
        "        row_pad_mask = torch.zeros((row_padding_needed, max_chunk_length), dtype=torch.int)\n",
        "        final_attention_mask = torch.cat([l_padded_attention_mask, row_pad_mask], dim=0)\n",
        "\n",
        "        batch_input_ids.append(final_input_ids)\n",
        "        batch_attention_mask.append(final_attention_mask)\n",
        "        batch_labels.append(item['labels'])\n",
        "\n",
        "    return {\n",
        "        'input_ids': torch.stack(batch_input_ids),        # Shape: [B, N_max, L_max]\n",
        "        'attention_mask': torch.stack(batch_attention_mask), # Shape: [B, N_max, L_max]\n",
        "        'labels': torch.stack(batch_labels)                 # Shape: [B, num_class]\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aK0dtY3HkC3Y"
      },
      "outputs": [],
      "source": [
        "train_dataset = MIDIMultiLabelDataset(\n",
        "    df,\n",
        "    tokenizer=tokenizer,\n",
        "    bars_per_segment=BARS_PER_SEGMENT,\n",
        "    class_to_idx=CLASS_TO_INDEX,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    max_token_length=MAX_CHUNK_LENGTH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rWciL_ekk_m"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    collate_fn=midi_custom_collate_fn, # ESSENTIAL for handling variable chunks/lengths\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK1z63Uckk9D",
        "outputId": "1418b268-c5ee-429c-9437-5c623292b8ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## 🎵 First Batch Data Sample Check 🎵\n",
            "---\n",
            "BATCH SHAPE (B, N_max, L_max): (4, 26, 256)\n",
            "Max Chunks (N_max): 26 (All documents padded to this number of rows/chunks)\n",
            "Max Segment Length (L_max): 256 (All chunks padded to this token length)\n",
            "\n",
            "### 1. Input IDs (Tokens) - [B, N_max, L_max]\n",
            "Shape: torch.Size([4, 26, 256])\n",
            "--- Doc 1 (MIDI A) Chunk 1 (Padded to 410) ---\n",
            "tensor([  2, 692, 970, 193,  13, 337, 538,  12, 695, 970, 193,  13, 337, 538,\n",
            "         25, 336, 538,  37, 337, 538,  49, 337, 538, 325, 538,  12, 695, 970,\n",
            "        193,  13, 339, 538, 325, 538,  25, 339, 538, 324, 538,  37, 341, 538,\n",
            "        325, 538,  49, 337, 538, 325, 538,  12, 695, 970, 193,  13, 342, 538,\n",
            "        327, 538,  25, 342, 538, 327, 538,  37, 341, 538, 329, 538,  49, 341,\n",
            "        538, 325, 538,  12, 695, 970, 193,  13, 339, 538, 330, 538,  25, 339,\n",
            "        538, 330, 538,  37, 337, 538, 329, 538,  49, 344, 538, 329, 538,  12,\n",
            "        695, 970, 193,  13, 342, 538, 327, 538,  25, 339, 538, 327, 538,  37,\n",
            "        341, 538, 325, 538,  49, 341, 538, 332, 538,  12, 695, 970, 193,  13,\n",
            "        339, 538, 330, 538,  25, 339, 538, 327, 538,  37, 337, 538, 329, 538,\n",
            "         49, 332, 538, 329, 538,  12, 695, 970, 193,  13, 334, 538, 327, 538,\n",
            "         25, 336, 538, 327, 538,  37, 337, 538, 325, 538,  49, 341, 538, 320,\n",
            "        538,  12,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1])\n",
            "\n",
            "--- Doc 2 (MIDI B) Chunk 1 (Padded to 410) ---\n",
            "tensor([  2, 695, 978,  12, 695, 978, 191,  13, 339, 622, 335, 622, 332, 622,\n",
            "        207,  13, 332, 534,  21, 334, 535,  29, 335, 534,  37, 337, 535,  45,\n",
            "        335, 535,  53, 334, 534, 195,  13, 332, 653, 327, 653, 320, 653, 236,\n",
            "         13, 332, 620, 327, 620, 320, 620, 308, 621,  12, 695, 978, 207,  13,\n",
            "        332, 564,  12, 695, 978, 191,  13, 341, 622, 337, 622, 332, 622, 207,\n",
            "         13, 332, 535,  21, 334, 535,  29, 335, 533,  37, 337, 536,  45, 335,\n",
            "        534,  53, 337, 534, 236,  13, 337, 617, 332, 617, 325, 617, 313, 618,\n",
            "         12, 695, 978, 207,  13, 339, 534,  21, 332, 558,  12, 695, 978, 191,\n",
            "         13, 340, 622, 335, 622, 332, 622, 207,  13, 332, 534,  21, 334, 534,\n",
            "         29, 335, 534,  37, 337, 536,  45, 335, 535,  53, 334, 534, 236,  13,\n",
            "        335, 616, 328, 616, 323, 615, 316, 616, 304, 616,  12, 695, 978, 207,\n",
            "         13, 332, 561,  55, 337, 532,  12, 695, 978, 207,  13, 339, 533,  21,\n",
            "        332, 558, 191,  13, 339, 622, 335, 622, 332, 622, 236,  13, 339, 626,\n",
            "        332, 622, 327, 622, 320, 622, 308, 622,  12,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1])\n",
            "\n",
            "--- Doc 2 (MIDI B) PADDED CHUNK (Should be all padding) ---\n",
            "tensor([  2, 695, 978, 191,  13])\n",
            "\n",
            "### 2. Labels (Multi-Hot Vector) - [B, num_class]\n",
            "Shape: torch.Size([4, 42])\n",
            "--- Labels Doc 1 ---\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
            "--- Labels Doc 2 ---\n",
            "tensor([])\n",
            "tensor([])\n"
          ]
        }
      ],
      "source": [
        "# --- Fetch and Check the FIRST Batch ---\n",
        "first_batch = next(iter(train_dataloader))\n",
        "\n",
        "# The batch contains Doc A (3 segments, max L=320) and Doc B (2 segments, max L=410)\n",
        "\n",
        "print(\"## 🎵 First Batch Data Sample Check 🎵\")\n",
        "print(\"---\")\n",
        "\n",
        "# Shape verification\n",
        "input_ids = first_batch['input_ids']\n",
        "labels = first_batch['labels']\n",
        "\n",
        "B, N_max, L_max = input_ids.shape\n",
        "print(f\"BATCH SHAPE (B, N_max, L_max): ({B}, {N_max}, {L_max})\")\n",
        "\n",
        "# Expected N_max: 3 (from Doc A's 3 segments) or 5 (from Doc C's 5 segments)\n",
        "# Expected L_max: 410 (from Doc B's longest segment) or 320/210 etc.\n",
        "\n",
        "# Let's inspect the first batch (Doc A and Doc B):\n",
        "# Doc A: N=3, L_docA=320. Doc B: N=2, L_docB=410.\n",
        "# The DataLoader must output N_max=3, L_max=410.\n",
        "\n",
        "print(f\"Max Chunks (N_max): {N_max} (All documents padded to this number of rows/chunks)\")\n",
        "print(f\"Max Segment Length (L_max): {L_max} (All chunks padded to this token length)\")\n",
        "\n",
        "print(\"\\n### 1. Input IDs (Tokens) - [B, N_max, L_max]\")\n",
        "print(f\"Shape: {input_ids.shape}\")\n",
        "print(\"--- Doc 1 (MIDI A) Chunk 1 (Padded to 410) ---\")\n",
        "print(input_ids[0, 0, :350]) # Should show token IDs then padding\n",
        "\n",
        "print(\"\\n--- Doc 2 (MIDI B) Chunk 1 (Padded to 410) ---\")\n",
        "print(input_ids[1, 0, :350]) # Should show token IDs then padding\n",
        "\n",
        "print(\"\\n--- Doc 2 (MIDI B) PADDED CHUNK (Should be all padding) ---\")\n",
        "print(input_ids[1, 2, 0:5]) # This should be the padding chunk (all pad_token_id=1)\n",
        "\n",
        "print(\"\\n### 2. Labels (Multi-Hot Vector) - [B, num_class]\")\n",
        "print(f\"Shape: {labels.shape}\")\n",
        "\n",
        "# Doc A labels: class1, class10 -> indices 0 and 9\n",
        "print(\"--- Labels Doc 1 ---\")\n",
        "print(labels[0, 0:15])\n",
        "\n",
        "# Doc B labels: class50, class51, class52, class99 -> indices 49, 50, 51, 98\n",
        "print(\"--- Labels Doc 2 ---\")\n",
        "print(labels[1, 48:53])\n",
        "print(labels[1, 98:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eec3a9f"
      },
      "source": [
        "### Data Pipeline: Dataset, DataLoader, and `collate_fn` Explained\n",
        "\n",
        "Handling MIDI data for a Transformer model presents unique challenges, primarily due to the variable length of musical pieces. Our data pipeline, utilizing `MIDIMultiLabelDataset`, `DataLoader`, and a custom `midi_custom_collate_fn`, is designed to efficiently manage this variability and prepare data for the hierarchical classification model.\n",
        "\n",
        "#### 1. `MIDIMultiLabelDataset` (The Data Source for a Single MIDI)\n",
        "\n",
        "This class serves as the initial layer for processing individual MIDI files. When the `DataLoader` requests an item (`__getitem__(idx)` is called), `MIDIMultiLabelDataset` performs the following steps:\n",
        "\n",
        "*   **Load MIDI and Segment**: It takes a MIDI file path and passes it to the `process_midi_to_segments` function.\n",
        "    *   `process_midi_to_segments` loads the MIDI file into a `MultiTrack` object using the REMI-z library.\n",
        "    *   It then filters out any empty bars to ensure only musically relevant content is processed.\n",
        "    *   The filtered `MultiTrack` is segmented into fixed `BARS_PER_SEGMENT` chunks (e.g., 8-bar segments). This is crucial because different MIDI files can have wildly different total lengths, but we need consistent input sizes for our model's feature extractor.\n",
        "    *   Each musical chunk (segment) is converted into its REMI-z string representation (a sequence of tokens).\n",
        "    *   These REMI-z token sequences are then tokenized using the pre-trained `tokenizer` and padded or truncated to a uniform `MAX_CHUNK_LENGTH` (e.g., 256 tokens). If a document originally has `N` chunks, this step produces `N` tokenized sequences, each of length `MAX_CHUNK_LENGTH`.\n",
        "*   **Per-Document Data Structure**: For a given MIDI document, the `MIDIMultiLabelDataset` returns `N` tokenized and padded chunks. The key here is that while each *chunk* has a fixed token length (`MAX_CHUNK_LENGTH`), the *number of chunks* (`N`) can still vary from one MIDI document to another.\n",
        "*   **Create Multi-Hot Labels**: The list of genre names associated with the MIDI file (e.g., `['reggae', 'pop']`) is converted into a multi-hot encoded vector. This vector has a size of `NUM_CLASSES` (e.g., 42), with `1.0` at the indices corresponding to the present genres and `0.0` otherwise. This is the ground truth for multi-label classification.\n",
        "\n",
        "**Output of `MIDIMultiLabelDataset` (`__getitem__`)**: For each MIDI document, it yields a dictionary containing:\n",
        "    *   `input_ids`: `torch.Tensor` of shape `[num_chunks, MAX_CHUNK_LENGTH]`\n",
        "    *   `attention_mask`: `torch.Tensor` of shape `[num_chunks, MAX_CHUNK_LENGTH]`\n",
        "    *   `labels`: `torch.Tensor` of shape `[NUM_CLASSES]`\n",
        "\n",
        "#### 2. `DataLoader` (The Batch Assembler)\n",
        "\n",
        "The `DataLoader`'s primary role is to collect individual data samples from the `MIDIMultiLabelDataset` and group them into mini-batches. However, because the `num_chunks` dimension returned by `MIDIMultiLabelDataset` is *variable* across different MIDI documents, a standard `DataLoader` cannot directly stack these tensors. This is precisely why a custom `collate_fn` is indispensable.\n",
        "\n",
        "*   It iteratively fetches `BATCH_SIZE` individual data items (dictionaries) from the `MIDIMultiLabelDataset`.\n",
        "*   Instead of attempting to combine them directly, it passes this list of `BATCH_SIZE` items to our custom `midi_custom_collate_fn`.\n",
        "\n",
        "#### 3. `midi_custom_collate_fn` (The Batch Unifier)\n",
        "\n",
        "This is the most crucial component for harmonizing the variable dimensions within a batch. Its function is to take the list of `BATCH_SIZE` data items (each with its own `num_chunks`) and uniformly pad them so that they can be stacked into a single, cohesive tensor for the model.\n",
        "\n",
        "Here's how it ensures uniformity:\n",
        "\n",
        "*   **Determine Max Dimensions within the Batch**: It first scans all `BATCH_SIZE` documents within the current batch to identify:\n",
        "    *   `N_max`: The maximum number of chunks found in any single document within that batch.\n",
        "    *   `L_max`: The maximum token length for any chunk across all chunks in all documents within that batch. (Given our `process_midi_to_segments` already pads individual chunks to `MAX_CHUNK_LENGTH`, `L_max` will typically be `MAX_CHUNK_LENGTH`).\n",
        "*   **Inner Padding (Token Length `L_max`)**: For any chunk whose tokenized length is less than `L_max` (which would only happen if `MAX_CHUNK_LENGTH` was not a fixed limit in `process_midi_to_segments`, or if we didn't truncate), it pads the token sequence with `tokenizer.pad_token_id` and extends its `attention_mask` with zeros.\n",
        "*   **Outer Padding (Number of Chunks `N_max`)**: This is the key step for documents with fewer than `N_max` chunks. For such documents, `midi_custom_collate_fn` adds extra 'padding chunks'. These padding chunks are entirely filled with `tokenizer.pad_token_id` for their `input_ids` and `0`s for their `attention_mask`. This ensures that every document in the batch effectively has `N_max` chunks.\n",
        "*   **Stacking**: After both inner (token length) and outer (number of chunks) padding, all tensors within the batch now have consistent dimensions. The `input_ids`, `attention_mask`, and `labels` from each document are then stacked into single `torch.Tensor`s.\n",
        "\n",
        "**Output of `midi_custom_collate_fn`**: A single dictionary ready for direct input to the model:\n",
        "    *   `input_ids`: `torch.Tensor` of shape `[BATCH_SIZE, N_max, MAX_CHUNK_LENGTH]`\n",
        "    *   `attention_mask`: `torch.Tensor` of shape `[BATCH_SIZE, N_max, MAX_CHUNK_LENGTH]`\n",
        "    *   `labels`: `torch.Tensor` of shape `[BATCH_SIZE, NUM_CLASSES]`\n",
        "\n",
        "This structured batch is then fed to the `GPT2ForHierarchicalClassification` model, which can seamlessly process the `N_max` chunks and their `MAX_CHUNK_LENGTH` token sequences, ultimately aggregating their features for genre classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wnhsi1a-nxtJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RctLgeKCkk6u",
        "outputId": "dc36562f-af02-456f-9c14-a17880b7dbaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT2ForHierarchicalClassification(\n",
            "  (feature_extractor): GPT2Model(\n",
            "    (wte): Embedding(989, 768)\n",
            "    (wpe): Embedding(2048, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=768)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (aggregation_head): ChunkAggregationHead(\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (chunk_attention): Sequential(\n",
            "      (0): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (1): Tanh()\n",
            "      (2): Linear(in_features=768, out_features=1, bias=True)\n",
            "      (3): Softmax(dim=1)\n",
            "    )\n",
            "    (classifier): Linear(in_features=768, out_features=42, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "--- Model Size Information ---\n",
            "Total Parameters: 88,012,075\n",
            "Trainable Parameters: 623,659\n",
            "Non-Trainable Parameters (Frozen): 87,388,416\n",
            "Estimated Model Size (MB): 335.74\n"
          ]
        }
      ],
      "source": [
        "print(model)\n",
        "\n",
        "# Calculate and print model size information\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "non_trainable_params = total_params - trainable_params\n",
        "\n",
        "# Estimate memory footprint (assuming float32 parameters, 4 bytes per parameter)\n",
        "param_size_mb = total_params * 4 / (1024**2)\n",
        "\n",
        "print(f\"\\n--- Model Size Information ---\")\n",
        "print(f\"Total Parameters: {total_params:,}\")\n",
        "print(f\"Trainable Parameters: {trainable_params:,}\")\n",
        "print(f\"Non-Trainable Parameters (Frozen): {non_trainable_params:,}\")\n",
        "print(f\"Estimated Model Size (MB): {param_size_mb:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N121-TRmtVI",
        "outputId": "0f3821f2-3682-4792-c07c-d9548b6777d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f92320df",
        "outputId": "f3eafe9b-dd36-4e20-d2ca-f9a6ea3513bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Dataset Memory Usage (Pandas DataFrame) ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2842 entries, 0 to 2841\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   location  2842 non-null   object\n",
            " 1   genre     2842 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 599.6 KB\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Dataset Memory Usage (Pandas DataFrame) ---\")\n",
        "df.info(memory_usage='deep')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5841d3da"
      },
      "source": [
        "### Explanation of Memory Usage\n",
        "\n",
        "*   **DataFrame Memory (RAM)**: The `df.info(memory_usage='deep')` output provides the memory footprint of your pandas DataFrame, which holds the metadata and file paths for the entire dataset. This is the main memory usage for the raw dataset itself in your system's RAM.\n",
        "\n",
        "*   **Dataset and DataLoader Memory (Batch-wise)**:\n",
        "    *   The `MIDIMultiLabelDataset` itself, when instantiated, primarily holds references to the DataFrame, tokenizer, and configuration parameters. It *does not* load all MIDI files or their tokenized representations into RAM at once. Instead, when `__getitem__` is called (typically by the `DataLoader`), it processes *one* MIDI file at a time, segments it, tokenizes it, and returns the tensors for that single item.\n",
        "    *   The `DataLoader` then groups these individual items into batches. The memory footprint relevant here is for a *single batch* of processed data that gets loaded into GPU memory (or CPU memory if `device` is set to 'cpu').\n",
        "\n",
        "    As seen from the `first_batch` check (which displayed `BATCH_SHAPE (B, N_max, L_max): (4, 26, 256)`):\n",
        "    *   `B` (batch size): `4` documents per batch.\n",
        "    *   `N_max` (max chunks per document in that batch): `26` chunks.\n",
        "    *   `L_max` (max token length per chunk in that batch): `256` tokens.\n",
        "\n",
        "    These `input_ids` and `attention_mask` tensors for a single batch would be `BATCH_SIZE * N_max * L_max` integers. If each integer (`torch.long`) takes 8 bytes, then each batch's input tensors alone would be `4 * 26 * 256 * 8 = 212,992` bytes (or approximately `0.2 MB`). The labels (`[B, num_classes]`) are much smaller. This batch data is dynamically loaded into GPU memory (or CPU) during each training step.\n",
        "\n",
        "*   **GPU Memory for Training**: When training the model, the GPU needs to store several components:\n",
        "    1.  **Model Parameters**: As previously calculated, your model's parameters alone take up approximately **335.74 MB** (for float32 weights).\n",
        "    2.  **Optimizer States**: For optimizers like AdamW, internal states (e.g., momentum, variance) are maintained for each trainable parameter. This typically consumes about **2x the memory of the trainable parameters**. Since you have ~623K trainable parameters, this adds roughly `623,659 * 2 * 4 bytes/param / (1024^2) = ~4.75 MB`.\n",
        "    3.  **Activations**: This is the most variable part. During the forward pass, intermediate activations are generated and stored for the backward pass (gradient computation). The memory consumed by activations is highly dependent on the `BATCH_SIZE`, `N_max` (number of chunks), and `L_max` (sequence length) of your input. Freezing the feature extractor helps here as activations for its layers don't need to be stored for gradient computation.\n",
        "\n",
        "Therefore, the total GPU memory needed during training will be the sum of these, predominantly driven by the model parameters and the activations generated for the given batch size and sequence lengths. You could monitor `torch.cuda.max_memory_allocated()` or `nvidia-smi` during training for real-time usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4017kScvmtOt",
        "outputId": "dcc551fa-52c3-4aa5-891f-e54631fa02e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPT2ForHierarchicalClassification(\n",
              "  (feature_extractor): GPT2Model(\n",
              "    (wte): Embedding(989, 768)\n",
              "    (wpe): Embedding(2048, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D(nf=2304, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=768)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=3072, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=3072)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (aggregation_head): ChunkAggregationHead(\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (chunk_attention): Sequential(\n",
              "      (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (1): Tanh()\n",
              "      (2): Linear(in_features=768, out_features=1, bias=True)\n",
              "      (3): Softmax(dim=1)\n",
              "    )\n",
              "    (classifier): Linear(in_features=768, out_features=42, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSvnq3ELmNb5"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define Optimizer (only for UN-frozen parameters)\n",
        "trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
        "optimizer = optim.AdamW(trainable_params, lr=1e-3)\n",
        "\n",
        "# Define Loss Function (Binary Cross-Entropy for Multi-Label)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBkW9YW3mZTg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3dMH_66mZKr"
      },
      "outputs": [],
      "source": [
        "# from tqdm.auto import tqdm\n",
        "# import torch.nn as nn\n",
        "\n",
        "# NUM_EPOCHS = 1\n",
        "\n",
        "# model.train()\n",
        "# for epoch in range(NUM_EPOCHS):\n",
        "#     total_loss = 0\n",
        "\n",
        "#     for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\"):\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         # Move data to the device\n",
        "#         input_ids = batch['input_ids'].to(device)         # [B, N_max, L_max]\n",
        "#         attention_mask = batch['attention_mask'].to(device) # [B, N_max, L_max]\n",
        "#         labels = batch['labels'].to(device)               # [B, 100]\n",
        "\n",
        "#         # 1. Forward Pass\n",
        "#         # The model handles the flattening, feature extraction, and aggregation.\n",
        "#         logits = model(input_ids, attention_mask)\n",
        "\n",
        "#         # 2. Calculate Loss\n",
        "#         loss = criterion(logits, labels)\n",
        "\n",
        "#         # 3. Backward Pass and Optimization\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         total_loss += loss.item()\n",
        "\n",
        "#     avg_loss = total_loss / len(train_dataloader)\n",
        "#     print(f\"Epoch {epoch+1} completed. Average Loss: {avg_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YddRqUKJoJUT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWSvW-xHRoVk"
      },
      "source": [
        "## Lightning Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkbqlu2k2adg"
      },
      "outputs": [],
      "source": [
        "# !pip install lightning # Install PyTorch Lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2We-N5lL6hX",
        "outputId": "d02cf360-b4f8-4a98-fa1c-cefe91bd65ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting lightning\n",
            "  Downloading lightning-2.6.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML<8.0,>5.4 in /usr/local/lib/python3.12/dist-packages (from lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2027.0,>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (2025.3.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: packaging<27.0,>=20.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (25.0)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (2.9.0+cu126)\n",
            "Collecting torchmetrics<3.0,>0.7.0 (from lightning)\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>4.5.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (4.15.0)\n",
            "Collecting pytorch-lightning (from lightning)\n",
            "  Downloading pytorch_lightning-2.6.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (3.13.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.5.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics<3.0,>0.7.0->lightning) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.22.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (3.11)\n",
            "Downloading lightning-2.6.0-py3-none-any.whl (845 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m846.0/846.0 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.6.0-py3-none-any.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch-lightning, lightning\n",
            "Successfully installed lightning-2.6.0 lightning-utilities-0.15.2 pytorch-lightning-2.6.0 torchmetrics-1.8.2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import lightning as L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soYfUc2xL6fJ"
      },
      "outputs": [],
      "source": [
        "class GenreClassifier(L.LightningModule):\n",
        "    def __init__(self, model_with_head):\n",
        "        super().__init__()\n",
        "        self.model_with_head = model_with_head\n",
        "        # Use BCEWithLogitsLoss for multi-label classification\n",
        "        self.criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels = batch['labels']\n",
        "\n",
        "        logits = self.model_with_head(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss = self.criterion(logits, labels)\n",
        "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels = batch['labels']\n",
        "\n",
        "        logits = self.model_with_head(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss = self.criterion(logits, labels)\n",
        "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "\n",
        "        # Optional: calculate accuracy or other metrics\n",
        "        preds = (torch.sigmoid(logits) > 0.5).float()\n",
        "        accuracy = (preds == labels).float().mean()\n",
        "        self.log(\"val_acc\", accuracy, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels = batch['labels']\n",
        "\n",
        "        logits = self.model_with_head(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss = self.criterion(logits, labels)\n",
        "        self.log(\"test_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "\n",
        "        preds = (torch.sigmoid(logits) > 0.5).float()\n",
        "        accuracy = (preds == labels).float().mean()\n",
        "        self.log(\"test_acc\", accuracy, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # Only optimize the parameters of the classifier head\n",
        "        # Ensure the learning rate is appropriate\n",
        "        return torch.optim.AdamW(self.model_with_head.aggregation_head.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1Pr1WCZL6c9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "new_python_cell_0",
        "outputId": "849683ce-692a-472e-894d-0dd7955dd49e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GenreClassificationData instantiated. Call setup() to create datasets.\n"
          ]
        }
      ],
      "source": [
        "import lightning as L\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "class GenreClassificationData(L.LightningDataModule):\n",
        "    def __init__(self, df, tokenizer, bars_per_segment, class_to_idx, num_classes, max_token_length, batch_size=BATCH_SIZE, val_split=0.1, test_split=0.1):\n",
        "        super().__init__()\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.bars_per_segment = bars_per_segment\n",
        "        self.class_to_idx = class_to_idx\n",
        "        self.num_classes = num_classes\n",
        "        self.max_token_length = max_token_length\n",
        "        self.batch_size = batch_size\n",
        "        self.val_split = val_split\n",
        "        self.test_split = test_split\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        # Assign train/val/test datasets for use in dataloaders\n",
        "        full_dataset = MIDIMultiLabelDataset(self.df, self.tokenizer, self.bars_per_segment, self.class_to_idx, self.num_classes, self.max_token_length)\n",
        "\n",
        "        val_size = int(len(full_dataset) * self.val_split)\n",
        "        test_size = int(len(full_dataset) * self.test_split)\n",
        "        train_size = len(full_dataset) - val_size - test_size\n",
        "\n",
        "        self.train_dataset, self.val_dataset, self.test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=midi_custom_collate_fn)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, collate_fn=midi_custom_collate_fn)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, collate_fn=midi_custom_collate_fn)\n",
        "\n",
        "# Instantiate the DataModule\n",
        "genre_classification_data = GenreClassificationData(\n",
        "    df=df, # Use the main dataframe\n",
        "    tokenizer=tokenizer,\n",
        "    bars_per_segment=BARS_PER_SEGMENT,\n",
        "    class_to_idx=CLASS_TO_INDEX,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    max_token_length=MAX_CHUNK_LENGTH,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "print(\"GenreClassificationData instantiated. Call setup() to create datasets.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607,
          "referenced_widgets": [
            "24f71f9b8b8b436ea2a86c3f110cf80d",
            "137b50091ccc4901b57859e81d9939c0"
          ]
        },
        "id": "new_python_cell_1",
        "outputId": "f925fef1-eb90-47ba-f0f8-3d423b0b0c38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training samples: 2274\n",
            "Number of validation samples: 284\n",
            "Number of test samples: 284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: 💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Batch 1:\n",
            "  input_ids shape: torch.Size([4, 17, 256])\n",
            "  attention_mask shape: torch.Size([4, 17, 256])\n",
            "  labels shape: torch.Size([4, 42])\n",
            "Starting Lightning training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name            </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>┃\n",
              "┡━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ model_with_head │ GPT2ForHierarchicalClassification │ 88.0 M │ train │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ criterion       │ BCEWithLogitsLoss                 │      0 │ train │     0 │\n",
              "└───┴─────────────────┴───────────────────────────────────┴────────┴───────┴───────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName           \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
              "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ model_with_head │ GPT2ForHierarchicalClassification │ 88.0 M │ train │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ criterion       │ BCEWithLogitsLoss                 │      0 │ train │     0 │\n",
              "└───┴─────────────────┴───────────────────────────────────┴────────┴───────┴───────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 623 K                                                                                            \n",
              "<span style=\"font-weight: bold\">Non-trainable params</span>: 87.4 M                                                                                       \n",
              "<span style=\"font-weight: bold\">Total params</span>: 88.0 M                                                                                               \n",
              "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 352                                                                        \n",
              "<span style=\"font-weight: bold\">Modules in train mode</span>: 172                                                                                         \n",
              "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mTrainable params\u001b[0m: 623 K                                                                                            \n",
              "\u001b[1mNon-trainable params\u001b[0m: 87.4 M                                                                                       \n",
              "\u001b[1mTotal params\u001b[0m: 88.0 M                                                                                               \n",
              "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 352                                                                        \n",
              "\u001b[1mModules in train mode\u001b[0m: 172                                                                                         \n",
              "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24f71f9b8b8b436ea2a86c3f110cf80d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=1` reached.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lightning training finished.\n"
          ]
        }
      ],
      "source": [
        "# Call setup to create the datasets\n",
        "genre_classification_data.setup()\n",
        "\n",
        "print(f\"Number of training samples: {len(genre_classification_data.train_dataset)}\")\n",
        "print(f\"Number of validation samples: {len(genre_classification_data.val_dataset)}\")\n",
        "print(f\"Number of test samples: {len(genre_classification_data.test_dataset)}\")\n",
        "\n",
        "# Example of getting a batch from the training dataloader\n",
        "for i, batch in enumerate(genre_classification_data.train_dataloader()):\n",
        "    print(f\"Train Batch {i+1}:\")\n",
        "    print(f\"  input_ids shape: {batch['input_ids'].shape}\")\n",
        "    print(f\"  attention_mask shape: {batch['attention_mask'].shape}\")\n",
        "    print(f\"  labels shape: {batch['labels'].shape}\")\n",
        "    if i == 0:\n",
        "        break\n",
        "\n",
        "# Instantiate the Lightning Module\n",
        "lightning_model = GenreClassifier(model_with_head=model)\n",
        "\n",
        "# Set up the Lightning Trainer\n",
        "trainer = L.Trainer(max_epochs=NUM_EPOCHS, accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Starting Lightning training...\")\n",
        "trainer.fit(lightning_model, genre_classification_data)\n",
        "print(\"Lightning training finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vuuj3yNNL6Yg",
        "outputId": "89e8138b-33ae-41f1-da8a-978c2eb48ad7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to model_checkpoints/genre_classifier_model.pth\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Define the path to save the model\n",
        "CHECKPOINT_DIR = \"model_checkpoints\"\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "model_save_path = os.path.join(CHECKPOINT_DIR, \"genre_classifier_model.pth\")\n",
        "\n",
        "# Save the model's state dictionary\n",
        "torch.save(lightning_model.model_with_head.state_dict(), model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198,
          "referenced_widgets": [
            "2dbbc4de1f8643e297401986f38d6fd5",
            "9469296bd3904355a21f3edf63d63a6d"
          ]
        },
        "id": "51f29161",
        "outputId": "a1464d1e-2ab6-4a6a-b38b-5b6b71c8f431"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2dbbc4de1f8643e297401986f38d6fd5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting model evaluation on the test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9621896743774414     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.12024378776550293    </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9621896743774414    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.12024378776550293   \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model evaluation finished.\n"
          ]
        }
      ],
      "source": [
        "print(\"Starting model evaluation on the test set...\")\n",
        "trainer.test(lightning_model, genre_classification_data)\n",
        "print(\"Model evaluation finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cys8Lk9FL-pK",
        "outputId": "7ac41016-9ec1-47ff-93e5-69d34e096524"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Performing Inference on a Sample MIDI ---\n",
            "MIDI File: /content/lmd_full/2/2a604c93ed4ee9d82d388da694e89e7c.mid\n",
            "Actual Genres: ['reggae' 'pop']\n",
            "Predicted Genres:\n",
            "  - electronic: 0.5856\n",
            "  - pop: 0.1844\n"
          ]
        }
      ],
      "source": [
        "def predict_genre(midi_file_path, model, tokenizer, bars_per_segment, class_to_idx, num_classes, max_token_length, device, threshold=0.5, top_k=2):\n",
        "    # Ensure model is in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Prepare the MIDI data for inference\n",
        "    try:\n",
        "        tokenized_segments = process_midi_to_segments(midi_file_path, bars_per_segment, tokenizer, max_token_length)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error processing MIDI file: {e}\")\n",
        "        return []\n",
        "    if not tokenized_segments:\n",
        "        return []\n",
        "\n",
        "    # Pad segments for this single document\n",
        "    max_segment_len = max(len(seg) for seg in tokenized_segments)\n",
        "    padded_segments = []\n",
        "    for segment in tokenized_segments:\n",
        "        padding_needed = max_segment_len - len(segment)\n",
        "        padded_segment = segment + [tokenizer.pad_token_id] * padding_needed\n",
        "        padded_segments.append(padded_segment)\n",
        "\n",
        "    # Convert to tensors and add batch dimension (Batch size = 1 for single inference)\n",
        "    input_ids = torch.tensor(padded_segments, dtype=torch.long).unsqueeze(0).to(device)\n",
        "    attention_mask = (input_ids != tokenizer.pad_token_id).int().to(device)\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_ids, attention_mask)\n",
        "        probabilities = torch.sigmoid(logits).squeeze(0) # Remove batch dimension\n",
        "\n",
        "    # Convert probabilities to genre labels\n",
        "    predicted_genres = []\n",
        "    idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
        "\n",
        "    for i, prob in enumerate(probabilities):\n",
        "        if prob > threshold:\n",
        "            predicted_genres.append((idx_to_class[i], prob.item()))\n",
        "\n",
        "    # Sort by probability descending\n",
        "    predicted_genres.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Return only the top_k genres\n",
        "    return predicted_genres[:top_k]\n",
        "\n",
        "# Example usage of inference\n",
        "print(\"\\n--- Performing Inference on a Sample MIDI ---\")\n",
        "# Use one of the MIDI files from your dataset for a quick test\n",
        "sample_midi_path = \"/content/\" + df['location'][0]\n",
        "\n",
        "# Get actual labels for the sample MIDI file\n",
        "actual_labels = df[df['location'] == sample_midi_path.replace('/content/', '')]['genre'].iloc[0]\n",
        "\n",
        "# Re-instantiate the model structure to load the saved weights\n",
        "# Make sure the feature_extractor and classifier_head are defined as before\n",
        "# For this example, 'model' is already our GPT2ForHierarchicalClassification instance\n",
        "# Load the saved state dict\n",
        "loaded_model = GPT2ForHierarchicalClassification(feature_extractor, classifier_head).to(device)\n",
        "loaded_model.load_state_dict(torch.load(model_save_path))\n",
        "loaded_model.eval()\n",
        "\n",
        "predicted_genres = predict_genre(\n",
        "    midi_file_path=sample_midi_path,\n",
        "    model=loaded_model,\n",
        "    tokenizer=tokenizer,\n",
        "    bars_per_segment=BARS_PER_SEGMENT,\n",
        "    class_to_idx=CLASS_TO_INDEX,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    max_token_length=MAX_CHUNK_LENGTH,\n",
        "    device=device,\n",
        "    threshold=0, # Adjust threshold as needed\n",
        "    top_k=2 # Limit to top 2 predictions\n",
        ")\n",
        "\n",
        "print(f\"MIDI File: {sample_midi_path}\")\n",
        "print(f\"Actual Genres: {actual_labels}\")\n",
        "\n",
        "if predicted_genres:\n",
        "    print(\"Predicted Genres:\")\n",
        "    for genre, prob in predicted_genres:\n",
        "        print(f\"  - {genre}: {prob:.4f}\")\n",
        "else:\n",
        "    print(f\"No genres predicted for {sample_midi_path} above the threshold.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFR-6MfZL6Tp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yIpF3wUQf1k"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0989f2b384a34486899bcd8c98bc1be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "137b50091ccc4901b57859e81d9939c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14f95cb68e7046328e88da6a1dfa4702": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18c6d7d86c4b41988a9a472f05542370": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e725a02050e4cea879941f3ebfc4faa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23621cfcd50b4d4abbd3c63dd2cf2314": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7397a5a085142bf9ab85ee487617e63",
            "max": 909,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55fea2b999614beb858c94ea3de551cb",
            "value": 909
          }
        },
        "24f71f9b8b8b436ea2a86c3f110cf80d": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_137b50091ccc4901b57859e81d9939c0",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 0/0  <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 569/569 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:34:12 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.33it/s</span> <span style=\"font-style: italic\">v_num: 1.000 train_loss_step:     </span>\n                                                                                 <span style=\"font-style: italic\">0.155                             </span>\n</pre>\n",
                  "text/plain": "Epoch 0/0  \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 569/569 \u001b[2m0:34:12 • 0:00:00\u001b[0m \u001b[2;4m0.33it/s\u001b[0m \u001b[3mv_num: 1.000 train_loss_step:     \u001b[0m\n                                                                                 \u001b[3m0.155                             \u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "28bc238ba4b94e7298d1395fd0cfc51c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a1b4036307943b3964881f03165fec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97bee1bfd448416eaf8b021813ab5ab9",
              "IPY_MODEL_c15eff3220f7435890af4aaddd98f3cb",
              "IPY_MODEL_e83ec1ddc8824f998229135628fab7ee"
            ],
            "layout": "IPY_MODEL_28bc238ba4b94e7298d1395fd0cfc51c"
          }
        },
        "2b2c9b60879849afb4ccbc981c2edcf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dbbc4de1f8643e297401986f38d6fd5": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_9469296bd3904355a21f3edf63d63a6d",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Testing <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 71/71 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:02:49 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.41it/s</span>  \n</pre>\n",
                  "text/plain": "Testing \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 71/71 \u001b[2m0:02:49 • 0:00:00\u001b[0m \u001b[2;4m0.41it/s\u001b[0m  \n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "300b8de437944cfbbfe45e923ec0248e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3357b1ce4fad4cfe9a1b788c7c21f32f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "349cf384cf6d47798d30f50b8f3facef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b6a2d92f23b40aa90a38645f5da955e",
            "placeholder": "​",
            "style": "IPY_MODEL_14f95cb68e7046328e88da6a1dfa4702",
            "value": "config.json: 100%"
          }
        },
        "35d39819d96b4b80b8cd881cffbf8cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a238f1225ed04f05a278e222aef91b69",
              "IPY_MODEL_dc36a6135c3f4cc2af1940d89ae81ced",
              "IPY_MODEL_e0ab1c01be274ff09bdb089a96d46020"
            ],
            "layout": "IPY_MODEL_e3babef5aa764e539ab024e23abb48c6"
          }
        },
        "362b59c182064ab1b78c4480432c9761": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c09c3100d144816a2a1d3e7fd8265e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41ba21f88158449991f5e0ca3e0d4346": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47892ad649814b5faee72728f062d3e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "496f38da15ce46f491017635f1717bca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4edfe0c86a3e40c487e5ee4c6c2c1423": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e725a02050e4cea879941f3ebfc4faa",
            "placeholder": "​",
            "style": "IPY_MODEL_e718e3db8f0141a285a639d45cde66d3",
            "value": " 178k/? [00:00&lt;00:00, 9.78MB/s]"
          }
        },
        "534eb9f0131a48a58a0306e2a8a6c85b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55fea2b999614beb858c94ea3de551cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d75c7861a1e44e18fd93a4b56d9d6a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70fbdb57e4bf4eae8a977ad307b37eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85f3d220ab34443e8c0fac5c63e7bcff",
              "IPY_MODEL_981d4b45bf524bd5a64912b850c9d310",
              "IPY_MODEL_4edfe0c86a3e40c487e5ee4c6c2c1423"
            ],
            "layout": "IPY_MODEL_5d75c7861a1e44e18fd93a4b56d9d6a2"
          }
        },
        "76f3005d96ec4bd5a8e349ab4a4254a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41ba21f88158449991f5e0ca3e0d4346",
            "placeholder": "​",
            "style": "IPY_MODEL_c3624ec6061f4568876ad2ca7c754b94",
            "value": " 116/116 [00:00&lt;00:00, 13.6kB/s]"
          }
        },
        "7b6a2d92f23b40aa90a38645f5da955e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f4f328f771e4ad4a6af756ec31e06c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6437fc8b86b426b8094976ff1a8e011",
            "placeholder": "​",
            "style": "IPY_MODEL_2b2c9b60879849afb4ccbc981c2edcf4",
            "value": " 175M/175M [00:02&lt;00:00, 77.7MB/s]"
          }
        },
        "83fcc4a284144217b87cc890207c23ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85f3d220ab34443e8c0fac5c63e7bcff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18c6d7d86c4b41988a9a472f05542370",
            "placeholder": "​",
            "style": "IPY_MODEL_d478ca79f3ff470a8b4412f6fbc15b36",
            "value": "tokenizer.json: "
          }
        },
        "89dd8a7538294d01a77d5321b6a3163a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9469296bd3904355a21f3edf63d63a6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "952e2fc228684ee987e909d58035cc43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95837b59fa7b404f9590c015cefd2a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_952e2fc228684ee987e909d58035cc43",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfadc6ec0fcf48e89339fb8ad27dbc85",
            "value": 116
          }
        },
        "97bee1bfd448416eaf8b021813ab5ab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_496f38da15ce46f491017635f1717bca",
            "placeholder": "​",
            "style": "IPY_MODEL_47892ad649814b5faee72728f062d3e1",
            "value": "tokenizer_config.json: "
          }
        },
        "981d4b45bf524bd5a64912b850c9d310": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df1a24cef97b49c097ea4b67bd7ca44d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c09c3100d144816a2a1d3e7fd8265e7",
            "value": 1
          }
        },
        "9d168fbc8c9944668b6eee2863653cc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a238f1225ed04f05a278e222aef91b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83fcc4a284144217b87cc890207c23ed",
            "placeholder": "​",
            "style": "IPY_MODEL_fc8277ad66e24c26889431fa7b3f3f38",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "a2f2c6c5431641b8831433d5339d4104": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2e37a6a3ee344d5a161be3788943b47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b7397a5a085142bf9ab85ee487617e63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfadc6ec0fcf48e89339fb8ad27dbc85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0b428b4da304a1da9eb2c29184ad43a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eed33007457946a698fa4ad91acf048d",
              "IPY_MODEL_95837b59fa7b404f9590c015cefd2a84",
              "IPY_MODEL_76f3005d96ec4bd5a8e349ab4a4254a9"
            ],
            "layout": "IPY_MODEL_fda56091e23643bab2960a0edf072587"
          }
        },
        "c15eff3220f7435890af4aaddd98f3cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2e37a6a3ee344d5a161be3788943b47",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f92c66900a0c43ca9055b1cb29693c1e",
            "value": 1
          }
        },
        "c3624ec6061f4568876ad2ca7c754b94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5d7d1e0f1424b3289cab78c43d6865c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce9831eb7a324779856743010728e8f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8c47af85de2490f8d17c18f1bcf26cb",
            "placeholder": "​",
            "style": "IPY_MODEL_cfd07bd1b0624d0392752d9f59004dae",
            "value": " 909/909 [00:00&lt;00:00, 117kB/s]"
          }
        },
        "cf13a028c3ef4aea952648faf7808948": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfd07bd1b0624d0392752d9f59004dae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d24a292fd89c403c8598bfc4beea36fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_362b59c182064ab1b78c4480432c9761",
            "placeholder": "​",
            "style": "IPY_MODEL_a2f2c6c5431641b8831433d5339d4104",
            "value": "model.safetensors: 100%"
          }
        },
        "d2e2f0a51a9041f3934dc3d0ecb44023": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_349cf384cf6d47798d30f50b8f3facef",
              "IPY_MODEL_23621cfcd50b4d4abbd3c63dd2cf2314",
              "IPY_MODEL_ce9831eb7a324779856743010728e8f7"
            ],
            "layout": "IPY_MODEL_534eb9f0131a48a58a0306e2a8a6c85b"
          }
        },
        "d478ca79f3ff470a8b4412f6fbc15b36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6437fc8b86b426b8094976ff1a8e011": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9ea2eda759a41fc8fe3e7ccd6cba530": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc36a6135c3f4cc2af1940d89ae81ced": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf13a028c3ef4aea952648faf7808948",
            "max": 857,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d168fbc8c9944668b6eee2863653cc5",
            "value": 857
          }
        },
        "dcf169cbc14048b380e243ee2bd14a4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d24a292fd89c403c8598bfc4beea36fc",
              "IPY_MODEL_f3927f9483a146138b4a8882f832b95b",
              "IPY_MODEL_7f4f328f771e4ad4a6af756ec31e06c8"
            ],
            "layout": "IPY_MODEL_fdd130428feb4cdd86d6a7480abb509c"
          }
        },
        "df1a24cef97b49c097ea4b67bd7ca44d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e0ab1c01be274ff09bdb089a96d46020": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8d39c6452ee44acb78f5d6c09884b07",
            "placeholder": "​",
            "style": "IPY_MODEL_0989f2b384a34486899bcd8c98bc1be1",
            "value": " 857/857 [00:00&lt;00:00, 96.2kB/s]"
          }
        },
        "e3babef5aa764e539ab024e23abb48c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e718e3db8f0141a285a639d45cde66d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e83ec1ddc8824f998229135628fab7ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89dd8a7538294d01a77d5321b6a3163a",
            "placeholder": "​",
            "style": "IPY_MODEL_d9ea2eda759a41fc8fe3e7ccd6cba530",
            "value": " 167k/? [00:00&lt;00:00, 11.2MB/s]"
          }
        },
        "ea82cbed1d124e3aaaa4178510a2200b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eed33007457946a698fa4ad91acf048d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5d7d1e0f1424b3289cab78c43d6865c",
            "placeholder": "​",
            "style": "IPY_MODEL_3357b1ce4fad4cfe9a1b788c7c21f32f",
            "value": "generation_config.json: 100%"
          }
        },
        "f3927f9483a146138b4a8882f832b95b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_300b8de437944cfbbfe45e923ec0248e",
            "max": 174791872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea82cbed1d124e3aaaa4178510a2200b",
            "value": 174791872
          }
        },
        "f8c47af85de2490f8d17c18f1bcf26cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8d39c6452ee44acb78f5d6c09884b07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f92c66900a0c43ca9055b1cb29693c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc8277ad66e24c26889431fa7b3f3f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fda56091e23643bab2960a0edf072587": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdd130428feb4cdd86d6a7480abb509c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
